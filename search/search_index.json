{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Robotics With Raspberry Pi: Build and Program Your First Robot Buggy Build and program your first robot buggy using a Raspberry Pi, learning how to connect motors, add sensors and write algorithms. This site is a mirror of the Raspberry Pi Foundation's \"Robotics With Raspberry Pi: Build and Program Your First Robot Buggy\" course on FutureLearn. We recommend that you take the free course on FutureLearn in order to access more features such as discussions about the course material, assistance from our course facilitators, and quizzes. If you are a teacher in England, sign up for Robotics With Raspberry Pi through teachcomputing.org to access a free upgrade, including unlimited access to the course and the ability to use the course as part of certification from the National Centre for Computing Education If you are not a teacher in England, sign up for Robotics With Raspberry Pi on FutureLearn Note that as the content hosted on this website is directly copied from the FutureLearn course, in some cases it will reference a comments section or other functionality which is not available on this website. All of the material in this course is licenced under the Open Government Licence and can therefore be reused and adapted, so long as it is properly attributed.","title":"Robotics With Raspberry Pi: Build and Program Your First Robot Buggy"},{"location":"#robotics-with-raspberry-pi-build-and-program-your-first-robot-buggy","text":"Build and program your first robot buggy using a Raspberry Pi, learning how to connect motors, add sensors and write algorithms. This site is a mirror of the Raspberry Pi Foundation's \"Robotics With Raspberry Pi: Build and Program Your First Robot Buggy\" course on FutureLearn. We recommend that you take the free course on FutureLearn in order to access more features such as discussions about the course material, assistance from our course facilitators, and quizzes. If you are a teacher in England, sign up for Robotics With Raspberry Pi through teachcomputing.org to access a free upgrade, including unlimited access to the course and the ability to use the course as part of certification from the National Centre for Computing Education If you are not a teacher in England, sign up for Robotics With Raspberry Pi on FutureLearn Note that as the content hosted on this website is directly copied from the FutureLearn course, in some cases it will reference a comments section or other functionality which is not available on this website. All of the material in this course is licenced under the Open Government Licence and can therefore be reused and adapted, so long as it is properly attributed.","title":"Robotics With Raspberry Pi: Build and Program Your First Robot Buggy"},{"location":"week-1/fl-progrobot-w1-activity/","text":"[comment]: # ( Is this step open? Y/N If so, short description of this step: Related links: Related files: ) Week one: Building a mobile robot Introduction to robotics Why is robotics important in the modern world? Connecting and programming motors Learn how to connect motors and program them using a Raspberry Pi. Building the buggy Build the chassis of your buggy and attach components to it. The end of week one Congratulations on completing week one of the course!","title":"Week one: Building a mobile robot"},{"location":"week-1/fl-progrobot-w1-activity/#week-one-building-a-mobile-robot","text":"","title":"Week one: Building a mobile robot"},{"location":"week-1/fl-progrobot-w1-activity/#introduction-to-robotics","text":"Why is robotics important in the modern world?","title":"Introduction to robotics"},{"location":"week-1/fl-progrobot-w1-activity/#connecting-and-programming-motors","text":"Learn how to connect motors and program them using a Raspberry Pi.","title":"Connecting and programming motors"},{"location":"week-1/fl-progrobot-w1-activity/#building-the-buggy","text":"Build the chassis of your buggy and attach components to it.","title":"Building the buggy"},{"location":"week-1/fl-progrobot-w1-activity/#the-end-of-week-one","text":"Congratulations on completing week one of the course!","title":"The end of week one"},{"location":"week-1/fl-progrobot-w1-step01/","text":"Resources Video Video subtitles Welcome to the course Welcome to Robotics With Raspberry Pi: Build and Program Your First Robot Buggy . Over this course you'll develop a robot buggy and program it. You'll start by making it move about, before programming it to react to sensor readings. By the end of the course you'll be able to make your buggy avoid obstacles and follow a line on the floor. What you will learn Over the next three weeks you will learn about: Using the GPIO pins on the Raspberry Pi for both input and output How to connect motors via a motorboard and control them using Python Attaching components to a chassis Using an ultrasonic distance sensor (UDS) to detect objects Using inputs to control the outputs of your robot How line sensors work How changing an algorithm can improve the performance of your robot What you will need This course requires you to have the following: Hardware Raspberry Pi 3B, 3B+, or 4 Motor controller board Two 3V\u20136V DC motors Two wheels Ball caster (unless using more than two wheels) Ultrasonic distance sensor (one or two) Two line-following sensors Jumper leads (female-to-female and male-to-female) or wire AA battery holder (for four AA batteries) Four AA batteries A USB powerbank (to power the Raspberry Pi) Soldering iron and solder Wire strippers Scissors Screwdriver A small cardboard box for the chassis (can be plastic, wood, metal, etc.) The hardware components (including suggested models and types) and tools are listed in this document , although alternatives are also available. You can also view most of the required components on this AliExpress Wish List , but they can be ordered and bought from many other suppliers. Software The latest version of the Raspbian operating system An IDE of your choice Additional extras Adhesives (duct tape/electrical tape, putty, glue, etc.) Cable ties or Velcro-type straps GPIO reference card Using a soldering iron can be a bit daunting at first, but whether you are new to soldering or a veteran, this Getting started with soldering resource will give you some quick tips and tricks. A Raspberry Pi model 3B or above is recommended, as you can connect to it over WiFi or Bluetooth without an adapter; this will help when programming the robot buggy. The ultrasonic distance sensors and line-following sensors are required for weeks two and three respectively. A ball caster is necessary if your robot has only two wheels; it will act as a third wheel so that the robot is balanced and can move freely. Choosing a programming environment I recommend using an Integrated Development Environment (IDE) during this course to create, run, and test your Python programs. The IDE I will be using is Mu, which is pre-installed on most Raspberry Pis. Mu is also available at the website Code with Mu along with instructions on how to install Mu on a Raspberry Pi . If you experience problems or would just like to know more about Mu, have a look at Raspberry Pi\u2019s Getting started with Mu guide. Week one In week one of the course you will attach the motors and get your robot buggy moving. What part of the course are you most looking forward to? Share your thoughts in the comments.","title":"Welcome to the course"},{"location":"week-1/fl-progrobot-w1-step01/#welcome-to-the-course","text":"Welcome to Robotics With Raspberry Pi: Build and Program Your First Robot Buggy . Over this course you'll develop a robot buggy and program it. You'll start by making it move about, before programming it to react to sensor readings. By the end of the course you'll be able to make your buggy avoid obstacles and follow a line on the floor.","title":"Welcome to the course"},{"location":"week-1/fl-progrobot-w1-step01/#what-you-will-learn","text":"Over the next three weeks you will learn about: Using the GPIO pins on the Raspberry Pi for both input and output How to connect motors via a motorboard and control them using Python Attaching components to a chassis Using an ultrasonic distance sensor (UDS) to detect objects Using inputs to control the outputs of your robot How line sensors work How changing an algorithm can improve the performance of your robot","title":"What you will learn"},{"location":"week-1/fl-progrobot-w1-step01/#what-you-will-need","text":"This course requires you to have the following:","title":"What you will need"},{"location":"week-1/fl-progrobot-w1-step01/#hardware","text":"Raspberry Pi 3B, 3B+, or 4 Motor controller board Two 3V\u20136V DC motors Two wheels Ball caster (unless using more than two wheels) Ultrasonic distance sensor (one or two) Two line-following sensors Jumper leads (female-to-female and male-to-female) or wire AA battery holder (for four AA batteries) Four AA batteries A USB powerbank (to power the Raspberry Pi) Soldering iron and solder Wire strippers Scissors Screwdriver A small cardboard box for the chassis (can be plastic, wood, metal, etc.) The hardware components (including suggested models and types) and tools are listed in this document , although alternatives are also available. You can also view most of the required components on this AliExpress Wish List , but they can be ordered and bought from many other suppliers.","title":"Hardware"},{"location":"week-1/fl-progrobot-w1-step01/#software","text":"The latest version of the Raspbian operating system An IDE of your choice","title":"Software"},{"location":"week-1/fl-progrobot-w1-step01/#additional-extras","text":"Adhesives (duct tape/electrical tape, putty, glue, etc.) Cable ties or Velcro-type straps GPIO reference card Using a soldering iron can be a bit daunting at first, but whether you are new to soldering or a veteran, this Getting started with soldering resource will give you some quick tips and tricks. A Raspberry Pi model 3B or above is recommended, as you can connect to it over WiFi or Bluetooth without an adapter; this will help when programming the robot buggy. The ultrasonic distance sensors and line-following sensors are required for weeks two and three respectively. A ball caster is necessary if your robot has only two wheels; it will act as a third wheel so that the robot is balanced and can move freely.","title":"Additional extras"},{"location":"week-1/fl-progrobot-w1-step01/#choosing-a-programming-environment","text":"I recommend using an Integrated Development Environment (IDE) during this course to create, run, and test your Python programs. The IDE I will be using is Mu, which is pre-installed on most Raspberry Pis. Mu is also available at the website Code with Mu along with instructions on how to install Mu on a Raspberry Pi . If you experience problems or would just like to know more about Mu, have a look at Raspberry Pi\u2019s Getting started with Mu guide.","title":"Choosing a programming environment"},{"location":"week-1/fl-progrobot-w1-step01/#week-one","text":"In week one of the course you will attach the motors and get your robot buggy moving. What part of the course are you most looking forward to? Share your thoughts in the comments.","title":"Week one"},{"location":"week-1/fl-progrobot-w1-step02/","text":"Meet the team and your fellow learners Before you begin your course, we would like to take this opportunity to introduce you to the team here at the Raspberry Pi Foundation. We are a charity that works to put the power of computing and digital making into the hands of people all over the world. We do this so that more people are able to harness the power of digital technologies for work, to solve problems that matter to them, and to express themselves creatively. Here are some of the things we currently offer to educators: Computing clubs in your school or local community centre Educational events for students and teachers High-quality, peer-reviewed resources written by experienced teachers Fun and engaging computing tutorials on our projects site Online training courses like this one Chief learning officer: Sue Sentance \"The team here at Raspberry Pi feel passionately that everybody should have access to a high-quality computing education. These courses, part of the NCCE, and all the other offerings from Raspberry Pi, are built to equip you with the skills and knowledge you need to succeed. Whether you are an educator looking to improve your subject knowledge, a hobbyist who is interested in the subject matter, or even a student yourself, we hope you enjoy learning with us. We are here to support you, so let us know what you like and how we could do better in the comments or through the feedback forms provided.\" Meet your course facilitators Our team is made up of both former and current teachers of computing, with loads of classroom experience. Alex Parry is a Learning Manager at the Raspberry Pi Foundation and Computer Science teacher. When not coding, he enjoys table tennis, gaming and going for walks in the woods. Nina Syzmor is a Translation Community Manager at Raspberry Pi. She's a former translator herself, and used to teach languages and translation at a university. She's keen on breaking down language barriers in computing education. In her free time, she likes to drink coffee, eat cake, and do crafty things. We care about supporting teachers to achieve their goals, and so we've made it our goal to provide you with the best digital learning experience possible \u2014 for free. That means being available to answer questions and give you feedback throughout the course. Check out our facilitation team's introductions in the comments section below. Introduce yourself The best way to learn is by collaborating with other amazing people. With this in mind, please introduce yourself to your fellow learners by commenting at the bottom of the page. Think about answering these questions: What made you take the course? What are you hoping to learn? What steps will you take to ensure that you will complete the course, for example by setting aside some 'do not disturb' time in your schedule each week, or by inviting a colleague to take it with you? Together we will build a community of educators who share ideas and inspire each other to learn along the way.","title":"Meet the team and your fellow learners"},{"location":"week-1/fl-progrobot-w1-step02/#meet-the-team-and-your-fellow-learners","text":"Before you begin your course, we would like to take this opportunity to introduce you to the team here at the Raspberry Pi Foundation. We are a charity that works to put the power of computing and digital making into the hands of people all over the world. We do this so that more people are able to harness the power of digital technologies for work, to solve problems that matter to them, and to express themselves creatively. Here are some of the things we currently offer to educators: Computing clubs in your school or local community centre Educational events for students and teachers High-quality, peer-reviewed resources written by experienced teachers Fun and engaging computing tutorials on our projects site Online training courses like this one","title":"Meet the team and your fellow learners"},{"location":"week-1/fl-progrobot-w1-step02/#chief-learning-officer-sue-sentance","text":"\"The team here at Raspberry Pi feel passionately that everybody should have access to a high-quality computing education. These courses, part of the NCCE, and all the other offerings from Raspberry Pi, are built to equip you with the skills and knowledge you need to succeed. Whether you are an educator looking to improve your subject knowledge, a hobbyist who is interested in the subject matter, or even a student yourself, we hope you enjoy learning with us. We are here to support you, so let us know what you like and how we could do better in the comments or through the feedback forms provided.\"","title":"Chief learning officer: Sue Sentance"},{"location":"week-1/fl-progrobot-w1-step02/#meet-your-course-facilitators","text":"Our team is made up of both former and current teachers of computing, with loads of classroom experience. Alex Parry is a Learning Manager at the Raspberry Pi Foundation and Computer Science teacher. When not coding, he enjoys table tennis, gaming and going for walks in the woods. Nina Syzmor is a Translation Community Manager at Raspberry Pi. She's a former translator herself, and used to teach languages and translation at a university. She's keen on breaking down language barriers in computing education. In her free time, she likes to drink coffee, eat cake, and do crafty things. We care about supporting teachers to achieve their goals, and so we've made it our goal to provide you with the best digital learning experience possible \u2014 for free. That means being available to answer questions and give you feedback throughout the course. Check out our facilitation team's introductions in the comments section below.","title":"Meet your course facilitators"},{"location":"week-1/fl-progrobot-w1-step02/#introduce-yourself","text":"The best way to learn is by collaborating with other amazing people. With this in mind, please introduce yourself to your fellow learners by commenting at the bottom of the page. Think about answering these questions: What made you take the course? What are you hoping to learn? What steps will you take to ensure that you will complete the course, for example by setting aside some 'do not disturb' time in your schedule each week, or by inviting a colleague to take it with you? Together we will build a community of educators who share ideas and inspire each other to learn along the way.","title":"Introduce yourself"},{"location":"week-1/fl-progrobot-w1-step03/","text":"The world of robotics Robots are an integral part of modern life and are set to be even more prominent in the future. They come in all shapes and sizes and are able to perform a wide range of tasks, from building cars to landing on Mars. But defining what a robot actually is can be tricky; ask five roboticists and you are likely to get five different answers! Robots can vary massively, from fixed-location robots making tiny, precise movements to manufacture microchips, to humanoid robots that can walk around different environments. What nearly all robots can do, though, is these three things: Sense Process Act Making sense of the environment Robots are able to sense the physical world, so they can perform actions accordingly. They often use sensors to detect the movement of their own components, as well as detecting other objects nearby. For example, a robotic arm in a smartphone factory may use a motion sensor to keep track of its position, and may use a pressure sensor to ensure it holds components with the correct force, to avoid dropping or crushing them. Between 1966 and 1972, researchers at Stanford University developed Shakey, the first truly mobile robot with the ability to sense its environment. It was capable of navigating around obstacles by using a TV camera and an infrared rangefinder to scan items in front of it. Shakey also had whisker-like feelers to determine if it was touching another object. Instead of relying on a preprogrammed set of instructions, Shakey could piece together simple commands to perform more complex tasks, as well as remembering and adjusting these actions for future tasks. This was integral to Shakey's ability to navigate spaces effectively, which in turn helped to advance artificial intelligence and pathfinding. Over the years, new and improved sensors have increased robots' abilities to understand the environment. For example, self-driving cars use light detection and ranging (LIDAR) sensors, which use pulses of laser light to measure the distance to other objects in order to build a 3D model of the world. All this extra information means that robots require more processing power so that they can process data in a quick and timely manner. The power of processing Nearly all robots need a device, such as a computer or microcontroller, to receive data from sensors and other components. This device will need to process the data into meaningful information that can then be used to communicate instructions. In this course your buggy will be based around a Raspberry Pi, a single-board computer that allows a wide range of components to be connected to it. You'll attach the different components of the buggy to the Raspberry Pi and program it to run autonomously. Automation in action The ability to process data and act on this information almost instantly, with minimal human interaction, is one of the major advancements of robotics, and indeed technology, in the last few decades. Most robots will be able to perform some actions autonomously, from a robotic arm that twists the lids onto jars of jam in an assembly line to a drone that is able to return to the location it took off from. The level of autonomy needed depends on how the robot is designed to interact with the world. Some are closely controlled by human operators, such as medical robots that assist surgeons with performing operations. These robots help surgeons to make very precise incisions that would be difficult without this assistance, and can sometimes even allow surgeons to operate remotely. Other robots are much more autonomous and rely on minimal human interaction. A robot vacuum cleaner will use sensors to move around the room while avoiding the furniture, and will map the areas it has visited to ensure it has covered the entire room. Some even have the ability to find a charging station and empty themselves automatically into a designated bin. Many robots are somewhere in the middle, having the ability to automate some tasks, but also requiring a small amount of human interaction. These semi-autonomous robots are optimal for activities such as navigating contaminated places that would be dangerous for people. It is possible for operators to take over the decision-making from the robot and perform certain actions remotely that the robot may not be programmed to perform. Discussion What are some of the robots that you interact with, either directly or indirectly? Which area do you think robotics will have the biggest impact on in the future? Why is that? Share your thoughts in the comments section below.","title":"The world of robotics"},{"location":"week-1/fl-progrobot-w1-step03/#the-world-of-robotics","text":"Robots are an integral part of modern life and are set to be even more prominent in the future. They come in all shapes and sizes and are able to perform a wide range of tasks, from building cars to landing on Mars. But defining what a robot actually is can be tricky; ask five roboticists and you are likely to get five different answers! Robots can vary massively, from fixed-location robots making tiny, precise movements to manufacture microchips, to humanoid robots that can walk around different environments. What nearly all robots can do, though, is these three things: Sense Process Act","title":"The world of robotics"},{"location":"week-1/fl-progrobot-w1-step03/#making-sense-of-the-environment","text":"Robots are able to sense the physical world, so they can perform actions accordingly. They often use sensors to detect the movement of their own components, as well as detecting other objects nearby. For example, a robotic arm in a smartphone factory may use a motion sensor to keep track of its position, and may use a pressure sensor to ensure it holds components with the correct force, to avoid dropping or crushing them. Between 1966 and 1972, researchers at Stanford University developed Shakey, the first truly mobile robot with the ability to sense its environment. It was capable of navigating around obstacles by using a TV camera and an infrared rangefinder to scan items in front of it. Shakey also had whisker-like feelers to determine if it was touching another object. Instead of relying on a preprogrammed set of instructions, Shakey could piece together simple commands to perform more complex tasks, as well as remembering and adjusting these actions for future tasks. This was integral to Shakey's ability to navigate spaces effectively, which in turn helped to advance artificial intelligence and pathfinding. Over the years, new and improved sensors have increased robots' abilities to understand the environment. For example, self-driving cars use light detection and ranging (LIDAR) sensors, which use pulses of laser light to measure the distance to other objects in order to build a 3D model of the world. All this extra information means that robots require more processing power so that they can process data in a quick and timely manner.","title":"Making sense of the environment"},{"location":"week-1/fl-progrobot-w1-step03/#the-power-of-processing","text":"Nearly all robots need a device, such as a computer or microcontroller, to receive data from sensors and other components. This device will need to process the data into meaningful information that can then be used to communicate instructions. In this course your buggy will be based around a Raspberry Pi, a single-board computer that allows a wide range of components to be connected to it. You'll attach the different components of the buggy to the Raspberry Pi and program it to run autonomously.","title":"The power of processing"},{"location":"week-1/fl-progrobot-w1-step03/#automation-in-action","text":"The ability to process data and act on this information almost instantly, with minimal human interaction, is one of the major advancements of robotics, and indeed technology, in the last few decades. Most robots will be able to perform some actions autonomously, from a robotic arm that twists the lids onto jars of jam in an assembly line to a drone that is able to return to the location it took off from. The level of autonomy needed depends on how the robot is designed to interact with the world. Some are closely controlled by human operators, such as medical robots that assist surgeons with performing operations. These robots help surgeons to make very precise incisions that would be difficult without this assistance, and can sometimes even allow surgeons to operate remotely. Other robots are much more autonomous and rely on minimal human interaction. A robot vacuum cleaner will use sensors to move around the room while avoiding the furniture, and will map the areas it has visited to ensure it has covered the entire room. Some even have the ability to find a charging station and empty themselves automatically into a designated bin. Many robots are somewhere in the middle, having the ability to automate some tasks, but also requiring a small amount of human interaction. These semi-autonomous robots are optimal for activities such as navigating contaminated places that would be dangerous for people. It is possible for operators to take over the decision-making from the robot and perform certain actions remotely that the robot may not be programmed to perform.","title":"Automation in action"},{"location":"week-1/fl-progrobot-w1-step03/#discussion","text":"What are some of the robots that you interact with, either directly or indirectly? Which area do you think robotics will have the biggest impact on in the future? Why is that? Share your thoughts in the comments section below.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step04/","text":"Raspberry Pi and General-Purpose Input/Output Robots are able to sense and interact with the environment through a wide range of components. So that a robot can make decisions and perform actions, it uses a processor to receive information from and send signals back to the other components. A standard interface for connecting a single-board computer or microprocessor to other components is through General-Purpose Input/Output (GPIO) pins. Controlling robots using the Raspberry Pi Raspberry Pi computers are wonderfully diverse in what they can do. Among the many applications they can be used for, robotics is one of the most exciting and powerful. Each model of the Raspberry Pi has a set of General-Purpose Input/Output (GPIO) pins along the top edge of the board. These can be used for connecting and communicating with all manner of electronic components, acting as a physical interface between the Raspberry Pi and the outside world. Using the pins, you can program the Raspberry Pi to switch components on and off (output), or receive data from sensors and switches (input). Raspberry Pi models Most models of the Raspberry Pi have a 40-pin header, as shown in the image above. Of the 40 pins, 26 are GPIO pins and the others are power or ground pins (plus two ID EEPROM pins, which you should not play with unless you know your stuff!). Any of the GPIO pins can be designated (in software) as an input or output pin and used for a wide range of purposes; whether it is turning on an LED, driving a motor, or sending data to another device, the possibilities are almost endless. Early models of the Raspberry Pi A and B have a shorter header with 26 pins, as shown below. The Raspberry Pi Zero models have unpopulated pins (apart from the Raspberry Pi Zero WH) so there are holes where the GPIO header is located instead of physical pins. This means you need to add a header that includes the pins yourself. Although it is possible to create a robot buggy with most models of Raspberry Pi, I recommend using a Raspberry Pi 3B, 3B+, or 4. These models allow you to program the Raspberry Pi easily and connect it to another computer or even a smartphone by using the inbuilt WiFi or Bluetooth, rather than needing to plug the Pi physically into a screen or a keyboard and mouse. GPIO pin numbering When programming the GPIO pins, there are two different ways to refer to them: GPIO numbering and physical numbering . Throughout this course (and in all our resources) we will refer to the pins using the GPIO numbering scheme. These are the GPIO pins as the computer sees them. The numbering of the GPIO pins is not in numerical order, instead relating to the numbering on the CPU of the Raspberry Pi, so there is no easy way to remember them. However, you can use a reference board that fits over the pins, a printed reference (like the image above), or a website guide to the GPIO pins to help you. Voltages The voltage of a pin is labelled on the reference guide. There are two 5V pins and two 3V3 pins, as well as a number of ground pins (0V), which are unconfigurable. The remaining pins are all general-purpose 3V3 pins, meaning that the outputs are set to 3.3 volts and the inputs are tolerant of 3.3 volts. A GPIO pin designated as an output pin can be set to high (3.3V) or low (0V). Components are usually attached so that setting the output to high will allow current to flow to them, while setting the output to low won't. A GPIO pin that is designated as an input will allow a signal to be received by the Raspberry Pi. The threshold between a high and a low signal is around 1.8V. A voltage between 1.8V and 3.3V will be read by the Raspberry Pi as high; anything lower than 1.8V will be read as low. Do not allow an input voltage above 3.3V, or else you will fry your Pi! A word of caution While connecting most components to the GPIO pins is perfectly safe, it's important to be careful how you wire things up, or you could damage the Raspberry Pi or the components. A few pieces of general advice: Do not attach 3V3 components directly to a 5V pin on the Raspberry Pi, or you may damage the component or your device Certain components, such as LEDs, should have resistors to limit the current passing through them Do not connect motors directly to the GPIO pins; instead, use a motor controller board or an H-bridge circuit In the next step, you will look at how to connect the motors to the motor controller board.","title":"Raspberry Pi and General-Purpose Input/Output"},{"location":"week-1/fl-progrobot-w1-step04/#raspberry-pi-and-general-purpose-inputoutput","text":"Robots are able to sense and interact with the environment through a wide range of components. So that a robot can make decisions and perform actions, it uses a processor to receive information from and send signals back to the other components. A standard interface for connecting a single-board computer or microprocessor to other components is through General-Purpose Input/Output (GPIO) pins.","title":"Raspberry Pi and General-Purpose Input/Output"},{"location":"week-1/fl-progrobot-w1-step04/#controlling-robots-using-the-raspberry-pi","text":"Raspberry Pi computers are wonderfully diverse in what they can do. Among the many applications they can be used for, robotics is one of the most exciting and powerful. Each model of the Raspberry Pi has a set of General-Purpose Input/Output (GPIO) pins along the top edge of the board. These can be used for connecting and communicating with all manner of electronic components, acting as a physical interface between the Raspberry Pi and the outside world. Using the pins, you can program the Raspberry Pi to switch components on and off (output), or receive data from sensors and switches (input).","title":"Controlling robots using the Raspberry Pi"},{"location":"week-1/fl-progrobot-w1-step04/#raspberry-pi-models","text":"Most models of the Raspberry Pi have a 40-pin header, as shown in the image above. Of the 40 pins, 26 are GPIO pins and the others are power or ground pins (plus two ID EEPROM pins, which you should not play with unless you know your stuff!). Any of the GPIO pins can be designated (in software) as an input or output pin and used for a wide range of purposes; whether it is turning on an LED, driving a motor, or sending data to another device, the possibilities are almost endless. Early models of the Raspberry Pi A and B have a shorter header with 26 pins, as shown below. The Raspberry Pi Zero models have unpopulated pins (apart from the Raspberry Pi Zero WH) so there are holes where the GPIO header is located instead of physical pins. This means you need to add a header that includes the pins yourself. Although it is possible to create a robot buggy with most models of Raspberry Pi, I recommend using a Raspberry Pi 3B, 3B+, or 4. These models allow you to program the Raspberry Pi easily and connect it to another computer or even a smartphone by using the inbuilt WiFi or Bluetooth, rather than needing to plug the Pi physically into a screen or a keyboard and mouse.","title":"Raspberry Pi models"},{"location":"week-1/fl-progrobot-w1-step04/#gpio-pin-numbering","text":"When programming the GPIO pins, there are two different ways to refer to them: GPIO numbering and physical numbering . Throughout this course (and in all our resources) we will refer to the pins using the GPIO numbering scheme. These are the GPIO pins as the computer sees them. The numbering of the GPIO pins is not in numerical order, instead relating to the numbering on the CPU of the Raspberry Pi, so there is no easy way to remember them. However, you can use a reference board that fits over the pins, a printed reference (like the image above), or a website guide to the GPIO pins to help you.","title":"GPIO pin numbering"},{"location":"week-1/fl-progrobot-w1-step04/#voltages","text":"The voltage of a pin is labelled on the reference guide. There are two 5V pins and two 3V3 pins, as well as a number of ground pins (0V), which are unconfigurable. The remaining pins are all general-purpose 3V3 pins, meaning that the outputs are set to 3.3 volts and the inputs are tolerant of 3.3 volts. A GPIO pin designated as an output pin can be set to high (3.3V) or low (0V). Components are usually attached so that setting the output to high will allow current to flow to them, while setting the output to low won't. A GPIO pin that is designated as an input will allow a signal to be received by the Raspberry Pi. The threshold between a high and a low signal is around 1.8V. A voltage between 1.8V and 3.3V will be read by the Raspberry Pi as high; anything lower than 1.8V will be read as low. Do not allow an input voltage above 3.3V, or else you will fry your Pi!","title":"Voltages"},{"location":"week-1/fl-progrobot-w1-step04/#a-word-of-caution","text":"While connecting most components to the GPIO pins is perfectly safe, it's important to be careful how you wire things up, or you could damage the Raspberry Pi or the components. A few pieces of general advice: Do not attach 3V3 components directly to a 5V pin on the Raspberry Pi, or you may damage the component or your device Certain components, such as LEDs, should have resistors to limit the current passing through them Do not connect motors directly to the GPIO pins; instead, use a motor controller board or an H-bridge circuit In the next step, you will look at how to connect the motors to the motor controller board.","title":"A word of caution"},{"location":"week-1/fl-progrobot-w1-step05/","text":"Resources Video Video subtitles Connecting a motor to the motor controller In this step you will start by connecting the motors to the motor controller board, before connecting the battery holder to the motor controller. The instructions are for a L298N dual H-bridge DC stepper motor driver controller board, and they will be similar for most motor controller boards. Check the documentation for your board if you are using a different one. What you will need For this step you will need the following items: Motor controller board Two 3V-6V DC motors Four jumper leads (male-to-male or female-to-male) or wire Screwdriver You may also need: Soldering iron and solder Wire strippers Scissors Tape Using a soldering iron can be a bit daunting at first, but whether you are new to soldering or a veteran, this Getting started with soldering resource will give you some quick tips and tricks. The DC motors Most DC motors do not come with wires attached to them, which means you will need to attach your own, using solder. Preparing the wires You will need two wires for each DC motor, to connect it to the motor controller board. Alternatively, you can use wire strippers to strip both ends of the jumper leads, to expose the bare wire for attaching to each of the motors. A demonstration of how to strip a wire with wire strippers can be seen in this video . Remove the soft plastic clip from the motors so that the wires can be attached. You can use a flathead screwdriver to help remove the clip. Thread the bare wire through the contact on the motor. Top tip: It may be easier to solder the wire to the contact on the motor if you bend the wire once it has passed through the contact. Soldering the wires Turn on the soldering iron and wait for it to heat up. Clean the soldering iron tip before using it; you can use a damp sponge or damp cloth to remove any residue while the iron is hot. Heat the contact on the motor with the soldering iron for a second or two. Keeping the soldering iron on the contact, touch the end of the solder to the soldering iron tip until the solder melts. Stop applying solder once the contact and wire are connected by the solder. Wait for a minute or two for the solder to cool and then gently try to move the wire, to test whether it is securely attached to the contact. If the wire moves, you can either reheat the applied solder with the soldering iron and realign the wire, or apply more solder to the connection. Try not to touch with the soldering iron the plastic coating of the wires or any plastic between the two contacts, or the plastic will melt and start to smoke. More tips and guidance can be found in this soldering tutorial . Once the wires have been soldered to the motors securely, trim the end of the wires with scissors. If the wires accidentally touch the metal casing while power is running, this can short the circuit and stop the motor from receiving consistent power. Reattach the plastic clips to the motors. It's also a good idea to wrap the end of the motors where you attached the wire in tape, to protect the connection and help keep the solder in good condition. Connect the motors to the motor controller board A motor controller board will usually have screw terminals for connecting a motor to it. A DC motor needs two screw terminals for it to work, and a servo motor needs four terminals. The four OUT terminals on the board I am using are circled in green below. A DC motor needs to use two wires so that it can turn forwards and backwards. Sending a high signal to one wire and a low signal to the other wire will turn the motor in one direction, and swapping the signals around will turn the motor in the other direction. Using a screwdriver, loosen the screws in the terminal blocks labelled OUT1 , OUT2 , OUT3 , and OUT4 . Have a look at the documentation for your board if your labels are different. Strip the ends of the wires; you can snip off the ends if you need to. Insert the stripped ends of one motor into the OUT1 and OUT2 terminals and the stripped ends of the second motor into the OUT3 and OUT4 terminals. Tighten the screws so the wires are secured firmly in the terminal blocks. Discussion Did you have any issues connecting the motors to the motor controller? Do you need help with anything that isn't working properly? If so, let us know in the comments below.","title":"Connecting a motor to the motor controller"},{"location":"week-1/fl-progrobot-w1-step05/#connecting-a-motor-to-the-motor-controller","text":"In this step you will start by connecting the motors to the motor controller board, before connecting the battery holder to the motor controller. The instructions are for a L298N dual H-bridge DC stepper motor driver controller board, and they will be similar for most motor controller boards. Check the documentation for your board if you are using a different one.","title":"Connecting a motor to the motor controller"},{"location":"week-1/fl-progrobot-w1-step05/#what-you-will-need","text":"For this step you will need the following items: Motor controller board Two 3V-6V DC motors Four jumper leads (male-to-male or female-to-male) or wire Screwdriver You may also need: Soldering iron and solder Wire strippers Scissors Tape Using a soldering iron can be a bit daunting at first, but whether you are new to soldering or a veteran, this Getting started with soldering resource will give you some quick tips and tricks.","title":"What you will need"},{"location":"week-1/fl-progrobot-w1-step05/#the-dc-motors","text":"Most DC motors do not come with wires attached to them, which means you will need to attach your own, using solder.","title":"The DC motors"},{"location":"week-1/fl-progrobot-w1-step05/#preparing-the-wires","text":"You will need two wires for each DC motor, to connect it to the motor controller board. Alternatively, you can use wire strippers to strip both ends of the jumper leads, to expose the bare wire for attaching to each of the motors. A demonstration of how to strip a wire with wire strippers can be seen in this video . Remove the soft plastic clip from the motors so that the wires can be attached. You can use a flathead screwdriver to help remove the clip. Thread the bare wire through the contact on the motor. Top tip: It may be easier to solder the wire to the contact on the motor if you bend the wire once it has passed through the contact.","title":"Preparing the wires"},{"location":"week-1/fl-progrobot-w1-step05/#soldering-the-wires","text":"Turn on the soldering iron and wait for it to heat up. Clean the soldering iron tip before using it; you can use a damp sponge or damp cloth to remove any residue while the iron is hot. Heat the contact on the motor with the soldering iron for a second or two. Keeping the soldering iron on the contact, touch the end of the solder to the soldering iron tip until the solder melts. Stop applying solder once the contact and wire are connected by the solder. Wait for a minute or two for the solder to cool and then gently try to move the wire, to test whether it is securely attached to the contact. If the wire moves, you can either reheat the applied solder with the soldering iron and realign the wire, or apply more solder to the connection. Try not to touch with the soldering iron the plastic coating of the wires or any plastic between the two contacts, or the plastic will melt and start to smoke. More tips and guidance can be found in this soldering tutorial . Once the wires have been soldered to the motors securely, trim the end of the wires with scissors. If the wires accidentally touch the metal casing while power is running, this can short the circuit and stop the motor from receiving consistent power. Reattach the plastic clips to the motors. It's also a good idea to wrap the end of the motors where you attached the wire in tape, to protect the connection and help keep the solder in good condition.","title":"Soldering the wires"},{"location":"week-1/fl-progrobot-w1-step05/#connect-the-motors-to-the-motor-controller-board","text":"A motor controller board will usually have screw terminals for connecting a motor to it. A DC motor needs two screw terminals for it to work, and a servo motor needs four terminals. The four OUT terminals on the board I am using are circled in green below. A DC motor needs to use two wires so that it can turn forwards and backwards. Sending a high signal to one wire and a low signal to the other wire will turn the motor in one direction, and swapping the signals around will turn the motor in the other direction. Using a screwdriver, loosen the screws in the terminal blocks labelled OUT1 , OUT2 , OUT3 , and OUT4 . Have a look at the documentation for your board if your labels are different. Strip the ends of the wires; you can snip off the ends if you need to. Insert the stripped ends of one motor into the OUT1 and OUT2 terminals and the stripped ends of the second motor into the OUT3 and OUT4 terminals. Tighten the screws so the wires are secured firmly in the terminal blocks.","title":"Connect the motors to the motor controller board"},{"location":"week-1/fl-progrobot-w1-step05/#discussion","text":"Did you have any issues connecting the motors to the motor controller? Do you need help with anything that isn't working properly? If so, let us know in the comments below.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step06/","text":"Resources Video Video subtitles Connecting the Raspberry Pi and battery pack to the motorboard Your next step is to connect the motorboard to the GPIO pins on the Raspberry Pi, and to the battery pack. This will allow you to power the motorboard and control the motors using the Raspberry Pi. What you will need Raspberry Pi Motor controller board (wired up to the DC motors) AA battery holder for four AA batteries Four AA batteries Five jumper leads (female-to-female) Screwdriver You may also need: GPIO reference card Connect the battery pack to the motorboard The motors require more power than the Raspberry Pi can provide. Therefore, you will use four AA batteries to power them. The battery pack should include two wires: one red and one black. The red wire is for the positive terminal and needs to be inserted into the VCC terminal block if it is present, or the 'voltage in' terminal block labelled +12V otherwise. The black wire is the ground wire and must be inserted into the GND terminal to complete the circuit. Make sure all the screws of the terminal blocks are tightened securely. Insert the four AA batteries into the battery pack and if it has a switch, turn it on. Most motor controllers have a red LED that lights up to show that it is powered on. If the LED is not lit up, the wires may not be connected properly. Also check that your battery pack is full, and the batteries are the right way around. Receiving input These instructions are for a L298N dual H-bridge DC stepper motor driver controller board, and they will be similar for most motor controller boards. Other boards may connect differently to the one that I'm using, and some boards can simply be placed onto the Raspberry Pi GPIO pins as a HAT. Check the documentation for your board if you are using a different one. On this motor controller board there are pins labelled IN1 , IN2 , IN3 , and IN4 . Some motorboards also have one or two GND (ground) pins next to the IN pins, but this board does not. Which GPIO pins you use on your Pi is up to you; I have used GPIO 7 , 8 , 9 , and 10 . However, if you use different GPIO pins, make sure you remember which ones, as you will need to refer to them in the code. Use five female-to-female jumper leads to connect the Raspberry Pi GPIO pins to the pins on the motor controller board. Each DC motor will need to need to use two IN pins to connect to the Raspberry Pi, so that the motor can turn in both directions. You will also need one GND pin to complete the circuits; this can be the same pin for both motors. GPIO pin Connects to Board pin 7 <\u2013> IN1 8 <\u2013> IN2 9 <\u2013> IN3 10 <\u2013> IN4 GND <\u2013> GND If your motorboard does not have a GND pin, use the terminal block that the battery pack also uses. Strip the end of the wire for the GND pin and secure it into the GND terminal block that your battery pack feeds into. There will now be two wires fed into the GND block: one from the battery pack and one from the Raspberry Pi. Powering the Raspberry Pi The Raspberry Pi will need its own source of power. For testing, the Raspberry Pi can be plugged directly into the mains power supply. However, when you come to building the body of the buggy and making it move, the Raspberry Pi will need a mobile source of power. A USB powerbank is a good choice, as it will be fairly light for the chassis to carry, just make sure it is capable of powering the model of Raspberry Pi that you are using. Setting up your Raspberry Pi If you are not familiar with setting up a Raspberry Pi and using it, follow this guide to Getting started with Raspberry Pi . The programming language I will be using in this course is Python together with a library called GPIO Zero , which provides an accessible way to control components through the GPIO pins. Python and GPIO Zero will be installed by default if your Raspberry Pi is running the Raspbian operating system. Follow this guide to Installing GPIO Zero if you are using Raspbian Lite or another operating system. If you would like to control your Raspberry Pi remotely from another computer, check out our guide to Creating a virtual desktop using VNC Server . Discussion Did you have any problems connecting the motorboard to the Raspberry Pi or to the battery pack? What type of power supply are you using for your Raspberry Pi? Leave your answers in the comments section below.","title":"Connecting the Raspberry Pi and battery pack to the motorboard"},{"location":"week-1/fl-progrobot-w1-step06/#connecting-the-raspberry-pi-and-battery-pack-to-the-motorboard","text":"Your next step is to connect the motorboard to the GPIO pins on the Raspberry Pi, and to the battery pack. This will allow you to power the motorboard and control the motors using the Raspberry Pi.","title":"Connecting the Raspberry Pi and battery pack to the motorboard"},{"location":"week-1/fl-progrobot-w1-step06/#what-you-will-need","text":"Raspberry Pi Motor controller board (wired up to the DC motors) AA battery holder for four AA batteries Four AA batteries Five jumper leads (female-to-female) Screwdriver You may also need: GPIO reference card","title":"What you will need"},{"location":"week-1/fl-progrobot-w1-step06/#connect-the-battery-pack-to-the-motorboard","text":"The motors require more power than the Raspberry Pi can provide. Therefore, you will use four AA batteries to power them. The battery pack should include two wires: one red and one black. The red wire is for the positive terminal and needs to be inserted into the VCC terminal block if it is present, or the 'voltage in' terminal block labelled +12V otherwise. The black wire is the ground wire and must be inserted into the GND terminal to complete the circuit. Make sure all the screws of the terminal blocks are tightened securely. Insert the four AA batteries into the battery pack and if it has a switch, turn it on. Most motor controllers have a red LED that lights up to show that it is powered on. If the LED is not lit up, the wires may not be connected properly. Also check that your battery pack is full, and the batteries are the right way around.","title":"Connect the battery pack to the motorboard"},{"location":"week-1/fl-progrobot-w1-step06/#receiving-input","text":"These instructions are for a L298N dual H-bridge DC stepper motor driver controller board, and they will be similar for most motor controller boards. Other boards may connect differently to the one that I'm using, and some boards can simply be placed onto the Raspberry Pi GPIO pins as a HAT. Check the documentation for your board if you are using a different one. On this motor controller board there are pins labelled IN1 , IN2 , IN3 , and IN4 . Some motorboards also have one or two GND (ground) pins next to the IN pins, but this board does not. Which GPIO pins you use on your Pi is up to you; I have used GPIO 7 , 8 , 9 , and 10 . However, if you use different GPIO pins, make sure you remember which ones, as you will need to refer to them in the code. Use five female-to-female jumper leads to connect the Raspberry Pi GPIO pins to the pins on the motor controller board. Each DC motor will need to need to use two IN pins to connect to the Raspberry Pi, so that the motor can turn in both directions. You will also need one GND pin to complete the circuits; this can be the same pin for both motors. GPIO pin Connects to Board pin 7 <\u2013> IN1 8 <\u2013> IN2 9 <\u2013> IN3 10 <\u2013> IN4 GND <\u2013> GND If your motorboard does not have a GND pin, use the terminal block that the battery pack also uses. Strip the end of the wire for the GND pin and secure it into the GND terminal block that your battery pack feeds into. There will now be two wires fed into the GND block: one from the battery pack and one from the Raspberry Pi.","title":"Receiving input"},{"location":"week-1/fl-progrobot-w1-step06/#powering-the-raspberry-pi","text":"The Raspberry Pi will need its own source of power. For testing, the Raspberry Pi can be plugged directly into the mains power supply. However, when you come to building the body of the buggy and making it move, the Raspberry Pi will need a mobile source of power. A USB powerbank is a good choice, as it will be fairly light for the chassis to carry, just make sure it is capable of powering the model of Raspberry Pi that you are using.","title":"Powering the Raspberry Pi"},{"location":"week-1/fl-progrobot-w1-step06/#setting-up-your-raspberry-pi","text":"If you are not familiar with setting up a Raspberry Pi and using it, follow this guide to Getting started with Raspberry Pi . The programming language I will be using in this course is Python together with a library called GPIO Zero , which provides an accessible way to control components through the GPIO pins. Python and GPIO Zero will be installed by default if your Raspberry Pi is running the Raspbian operating system. Follow this guide to Installing GPIO Zero if you are using Raspbian Lite or another operating system. If you would like to control your Raspberry Pi remotely from another computer, check out our guide to Creating a virtual desktop using VNC Server .","title":"Setting up your Raspberry Pi"},{"location":"week-1/fl-progrobot-w1-step06/#discussion","text":"Did you have any problems connecting the motorboard to the Raspberry Pi or to the battery pack? What type of power supply are you using for your Raspberry Pi? Leave your answers in the comments section below.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step07/","text":"Resources Video Video subtitles Testing the motors In this step you will label and test the motors, to help ensure that your robot will correctly go forwards, backwards, left, or right as commanded. Labelling the motors The easiest way to keep track of which motor is left and which is right is to label them. Line the motors up side by side Use a marker pen to label the left-hand motor \u2018left\u2019 and draw an arrow on it to indicate which way is forward, as shown below Label the other motor \u2018right\u2019 and draw an arrow on it pointing in the same direction as your first motor Programming the motors Setting up the motors in Python 1. On your Raspberry Pi, open Mu or the IDE of your choice and create a new Python file. 2. Add the following code: from gpiozero import Robot from time import sleep robin = Robot(left=(7,8), right=(9,10)) The first line imports Robot , which you will use to control the direction and speed of the motors, from the GPIO Zero library. The second line imports sleep from the time library. The final line defines the Robot . You can name the variable anything you like; I've chosen to call my robot robin . When initialising the Robot you need to give it two arguments: left and right . The left argument should specify the two GPIO pins on the Raspberry Pi that are connected to the pins labelled IN1 and IN2 on the motor controller. I chose GPIO pins 7 and 8, but yours might be different. Similarly, the right argument needs to specify the GPIO pins that are connected to the pins labelled IN3 and IN4 ; for me that is GPIO pins 9 and 10. 3. Save your file. Forwards and backwards You now need to test which direction is forwards on each motor. 4. Add this code, which will drive both motors forward, wait one second, and then stop the motors: robin.forward() sleep(1) robin.stop() Note: robin is the name I gave my Robot ; if you chose a different name, make sure you change robin . Run the program and check that both motors are turning in the direction of the arrows you drew. If either motor is turning in the wrong direction, alter your program by swapping the pin numbers for that motor. # for example, change the left pins from robin = Robot(left=(7,8), right=(9,10)) # to robin = Robot(left=(8,7), right=(9,10)) Stop the program and run it again to check how any changes you made have affected the motors. 5. Test that the motors both turn backwards by adding robin.backward() and another sleep and running your program. robin.forward() sleep(1) robin.backward() sleep(1) robin.stop() You should see both the motors turn forwards for one second and then backwards for one second before stopping. Repeat steps 4 and 5 until both motors turn forwards and backwards correctly. Left and right Finally, you are going to test whether your program correctly identifies the left and right motors, by using the .right() command. 6. Add the following lines of code to your program. Run the program and note which motor changes direction on the command robin.right(0.6) . robin.forward(0.6) sleep(1) robin.right(0.6) sleep(1) robin.stop() Note: The 0.6 inside the .forward() and .right() commands makes the motors go a little slower. The default speed is 1. The motor that changed direction is the one that your program has defined as the right-hand motor. If this matches your label, then there\u2019s nothing to change. If this motor was the one you labelled 'left', you need to alter your Robot code to swap the left pin numbers with the right pins: # for example, change the GPIO pins from robin = Robot(left=(7,8), right=(9,10)) # to robin = Robot(left=(9,10), right=(7,8)) Repeat step 6 until the motor labelled 'right' changes direction. Potential problems If you are having problems with getting the motors to turn in the correct directions, try working through this step again with a new Python file. Top tip: If there is a problem with your program or the wiring, the motors can spin continuously. If this happens, try entering the command robin.stop() (replacing robin with the name you gave your robot) into the Python shell. Otherwise, turn off the battery pack or Raspberry Pi and check that the wiring is correct. If the motors aren't moving at all, try the following: Use the previous steps to check that the wiring of the components is correct Check that all the connections are secure Check that your battery pack is correctly filled with working batteries and is turned on Challenge: Experimenting with direction and speed Create a Python file including each of the commands: .forward() , .backward() , .left() , and .right() Experiment with giving these commands different values inside the brackets, e.g. robin.left(0.65) Discussion Do you need any help? Share any issues you have below.","title":"Testing the motors"},{"location":"week-1/fl-progrobot-w1-step07/#testing-the-motors","text":"In this step you will label and test the motors, to help ensure that your robot will correctly go forwards, backwards, left, or right as commanded.","title":"Testing the motors"},{"location":"week-1/fl-progrobot-w1-step07/#labelling-the-motors","text":"The easiest way to keep track of which motor is left and which is right is to label them. Line the motors up side by side Use a marker pen to label the left-hand motor \u2018left\u2019 and draw an arrow on it to indicate which way is forward, as shown below Label the other motor \u2018right\u2019 and draw an arrow on it pointing in the same direction as your first motor","title":"Labelling the motors"},{"location":"week-1/fl-progrobot-w1-step07/#programming-the-motors","text":"","title":"Programming the motors"},{"location":"week-1/fl-progrobot-w1-step07/#setting-up-the-motors-in-python","text":"1. On your Raspberry Pi, open Mu or the IDE of your choice and create a new Python file. 2. Add the following code: from gpiozero import Robot from time import sleep robin = Robot(left=(7,8), right=(9,10)) The first line imports Robot , which you will use to control the direction and speed of the motors, from the GPIO Zero library. The second line imports sleep from the time library. The final line defines the Robot . You can name the variable anything you like; I've chosen to call my robot robin . When initialising the Robot you need to give it two arguments: left and right . The left argument should specify the two GPIO pins on the Raspberry Pi that are connected to the pins labelled IN1 and IN2 on the motor controller. I chose GPIO pins 7 and 8, but yours might be different. Similarly, the right argument needs to specify the GPIO pins that are connected to the pins labelled IN3 and IN4 ; for me that is GPIO pins 9 and 10. 3. Save your file.","title":"Setting up the motors in Python"},{"location":"week-1/fl-progrobot-w1-step07/#forwards-and-backwards","text":"You now need to test which direction is forwards on each motor. 4. Add this code, which will drive both motors forward, wait one second, and then stop the motors: robin.forward() sleep(1) robin.stop() Note: robin is the name I gave my Robot ; if you chose a different name, make sure you change robin . Run the program and check that both motors are turning in the direction of the arrows you drew. If either motor is turning in the wrong direction, alter your program by swapping the pin numbers for that motor. # for example, change the left pins from robin = Robot(left=(7,8), right=(9,10)) # to robin = Robot(left=(8,7), right=(9,10)) Stop the program and run it again to check how any changes you made have affected the motors. 5. Test that the motors both turn backwards by adding robin.backward() and another sleep and running your program. robin.forward() sleep(1) robin.backward() sleep(1) robin.stop() You should see both the motors turn forwards for one second and then backwards for one second before stopping. Repeat steps 4 and 5 until both motors turn forwards and backwards correctly.","title":"Forwards and backwards"},{"location":"week-1/fl-progrobot-w1-step07/#left-and-right","text":"Finally, you are going to test whether your program correctly identifies the left and right motors, by using the .right() command. 6. Add the following lines of code to your program. Run the program and note which motor changes direction on the command robin.right(0.6) . robin.forward(0.6) sleep(1) robin.right(0.6) sleep(1) robin.stop() Note: The 0.6 inside the .forward() and .right() commands makes the motors go a little slower. The default speed is 1. The motor that changed direction is the one that your program has defined as the right-hand motor. If this matches your label, then there\u2019s nothing to change. If this motor was the one you labelled 'left', you need to alter your Robot code to swap the left pin numbers with the right pins: # for example, change the GPIO pins from robin = Robot(left=(7,8), right=(9,10)) # to robin = Robot(left=(9,10), right=(7,8)) Repeat step 6 until the motor labelled 'right' changes direction.","title":"Left and right"},{"location":"week-1/fl-progrobot-w1-step07/#potential-problems","text":"If you are having problems with getting the motors to turn in the correct directions, try working through this step again with a new Python file. Top tip: If there is a problem with your program or the wiring, the motors can spin continuously. If this happens, try entering the command robin.stop() (replacing robin with the name you gave your robot) into the Python shell. Otherwise, turn off the battery pack or Raspberry Pi and check that the wiring is correct. If the motors aren't moving at all, try the following: Use the previous steps to check that the wiring of the components is correct Check that all the connections are secure Check that your battery pack is correctly filled with working batteries and is turned on","title":"Potential problems"},{"location":"week-1/fl-progrobot-w1-step07/#challenge-experimenting-with-direction-and-speed","text":"Create a Python file including each of the commands: .forward() , .backward() , .left() , and .right() Experiment with giving these commands different values inside the brackets, e.g. robin.left(0.65)","title":"Challenge: Experimenting with direction and speed"},{"location":"week-1/fl-progrobot-w1-step07/#discussion","text":"Do you need any help? Share any issues you have below.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step08/","text":"Designing the chassis Now that you have the motors set up, it's time to design a chassis \u2014 the physical frame of your vehicle. Your buggy will need a chassis onto which you can secure the components, such as the wheels, motors, and Raspberry Pi. Choosing a material A chassis for a robot buggy can be built using all sorts of materials: cardboard, plastic, or metal to name a few. The material that works best for you depends on the weight of the components, cost, the skill of the maker, and the tools available. When choosing a material, you need to consider aspects such as weight versus durability, cost versus strength, and difficulty to work with versus quality of the chassis. Using certain types of metal might result in a strong and durable chassis, but will be more difficult to modify than cardboard. A cardboard chassis will be light and cheap, but is less sturdy than some other materials. I recommend making a prototype of the chassis first using a low-cost material, as tweaking the design will then be much easier. Common household items, such as a cardboard box or a plastic ice-cream tub, are perfect for experimenting with the design. The robot buggy that is built throughout the videos in this course uses a chassis made out of a cardboard carton that held grapes. I chose this was because it is a good-sized box that can hold the robot components without needing to be modified. It was also easy to make holes in the carton to attach the components. Planning the layout What needs to be attached to the chassis There is no right way to build your prototype robot chassis, but there are a few things to bear in mind. At the very minimum, the chassis needs to house the following components: Raspberry Pi Motor controller board Two DC motors Ultrasonic distance sensor Two line sensors AA battery holder (to power the motor controller board) USB battery pack (for powering the Raspberry Pi) You will also need to mount a pair of wheels to the axles of the motors, and add a ball caster to the front of the chassis that will act as a third wheel. The line sensors will need to sit on either side of the ball caster and point downwards to the floor. The optimal distance between the line sensors and the floor surface is 1 cm to 3 cm, which should be fine for most buggies. Making sure the components fit If you are planning on using a pre-made container for the chassis, you can try placing all the components inside to see if there is room. Bear in mind that the components can't all just be shoved in; some parts will need extra space around them so that they can be accessed easily, such as the power supply, which will need to be recharged. Other parts will need to be secured to certain places on the chassis; for instance, the ultrasonic distance sensor must be attached to the front of the chassis so that it can sense objects in front of the buggy. It can also be useful to design the layout of the buggy on paper, to make sure that all the components have enough room. Begin by making a footprint, which is the base of your buggy. You need to ensure that all the components can fit inside the footprint appropriately. A good method is to represent each component with a piece of paper that you can easily move about, so that you can try out different arrangements. Make sure each piece of paper is the correct size and shape for the component. You might have to measure your components, but most of them will have technical documentation online that will include their exact dimensions. Advanced design techniques If you want to know more about creating a physical object and using tools such as 3D modelling and 3D printing, check out our Design and Prototype Embedded Computer Systems course . Your turn Now it is time for you to design a chassis for your robot buggy and make sure all the components fit: Find a container that you can use for the prototype of the chassis Check that all the components will fit, either by using the actual components, or by mapping them out on paper Check that there is a bit of extra room around the components to account for things such as wiring Discussion What type of container have you used for your chassis? What material is it made out of? How did you check that all the components will fit? Share your answers in the comments below. You can also include a link to an image of your chassis by using Imgur or another image-hosting platform.","title":"Designing the chassis"},{"location":"week-1/fl-progrobot-w1-step08/#designing-the-chassis","text":"Now that you have the motors set up, it's time to design a chassis \u2014 the physical frame of your vehicle. Your buggy will need a chassis onto which you can secure the components, such as the wheels, motors, and Raspberry Pi.","title":"Designing the chassis"},{"location":"week-1/fl-progrobot-w1-step08/#choosing-a-material","text":"A chassis for a robot buggy can be built using all sorts of materials: cardboard, plastic, or metal to name a few. The material that works best for you depends on the weight of the components, cost, the skill of the maker, and the tools available. When choosing a material, you need to consider aspects such as weight versus durability, cost versus strength, and difficulty to work with versus quality of the chassis. Using certain types of metal might result in a strong and durable chassis, but will be more difficult to modify than cardboard. A cardboard chassis will be light and cheap, but is less sturdy than some other materials. I recommend making a prototype of the chassis first using a low-cost material, as tweaking the design will then be much easier. Common household items, such as a cardboard box or a plastic ice-cream tub, are perfect for experimenting with the design. The robot buggy that is built throughout the videos in this course uses a chassis made out of a cardboard carton that held grapes. I chose this was because it is a good-sized box that can hold the robot components without needing to be modified. It was also easy to make holes in the carton to attach the components.","title":"Choosing a material"},{"location":"week-1/fl-progrobot-w1-step08/#planning-the-layout","text":"","title":"Planning the layout"},{"location":"week-1/fl-progrobot-w1-step08/#what-needs-to-be-attached-to-the-chassis","text":"There is no right way to build your prototype robot chassis, but there are a few things to bear in mind. At the very minimum, the chassis needs to house the following components: Raspberry Pi Motor controller board Two DC motors Ultrasonic distance sensor Two line sensors AA battery holder (to power the motor controller board) USB battery pack (for powering the Raspberry Pi) You will also need to mount a pair of wheels to the axles of the motors, and add a ball caster to the front of the chassis that will act as a third wheel. The line sensors will need to sit on either side of the ball caster and point downwards to the floor. The optimal distance between the line sensors and the floor surface is 1 cm to 3 cm, which should be fine for most buggies.","title":"What needs to be attached to the chassis"},{"location":"week-1/fl-progrobot-w1-step08/#making-sure-the-components-fit","text":"If you are planning on using a pre-made container for the chassis, you can try placing all the components inside to see if there is room. Bear in mind that the components can't all just be shoved in; some parts will need extra space around them so that they can be accessed easily, such as the power supply, which will need to be recharged. Other parts will need to be secured to certain places on the chassis; for instance, the ultrasonic distance sensor must be attached to the front of the chassis so that it can sense objects in front of the buggy. It can also be useful to design the layout of the buggy on paper, to make sure that all the components have enough room. Begin by making a footprint, which is the base of your buggy. You need to ensure that all the components can fit inside the footprint appropriately. A good method is to represent each component with a piece of paper that you can easily move about, so that you can try out different arrangements. Make sure each piece of paper is the correct size and shape for the component. You might have to measure your components, but most of them will have technical documentation online that will include their exact dimensions.","title":"Making sure the components fit"},{"location":"week-1/fl-progrobot-w1-step08/#advanced-design-techniques","text":"If you want to know more about creating a physical object and using tools such as 3D modelling and 3D printing, check out our Design and Prototype Embedded Computer Systems course .","title":"Advanced design techniques"},{"location":"week-1/fl-progrobot-w1-step08/#your-turn","text":"Now it is time for you to design a chassis for your robot buggy and make sure all the components fit: Find a container that you can use for the prototype of the chassis Check that all the components will fit, either by using the actual components, or by mapping them out on paper Check that there is a bit of extra room around the components to account for things such as wiring","title":"Your turn"},{"location":"week-1/fl-progrobot-w1-step08/#discussion","text":"What type of container have you used for your chassis? What material is it made out of? How did you check that all the components will fit? Share your answers in the comments below. You can also include a link to an image of your chassis by using Imgur or another image-hosting platform.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step09/","text":"Resources Video Video subtitles Attaching the components to the chassis Once you have ensured that all the robot parts fit into the chassis, you need to secure some of the components in place. Permanent and removable fastenings Some types of fastening might be preferable to others, depending on the material of the robot chassis and the component that is being secured. You may not want to use permanent fastenings such as adhesive putty or glue when you are making the prototype chassis, if you intend to remove the components later. In this instance, a fastening that is easier to remove may be better, such as tape, cable ties, or Velcro-type strips. Once you are confident that you will not have to take things apart, using a permanent fastening might be desirable, to keep the components secured firmly in place. Screw holes may need to be incorporated into the chassis to attach some components, such as the ball caster. If you are using a material that is fairly durable, like metal or a hard plastic, you can use a threading tool to create threads for the screws. Otherwise, you can use a sharp instrument to make a small hole for the screw to go through. Securing the components in place I'm going to be using a cardboard box as my chassis. If you are using a different type of material or container for your chassis, some of these instructions may need to be adjusted to suit your design. The first step is to place your motors into the chassis. Place your motors inside the box, in roughly the position you would like them to be in. Then use a pen to mark the place where the motors\u2019 axles will need to pass through the walls of the box. Make sure you are giving your wheels enough room to spin around. Make a hole that is big enough for the motors\u2019 axles to fit through. If your chassis is made of cardboard, use a sharp object (such as a pencil or screwdriver) to carefully poke holes through the sides of the box. For more durable materials, use a threading tool or drill. You will need to secure the motors firmly to the chassis. If you don't, the motors may move inside the chassis once the wheels are attached and the motors are powered, and this could disturb other components. Tape or cable ties might be best for your prototype, as they are easy to attach and remove if necessary. Once the motors are in place you should attach the wheels to the axles. Next, you need to attach a ball caster to the front of the chassis to support the robot and act as a third wheel. Start by assembling the ball caster. It is useful to work out where the screw holes for the ball caster should be on the chassis before securing it in place. Place the ball caster face down inside the chassis near the front-centre, and use a pen to mark where the screws need to go. If your chassis is made of cardboard, use a small, sharp instrument to carefully make holes in the places you marked; use a threading tool or drill for more durable materials. Most ball casters come with spacers to increase the height. If the chassis dips towards the floor at the front, add spacers to the ball caster until the chassis is level. Otherwise, you can adjust the position of the ball caster forwards or towards the back of the chassis if the buggy is dipping where the wheels are. If you haven't done so already, place the motor controller, Raspberry Pi, and battery packs for the motorboard and Raspberry Pi inside the chassis. You won't need to secure these components to the chassis just yet. Remember that you will need to access the Raspberry Pi and parts of the chassis later in the course, to add the ultrasonic distance sensor and line-following sensor. Make sure there is nothing that could disturb the jumper leads that are connected to the Raspberry Pi, as they can easily come loose. Discussion Did you have any issues with attaching components to the chassis? If so, what adjustments did you have to make? What types of fastenings did you use for your robot buggy? Share your answers and a picture of your robot (hosted using Imgur or another image-hosting platform) in the comments below.","title":"Attaching the components to the chassis"},{"location":"week-1/fl-progrobot-w1-step09/#attaching-the-components-to-the-chassis","text":"Once you have ensured that all the robot parts fit into the chassis, you need to secure some of the components in place.","title":"Attaching the components to the chassis"},{"location":"week-1/fl-progrobot-w1-step09/#permanent-and-removable-fastenings","text":"Some types of fastening might be preferable to others, depending on the material of the robot chassis and the component that is being secured. You may not want to use permanent fastenings such as adhesive putty or glue when you are making the prototype chassis, if you intend to remove the components later. In this instance, a fastening that is easier to remove may be better, such as tape, cable ties, or Velcro-type strips. Once you are confident that you will not have to take things apart, using a permanent fastening might be desirable, to keep the components secured firmly in place. Screw holes may need to be incorporated into the chassis to attach some components, such as the ball caster. If you are using a material that is fairly durable, like metal or a hard plastic, you can use a threading tool to create threads for the screws. Otherwise, you can use a sharp instrument to make a small hole for the screw to go through.","title":"Permanent and removable fastenings"},{"location":"week-1/fl-progrobot-w1-step09/#securing-the-components-in-place","text":"I'm going to be using a cardboard box as my chassis. If you are using a different type of material or container for your chassis, some of these instructions may need to be adjusted to suit your design. The first step is to place your motors into the chassis. Place your motors inside the box, in roughly the position you would like them to be in. Then use a pen to mark the place where the motors\u2019 axles will need to pass through the walls of the box. Make sure you are giving your wheels enough room to spin around. Make a hole that is big enough for the motors\u2019 axles to fit through. If your chassis is made of cardboard, use a sharp object (such as a pencil or screwdriver) to carefully poke holes through the sides of the box. For more durable materials, use a threading tool or drill. You will need to secure the motors firmly to the chassis. If you don't, the motors may move inside the chassis once the wheels are attached and the motors are powered, and this could disturb other components. Tape or cable ties might be best for your prototype, as they are easy to attach and remove if necessary. Once the motors are in place you should attach the wheels to the axles. Next, you need to attach a ball caster to the front of the chassis to support the robot and act as a third wheel. Start by assembling the ball caster. It is useful to work out where the screw holes for the ball caster should be on the chassis before securing it in place. Place the ball caster face down inside the chassis near the front-centre, and use a pen to mark where the screws need to go. If your chassis is made of cardboard, use a small, sharp instrument to carefully make holes in the places you marked; use a threading tool or drill for more durable materials. Most ball casters come with spacers to increase the height. If the chassis dips towards the floor at the front, add spacers to the ball caster until the chassis is level. Otherwise, you can adjust the position of the ball caster forwards or towards the back of the chassis if the buggy is dipping where the wheels are. If you haven't done so already, place the motor controller, Raspberry Pi, and battery packs for the motorboard and Raspberry Pi inside the chassis. You won't need to secure these components to the chassis just yet. Remember that you will need to access the Raspberry Pi and parts of the chassis later in the course, to add the ultrasonic distance sensor and line-following sensor. Make sure there is nothing that could disturb the jumper leads that are connected to the Raspberry Pi, as they can easily come loose.","title":"Securing the components in place"},{"location":"week-1/fl-progrobot-w1-step09/#discussion","text":"Did you have any issues with attaching components to the chassis? If so, what adjustments did you have to make? What types of fastenings did you use for your robot buggy? Share your answers and a picture of your robot (hosted using Imgur or another image-hosting platform) in the comments below.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step10/","text":"Resources Video Video subtitles Making the robot move Now you are going to test whether your buggy can move forwards, backwards, left, and right, using the Python program you created for testing the motors. Finding a suitable surface Typically, the motors and wheels used for a robot buggy aren't very good at moving on certain surfaces, such as carpet. If possible, I recommend testing the buggy on a large wooden surface or a tiled floor. Powering the Raspberry Pi and motor controller Power up your Raspberry Pi and the motor controller board. Remember, you will need a mobile power supply for the Pi, or your robot will not be able to travel far from the mains plug. If either of the wheels starts spinning continuously, chances are one of the connections between the motor controller and the Raspberry Pi has come loose, or is wired up wrongly. Turn off the battery pack for the motor controller or remove the power from the Pi to stop the motors. Then check the wiring that you connected in the steps for connecting the motors and the Raspberry Pi to the motor controller. Testing the movement To check whether your buggy can move in all directions, it is best to use one of the programs you created for testing the direction of the motors; just make sure it was a working program with the correct GPIO pins for the Robot ! You need to check that the buggy can move in every direction. Therefore, a program that contains the commands .forward() , .backward() , .left() , and .right() is ideal. Remember to end the program with .stop() to stop the motors from turning. If you don't have a program that is suitable, you can copy the code below into a new Python file (adjusting the GPIO pin numbers as needed). from gpiozero import Robot from time import sleep robin = Robot(left=(8,7), right=(9,10)) robin.forward() sleep(1) robin.right(0.8) sleep(1) robin.backward(0.9) sleep(1) robin.left(0.7) sleep(1) robin.stop() Does the robot buggy move forwards, backwards, left, and right correctly, in the order you specified in the code? If not, check that the GPIO pins of the left and right arguments of the Robot are set correctly for your motors. For example, in my robot set-up I had to swap the left motor pins from 7,8 to 8,7 . If you are still having issues, follow the instructions that you used previously when you tested the direction of both motors. If your buggy moves for some but not all of the commands, try adjusting the number given in the brackets, which controls the speed of the motors. Understanding how the .forward(), .left(), .right(), and .backward() commands work Using Robot from the GPIO Zero library allows you to set the direction of the motors without worrying too much about the signals being sent to the motors. As useful as this is, it's also important to understand how these signals are interpreted by the motor controller board to produce the output you want. The motors work on a range of -1 to 1 ; positive values tell the motor to run forwards, and negative values tell the motor to run in reverse. The size of the value adjusts the speed of the motors. When using the .forward() command, a positive value is sent to both motors, while the .backward() command sends a negative value to both. The .left() and .right() commands work a bit differently. To turn left, the left motor needs to run backwards (a negative signal is needed), while the right motor should run forwards. The opposite is true to turn right; the right motor needs to receive a negative value and the left motor a positive value. Connecting to a Raspberry Pi remotely Being able to connect to your Raspberry Pi remotely is useful when designing, running, and testing code on the robot buggy. It means you don't have to remove the Raspberry Pi from the buggy every time you want to run or edit a program. To use your Raspberry Pi without physically connecting it to a monitor, mouse, or keyboard, you can remotely access the Pi via VNC (Virtual Network Computing) or SSH (Secure Shell). VNC is a system that allows you to control remotely the graphical desktop interface of one computer (running VNC Server) from another computer or mobile device (running VNC Viewer). For more information, read our guide on Connecting to your Raspberry Pi with VNC Viewer . You can also access the command line (but not the graphical interface) of a Raspberry Pi remotely from another device on the same network, using SSH. Our guide on Connecting to Raspberry Pi via SSH contains the details of how to do this. Discussion Share how you got on and any issues you are having in the comments below. Post a link to a video of your robot once you have got it moving! You may need to use a video-hosting platform such as YouTube .","title":"Making the robot move"},{"location":"week-1/fl-progrobot-w1-step10/#making-the-robot-move","text":"Now you are going to test whether your buggy can move forwards, backwards, left, and right, using the Python program you created for testing the motors.","title":"Making the robot move"},{"location":"week-1/fl-progrobot-w1-step10/#finding-a-suitable-surface","text":"Typically, the motors and wheels used for a robot buggy aren't very good at moving on certain surfaces, such as carpet. If possible, I recommend testing the buggy on a large wooden surface or a tiled floor.","title":"Finding a suitable surface"},{"location":"week-1/fl-progrobot-w1-step10/#powering-the-raspberry-pi-and-motor-controller","text":"Power up your Raspberry Pi and the motor controller board. Remember, you will need a mobile power supply for the Pi, or your robot will not be able to travel far from the mains plug. If either of the wheels starts spinning continuously, chances are one of the connections between the motor controller and the Raspberry Pi has come loose, or is wired up wrongly. Turn off the battery pack for the motor controller or remove the power from the Pi to stop the motors. Then check the wiring that you connected in the steps for connecting the motors and the Raspberry Pi to the motor controller.","title":"Powering the Raspberry Pi and motor controller"},{"location":"week-1/fl-progrobot-w1-step10/#testing-the-movement","text":"To check whether your buggy can move in all directions, it is best to use one of the programs you created for testing the direction of the motors; just make sure it was a working program with the correct GPIO pins for the Robot ! You need to check that the buggy can move in every direction. Therefore, a program that contains the commands .forward() , .backward() , .left() , and .right() is ideal. Remember to end the program with .stop() to stop the motors from turning. If you don't have a program that is suitable, you can copy the code below into a new Python file (adjusting the GPIO pin numbers as needed). from gpiozero import Robot from time import sleep robin = Robot(left=(8,7), right=(9,10)) robin.forward() sleep(1) robin.right(0.8) sleep(1) robin.backward(0.9) sleep(1) robin.left(0.7) sleep(1) robin.stop() Does the robot buggy move forwards, backwards, left, and right correctly, in the order you specified in the code? If not, check that the GPIO pins of the left and right arguments of the Robot are set correctly for your motors. For example, in my robot set-up I had to swap the left motor pins from 7,8 to 8,7 . If you are still having issues, follow the instructions that you used previously when you tested the direction of both motors. If your buggy moves for some but not all of the commands, try adjusting the number given in the brackets, which controls the speed of the motors.","title":"Testing the movement"},{"location":"week-1/fl-progrobot-w1-step10/#understanding-how-the-forward-left-right-and-backward-commands-work","text":"Using Robot from the GPIO Zero library allows you to set the direction of the motors without worrying too much about the signals being sent to the motors. As useful as this is, it's also important to understand how these signals are interpreted by the motor controller board to produce the output you want. The motors work on a range of -1 to 1 ; positive values tell the motor to run forwards, and negative values tell the motor to run in reverse. The size of the value adjusts the speed of the motors. When using the .forward() command, a positive value is sent to both motors, while the .backward() command sends a negative value to both. The .left() and .right() commands work a bit differently. To turn left, the left motor needs to run backwards (a negative signal is needed), while the right motor should run forwards. The opposite is true to turn right; the right motor needs to receive a negative value and the left motor a positive value.","title":"Understanding how the .forward(), .left(), .right(), and .backward() commands work"},{"location":"week-1/fl-progrobot-w1-step10/#connecting-to-a-raspberry-pi-remotely","text":"Being able to connect to your Raspberry Pi remotely is useful when designing, running, and testing code on the robot buggy. It means you don't have to remove the Raspberry Pi from the buggy every time you want to run or edit a program. To use your Raspberry Pi without physically connecting it to a monitor, mouse, or keyboard, you can remotely access the Pi via VNC (Virtual Network Computing) or SSH (Secure Shell). VNC is a system that allows you to control remotely the graphical desktop interface of one computer (running VNC Server) from another computer or mobile device (running VNC Viewer). For more information, read our guide on Connecting to your Raspberry Pi with VNC Viewer . You can also access the command line (but not the graphical interface) of a Raspberry Pi remotely from another device on the same network, using SSH. Our guide on Connecting to Raspberry Pi via SSH contains the details of how to do this.","title":"Connecting to a Raspberry Pi remotely"},{"location":"week-1/fl-progrobot-w1-step10/#discussion","text":"Share how you got on and any issues you are having in the comments below. Post a link to a video of your robot once you have got it moving! You may need to use a video-hosting platform such as YouTube .","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step11/","text":"Challenge: Driving in patterns So far, you have been testing that the robot buggy moves appropriately in response to the commands .forward() , .backward() , .left() , .right() , and .stop() . You have also used the sleep() command to make the program wait for a specified number of seconds before running the next command, thus enabling the buggy to either move or stop moving for a certain amount of time. Developing a new algorithm The next task is for you to create and test an algorithm that drives the buggy in a certain pattern. Start by creating a program that makes your robot drive in the shape of a square. Then try another pattern, for example: A triangle A star A figure of eight You could also include a loop in your program so that the buggy repeats a pattern more than once. Discussion Once you\u2019ve completed a challenge, add a comment below and share a link to your code (for example using Pastebin ), along with any comments or questions.","title":"Challenge: Driving in patterns"},{"location":"week-1/fl-progrobot-w1-step11/#challenge-driving-in-patterns","text":"So far, you have been testing that the robot buggy moves appropriately in response to the commands .forward() , .backward() , .left() , .right() , and .stop() . You have also used the sleep() command to make the program wait for a specified number of seconds before running the next command, thus enabling the buggy to either move or stop moving for a certain amount of time.","title":"Challenge: Driving in patterns"},{"location":"week-1/fl-progrobot-w1-step11/#developing-a-new-algorithm","text":"The next task is for you to create and test an algorithm that drives the buggy in a certain pattern. Start by creating a program that makes your robot drive in the shape of a square. Then try another pattern, for example: A triangle A star A figure of eight You could also include a loop in your program so that the buggy repeats a pattern more than once.","title":"Developing a new algorithm"},{"location":"week-1/fl-progrobot-w1-step11/#discussion","text":"Once you\u2019ve completed a challenge, add a comment below and share a link to your code (for example using Pastebin ), along with any comments or questions.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step12/","text":"Why we call robotics challenging You are coming to the end of the first week of your journey into the world of robotics, and you may have noticed that working in this area requires you to navigate some challenges! Robotics is a complex and vast subject, which can be off-putting when you are starting out. I want to discuss some of these challenges and hear how you have overcome them. Challenges with components Jumper cables and loose components The jumper cables you have been using for the buggy so far tend to come loose from the components or GPIO pins if you knock them. I cannot tell you how many times I have been pulling my hair out trying to find an error in my code, only to find that it was a loose jumper cable causing the problem. GPIO pin numbers are weird The numbering on the GPIO pins can be confusing; they are numbered as the processor sees them, rather than as they are laid out on the board. This is a product of wanting the Raspberry Pi to be backwards-compatible as much as possible; when the pins changed from a 26-pin to a 40-pin set-up they had to be rearranged, and the original pins were moved and mixed with new ones. Debugging components A lot of the things you have done this week will be completely new to you, as will the components you are using. Dealing with components rather than products means you forgo some of the hand-holding that comes with a pre-built device. When you buy components, you have to figure out how they work and test them. If the components are new to you, this can be a challenging process, as you don't know what to look for, or how to test the component. Cardboard is easy, not strong As you create your buggy, you are most likely using cardboard to house it; this is great, and the most sensible option for the initial build. This, however, brings its own challenges; as previously mentioned, the components are susceptible to being knocked out of place. These two challenges combined mean that as roboticists we need to do two things when testing: check the components after each run, and make sure to avoid bumps as much as possible. Things can go wrong if the placement of your components in the chassis doesn't allow for particularly sturdy attachments; even a small bump can knock any number of components loose, and you may need to do a thorough check to find out what is going wrong. The environment Not all floors are created equal Creating a mobile robot, particularly one that uses wheels to navigate around, requires you to consider carefully the floor you test it on. Some motors have no problem navigating carpet, linoleum, or tiles; others will not work on anything other than smooth concrete. This can cause frustration, as you may adjust the settings on the wheels, only to find out it was an uneven floor causing the issues. Environments are not consistent Some of the sensors and components you will use can be greatly impacted by the environment you test the buggy in. Light and line sensors can be thrown off by environmental light levels and have to be calibrated in order to be accurate. Handling these inconsistencies is much simpler if you are working with components that you are familiar with. This process can cause considerable frustration if you are having to learn how to calibrate the sensors at the same time. It's not you, it's robotics I hope you have found some comfort in this step. This is a challenging area of computing, and you are not alone in coming across frustrations when working on your buggy. Discussion Think of a challenge you have faced during this first week. It could be one from the areas I have discussed here, or another challenge that you would like to discuss. What happened? How did you overcome the challenge? If you haven't yet, this is a great time to ask for help! If you haven't experienced these challenges, what have you done to prevent them? Could you share your process, to help other learners? Share your challenges and stories in the comments below. We are all in this together, after all; it may be frustrating, but together we can overcome these obstacles and create amazing robots.","title":"Why we call robotics challenging"},{"location":"week-1/fl-progrobot-w1-step12/#why-we-call-robotics-challenging","text":"You are coming to the end of the first week of your journey into the world of robotics, and you may have noticed that working in this area requires you to navigate some challenges! Robotics is a complex and vast subject, which can be off-putting when you are starting out. I want to discuss some of these challenges and hear how you have overcome them.","title":"Why we call robotics challenging"},{"location":"week-1/fl-progrobot-w1-step12/#challenges-with-components","text":"","title":"Challenges with components"},{"location":"week-1/fl-progrobot-w1-step12/#jumper-cables-and-loose-components","text":"The jumper cables you have been using for the buggy so far tend to come loose from the components or GPIO pins if you knock them. I cannot tell you how many times I have been pulling my hair out trying to find an error in my code, only to find that it was a loose jumper cable causing the problem.","title":"Jumper cables and loose components"},{"location":"week-1/fl-progrobot-w1-step12/#gpio-pin-numbers-are-weird","text":"The numbering on the GPIO pins can be confusing; they are numbered as the processor sees them, rather than as they are laid out on the board. This is a product of wanting the Raspberry Pi to be backwards-compatible as much as possible; when the pins changed from a 26-pin to a 40-pin set-up they had to be rearranged, and the original pins were moved and mixed with new ones.","title":"GPIO pin numbers are weird"},{"location":"week-1/fl-progrobot-w1-step12/#debugging-components","text":"A lot of the things you have done this week will be completely new to you, as will the components you are using. Dealing with components rather than products means you forgo some of the hand-holding that comes with a pre-built device. When you buy components, you have to figure out how they work and test them. If the components are new to you, this can be a challenging process, as you don't know what to look for, or how to test the component.","title":"Debugging components"},{"location":"week-1/fl-progrobot-w1-step12/#cardboard-is-easy-not-strong","text":"As you create your buggy, you are most likely using cardboard to house it; this is great, and the most sensible option for the initial build. This, however, brings its own challenges; as previously mentioned, the components are susceptible to being knocked out of place. These two challenges combined mean that as roboticists we need to do two things when testing: check the components after each run, and make sure to avoid bumps as much as possible. Things can go wrong if the placement of your components in the chassis doesn't allow for particularly sturdy attachments; even a small bump can knock any number of components loose, and you may need to do a thorough check to find out what is going wrong.","title":"Cardboard is easy, not strong"},{"location":"week-1/fl-progrobot-w1-step12/#the-environment","text":"","title":"The environment"},{"location":"week-1/fl-progrobot-w1-step12/#not-all-floors-are-created-equal","text":"Creating a mobile robot, particularly one that uses wheels to navigate around, requires you to consider carefully the floor you test it on. Some motors have no problem navigating carpet, linoleum, or tiles; others will not work on anything other than smooth concrete. This can cause frustration, as you may adjust the settings on the wheels, only to find out it was an uneven floor causing the issues.","title":"Not all floors are created equal"},{"location":"week-1/fl-progrobot-w1-step12/#environments-are-not-consistent","text":"Some of the sensors and components you will use can be greatly impacted by the environment you test the buggy in. Light and line sensors can be thrown off by environmental light levels and have to be calibrated in order to be accurate. Handling these inconsistencies is much simpler if you are working with components that you are familiar with. This process can cause considerable frustration if you are having to learn how to calibrate the sensors at the same time.","title":"Environments are not consistent"},{"location":"week-1/fl-progrobot-w1-step12/#its-not-you-its-robotics","text":"I hope you have found some comfort in this step. This is a challenging area of computing, and you are not alone in coming across frustrations when working on your buggy.","title":"It's not you, it's robotics"},{"location":"week-1/fl-progrobot-w1-step12/#discussion","text":"Think of a challenge you have faced during this first week. It could be one from the areas I have discussed here, or another challenge that you would like to discuss. What happened? How did you overcome the challenge? If you haven't yet, this is a great time to ask for help! If you haven't experienced these challenges, what have you done to prevent them? Could you share your process, to help other learners? Share your challenges and stories in the comments below. We are all in this together, after all; it may be frustrating, but together we can overcome these obstacles and create amazing robots.","title":"Discussion"},{"location":"week-1/fl-progrobot-w1-step13/","text":"Resources Video Video subtitles The end of week one Congratulations on reaching the end of week one! If you still haven't managed to get your robot moving, ask for help in the comments below. Well done if you have managed to complete all of the tasks this week and programmed your robot to drive in a particular pattern. Key points You learnt about the Raspberry Pi, and how the GPIO pins make it a good platform to use for building a robot Motors require more power than a Raspberry Pi can provide, as well as analogue signals, so you connected your motors via a motorboard You designed a chassis and connected your motors to it, making sure that you knew which way around they were connected Finally, you used the Robot class to control your motors, and make your robot drive around Next week you'll move on to taking inputs from sensors, and use those to affect how your robot moves. Is there anything this week which particularly challenged you? What accomplishment do you feel most proud of? Let us know in the comments!","title":"The end of week one"},{"location":"week-1/fl-progrobot-w1-step13/#the-end-of-week-one","text":"Congratulations on reaching the end of week one! If you still haven't managed to get your robot moving, ask for help in the comments below. Well done if you have managed to complete all of the tasks this week and programmed your robot to drive in a particular pattern.","title":"The end of week one"},{"location":"week-1/fl-progrobot-w1-step13/#key-points","text":"You learnt about the Raspberry Pi, and how the GPIO pins make it a good platform to use for building a robot Motors require more power than a Raspberry Pi can provide, as well as analogue signals, so you connected your motors via a motorboard You designed a chassis and connected your motors to it, making sure that you knew which way around they were connected Finally, you used the Robot class to control your motors, and make your robot drive around Next week you'll move on to taking inputs from sensors, and use those to affect how your robot moves. Is there anything this week which particularly challenged you? What accomplishment do you feel most proud of? Let us know in the comments!","title":"Key points"},{"location":"week-2/fl-progrobot-w2-activity/","text":"[comment]: # ( Is this step open? Y/N If so, short description of this step: Related links: Related files: ) Week two: Automating actions using distance sensors Welcome to week two Welcome to week two of the course! Sensing the physical world Learn about how robots use sensors to understand the world around them. Adding a distance sensor to the buggy Learn about how ultrasonic distance sensors work and attach one to your buggy. Navigating obstacles autonomously Program your robot buggy so that it can avoid obstacles. The end of week two Congratulations on completing week two of the course!","title":"Week two: Automating actions using distance sensors"},{"location":"week-2/fl-progrobot-w2-activity/#week-two-automating-actions-using-distance-sensors","text":"","title":"Week two: Automating actions using distance sensors"},{"location":"week-2/fl-progrobot-w2-activity/#welcome-to-week-two","text":"Welcome to week two of the course!","title":"Welcome to week two"},{"location":"week-2/fl-progrobot-w2-activity/#sensing-the-physical-world","text":"Learn about how robots use sensors to understand the world around them.","title":"Sensing the physical world"},{"location":"week-2/fl-progrobot-w2-activity/#adding-a-distance-sensor-to-the-buggy","text":"Learn about how ultrasonic distance sensors work and attach one to your buggy.","title":"Adding a distance sensor to the buggy"},{"location":"week-2/fl-progrobot-w2-activity/#navigating-obstacles-autonomously","text":"Program your robot buggy so that it can avoid obstacles.","title":"Navigating obstacles autonomously"},{"location":"week-2/fl-progrobot-w2-activity/#the-end-of-week-two","text":"Congratulations on completing week two of the course!","title":"The end of week two"},{"location":"week-2/fl-progrobot-w2-step01/","text":"Resources Video Video subtitles Welcome to week two Welcome to week two of Robotics With Raspberry Pi: Build and Program Your First Robot Buggy . Last week, you started building your robot, with wheels and a chassis. You also programmed it in Python, to make it move. This week, you will: Discover different types of sensors that robots can use Look in more detail at how a distance sensor works Attach an ultrasonic distance sensor (UDS) to your buggy Program your robot to avoid obstacles detected by the UDS I hope you enjoy the week!","title":"Welcome to week two"},{"location":"week-2/fl-progrobot-w2-step01/#welcome-to-week-two","text":"Welcome to week two of Robotics With Raspberry Pi: Build and Program Your First Robot Buggy . Last week, you started building your robot, with wheels and a chassis. You also programmed it in Python, to make it move. This week, you will: Discover different types of sensors that robots can use Look in more detail at how a distance sensor works Attach an ultrasonic distance sensor (UDS) to your buggy Program your robot to avoid obstacles detected by the UDS I hope you enjoy the week!","title":"Welcome to week two"},{"location":"week-2/fl-progrobot-w2-step02/","text":"[comment]: # ( Feedback Author: Normally lead educator ) Quiz: Mobile robotics Last week, you learnt about some of the different components that you can use to build a robot buggy. In this quiz, you will test your knowledge of how these components connect and work together to create a mobile robot. Question 1 Which of these things can nearly all robots do? Think, learn, and act No Many robots aren't able to learn; instead, they perform actions based on written instructions Week 1, step 3 Sense, process, and learn No Many robots aren't able to learn; instead, they perform actions based on written instructions Week 1, step 3 Think, process, and learn No Many robots aren't able to think or learn; instead, they perform actions based on written instructions Week 1, step 3 Sense, process, and act Yes N/A Week 1, step 3 Question 2 What is the maximum input voltage that a Raspberry Pi can handle through the GPIO pins? 3V No A Raspberry Pi can handle input voltages higher than 3V from the GPIO pins Week 1, step 4 3.3V Yes N/A Week 1, step 4 5V No An input voltage of 5V is too high for a Raspberry Pi to handle through the GPIO pins and will damage it Week 1, step 4 5.5V No An input voltage of 5.5V is too high for a Raspberry Pi to handle through the GPIO pins and will damage it Week 1, step 4 Question 3 When testing the movement of your robot buggy, why do you need to perform the .stop() command before closing the Python program? This switches the motor controller board off so it doesn\u2019t use any more power No The motor controller will still draw power until the battery pack and/or the Raspberry Pi is switched off Week 1, step 7 Otherwise the motors will continue to spin in the direction they have been instructed to Yes N/A Week 1, step 7 If the robot isn\u2019t instructed to stop first, the program will output an error No Not including the .stop() command before closing the program won't cause an error in Python Week 1, step 7 So that the Raspberry Pi and the motors are shut down safely No The .stop() command in GPIO Zero is for controlling the motors, not the motor controller or the Raspberry Pi Week 1, step 7 Question 4 Which series of commands could be used to instruct a robot buggy to move in an L shape? robin.forward() , sleep(0.5) , robin.left(0.8) , sleep(0.5) , robin.forward() Yes N/A Week 1, step 7 robin.forward(10) , sleep(0.5) , robin.left(90) , sleep(0.5) , robin.forward(10) No The commands .forward() and .left() can only accept values from a range of -1 to 1 Week 1, step 7 robin.left(0.8) , sleep(0.5) , robin.forward() , sleep(0.5) , robin.left(0.8) No This algorithm would need an extra sleep() and .forward() command at the end for it to make an L shape Week 1, step 7 robin.left(90) , sleep(0.5) , robin.forward(10) , sleep(0.5) , robin.left(90) No The commands .forward() and .left() can only accept values from a range of -1 to 1 Week 1, step 7","title":"Quiz: Mobile robotics"},{"location":"week-2/fl-progrobot-w2-step02/#quiz-mobile-robotics","text":"Last week, you learnt about some of the different components that you can use to build a robot buggy. In this quiz, you will test your knowledge of how these components connect and work together to create a mobile robot.","title":"Quiz: Mobile robotics"},{"location":"week-2/fl-progrobot-w2-step02/#question-1","text":"Which of these things can nearly all robots do? Think, learn, and act No Many robots aren't able to learn; instead, they perform actions based on written instructions Week 1, step 3 Sense, process, and learn No Many robots aren't able to learn; instead, they perform actions based on written instructions Week 1, step 3 Think, process, and learn No Many robots aren't able to think or learn; instead, they perform actions based on written instructions Week 1, step 3 Sense, process, and act Yes N/A Week 1, step 3","title":"Question 1"},{"location":"week-2/fl-progrobot-w2-step02/#question-2","text":"What is the maximum input voltage that a Raspberry Pi can handle through the GPIO pins? 3V No A Raspberry Pi can handle input voltages higher than 3V from the GPIO pins Week 1, step 4 3.3V Yes N/A Week 1, step 4 5V No An input voltage of 5V is too high for a Raspberry Pi to handle through the GPIO pins and will damage it Week 1, step 4 5.5V No An input voltage of 5.5V is too high for a Raspberry Pi to handle through the GPIO pins and will damage it Week 1, step 4","title":"Question 2"},{"location":"week-2/fl-progrobot-w2-step02/#question-3","text":"When testing the movement of your robot buggy, why do you need to perform the .stop() command before closing the Python program? This switches the motor controller board off so it doesn\u2019t use any more power No The motor controller will still draw power until the battery pack and/or the Raspberry Pi is switched off Week 1, step 7 Otherwise the motors will continue to spin in the direction they have been instructed to Yes N/A Week 1, step 7 If the robot isn\u2019t instructed to stop first, the program will output an error No Not including the .stop() command before closing the program won't cause an error in Python Week 1, step 7 So that the Raspberry Pi and the motors are shut down safely No The .stop() command in GPIO Zero is for controlling the motors, not the motor controller or the Raspberry Pi Week 1, step 7","title":"Question 3"},{"location":"week-2/fl-progrobot-w2-step02/#question-4","text":"Which series of commands could be used to instruct a robot buggy to move in an L shape? robin.forward() , sleep(0.5) , robin.left(0.8) , sleep(0.5) , robin.forward() Yes N/A Week 1, step 7 robin.forward(10) , sleep(0.5) , robin.left(90) , sleep(0.5) , robin.forward(10) No The commands .forward() and .left() can only accept values from a range of -1 to 1 Week 1, step 7 robin.left(0.8) , sleep(0.5) , robin.forward() , sleep(0.5) , robin.left(0.8) No This algorithm would need an extra sleep() and .forward() command at the end for it to make an L shape Week 1, step 7 robin.left(90) , sleep(0.5) , robin.forward(10) , sleep(0.5) , robin.left(90) No The commands .forward() and .left() can only accept values from a range of -1 to 1 Week 1, step 7","title":"Question 4"},{"location":"week-2/fl-progrobot-w2-step03/","text":"How could you improve the functionality of the buggy? Now that you have created a buggy that can move in various directions, have a think about what improvements you could make. For example, what components could you add to your robot buggy to make it sense the world around it? How should your buggy act, based on this new information? What algorithms could you use to make it behave differently? This is also a great time to share your progress and any pictures or videos that you have of your robot in action. Describe your progress, and share a link to any images or videos you've taken of your robot, in the comments section below. You may need to use an image-hosting platform such as Imgur , or a video-hosting platform such as YouTube . In the next step you will find out about a range of sensors and learn how robots can use these to understand their environment.","title":"How could you improve the functionality of the buggy?"},{"location":"week-2/fl-progrobot-w2-step03/#how-could-you-improve-the-functionality-of-the-buggy","text":"Now that you have created a buggy that can move in various directions, have a think about what improvements you could make. For example, what components could you add to your robot buggy to make it sense the world around it? How should your buggy act, based on this new information? What algorithms could you use to make it behave differently? This is also a great time to share your progress and any pictures or videos that you have of your robot in action. Describe your progress, and share a link to any images or videos you've taken of your robot, in the comments section below. You may need to use an image-hosting platform such as Imgur , or a video-hosting platform such as YouTube . In the next step you will find out about a range of sensors and learn how robots can use these to understand their environment.","title":"How could you improve the functionality of the buggy?"},{"location":"week-2/fl-progrobot-w2-step04/","text":"Robotic sensors Robots, particularly autonomous ones, need to sense the world around them. In this step, I will take you through a few of the many options available to add sensing to your buggy. Force and touch A robot that is designed to navigate the real world and interact with physical objects, for example by picking them up, must be able to measure the force it is applying to these objects. In some cases, it might be necessary for the robot to sense external forces exerted upon it. Force Force sensors are used by roboticists to measure the forces their robots, such as the robotic arm assembling mobile phones that you heard about last week, are exerting on the objects they interact with. It is important that the arm applies enough force to hold the part and not drop it, but not so much pressure that the component is damaged or crushed. Other roboticists use force sensors to detect shocks or vibrations, to allow a robot to react and balance/stabilise itself. Mobile robots could use force sensors in navigation as well, although touch sensors are more common. Touch Touch sensors allow robots to detect physical interactions between their body and objects in their surroundings. Capacitive touch sensors use conductive properties to detect touches, most commonly from a human's touch, but any object that can conduct electricity will work. Resistive touch sensors do not use electrical properties, but instead detect touches based on pressure applied to the plate. This type of sensor can allow a robot to navigate its surroundings, even if the object touching the sensor does not conduct electricity. Detecting the environment Robots can use measurements of the environment around them to influence their behaviour, or just to collect data for analysis. Temperature Temperature sensors can be used in a variety of contexts, not just as data collection for scientific experiments. A rover on Mars can use its temperature sensor to evaluate the terrain it is rolling over; if it detects a drop in temperature it can reduce the torque on its wheels to prepare for ice. A robot designed to fight fires could use a temperature sensor to direct itself towards the hottest parts of a burning building, where it will be most effective. Light Another detectable property of the environment is light. If a robot has different tasks to accomplish at night than in the day, it could detect decreasing light levels and change its behaviour to night mode. Changes in light can also indicate a change in surroundings; a robot designed to explore houses in disaster zones could use light sensors to help navigate around a home that has collapsed, by directing itself towards the light to get out of tight spaces. Sound Sound sensors act similarly to microphones, but are often attached to circuits that compare the amplitude of the sound to a threshold value, returning the result of that comparison to the robot. The higher the amplitude, the louder the noise. This could be used by a robot designed to study wildlife; detecting and following loud noises may be one of the pieces of data that is used to locate wildlife. A more complex use would be a sound sensor for speech recognition, responding to commands spoken by a user. Chemical Robots can also use specialised sensors to detect certain chemical properties. For example, pH sensors detect the acidity or alkalinity of the environment around a robot. Scientific robots could use this to check the quality of rivers or soil in remote places. Carbon monoxide is poisonous, and robots equipped to sense this gas can be used to monitor potentially dangerous environments where human explorers would be at risk. Object proximity Mobile robots have to navigate the world around them, often autonomously, and there are sensors that help them detect the proximity of other objects around them. Infrared sensors Infrared sensors detect changes in the levels of infrared radiation captured by the device. These changes are caused when an object (often a living thing) that is hotter than the background passes through the sensor's field of view. Ultrasonic distance sensors A better sensor for robots that have to navigate around inanimate objects is the ultrasonic distance sensor (UDS). This type of sensor emits high-frequency noises that rebound off objects in the surrounding area and return to the robot. This is how bats sense the world when they are flying at night. You are going to use a UDS in your buggy, and in the next step you will see how they work in greater detail. Discussion Pick one of the types of sensor you have seen in this step. Think of another use of that sensor in robotics, from past experience or from your imagination. Share your ideas in the comments section.","title":"Robotic sensors"},{"location":"week-2/fl-progrobot-w2-step04/#robotic-sensors","text":"Robots, particularly autonomous ones, need to sense the world around them. In this step, I will take you through a few of the many options available to add sensing to your buggy.","title":"Robotic sensors"},{"location":"week-2/fl-progrobot-w2-step04/#force-and-touch","text":"A robot that is designed to navigate the real world and interact with physical objects, for example by picking them up, must be able to measure the force it is applying to these objects. In some cases, it might be necessary for the robot to sense external forces exerted upon it.","title":"Force and touch"},{"location":"week-2/fl-progrobot-w2-step04/#force","text":"Force sensors are used by roboticists to measure the forces their robots, such as the robotic arm assembling mobile phones that you heard about last week, are exerting on the objects they interact with. It is important that the arm applies enough force to hold the part and not drop it, but not so much pressure that the component is damaged or crushed. Other roboticists use force sensors to detect shocks or vibrations, to allow a robot to react and balance/stabilise itself. Mobile robots could use force sensors in navigation as well, although touch sensors are more common.","title":"Force"},{"location":"week-2/fl-progrobot-w2-step04/#touch","text":"Touch sensors allow robots to detect physical interactions between their body and objects in their surroundings. Capacitive touch sensors use conductive properties to detect touches, most commonly from a human's touch, but any object that can conduct electricity will work. Resistive touch sensors do not use electrical properties, but instead detect touches based on pressure applied to the plate. This type of sensor can allow a robot to navigate its surroundings, even if the object touching the sensor does not conduct electricity.","title":"Touch"},{"location":"week-2/fl-progrobot-w2-step04/#detecting-the-environment","text":"Robots can use measurements of the environment around them to influence their behaviour, or just to collect data for analysis.","title":"Detecting the environment"},{"location":"week-2/fl-progrobot-w2-step04/#temperature","text":"Temperature sensors can be used in a variety of contexts, not just as data collection for scientific experiments. A rover on Mars can use its temperature sensor to evaluate the terrain it is rolling over; if it detects a drop in temperature it can reduce the torque on its wheels to prepare for ice. A robot designed to fight fires could use a temperature sensor to direct itself towards the hottest parts of a burning building, where it will be most effective.","title":"Temperature"},{"location":"week-2/fl-progrobot-w2-step04/#light","text":"Another detectable property of the environment is light. If a robot has different tasks to accomplish at night than in the day, it could detect decreasing light levels and change its behaviour to night mode. Changes in light can also indicate a change in surroundings; a robot designed to explore houses in disaster zones could use light sensors to help navigate around a home that has collapsed, by directing itself towards the light to get out of tight spaces.","title":"Light"},{"location":"week-2/fl-progrobot-w2-step04/#sound","text":"Sound sensors act similarly to microphones, but are often attached to circuits that compare the amplitude of the sound to a threshold value, returning the result of that comparison to the robot. The higher the amplitude, the louder the noise. This could be used by a robot designed to study wildlife; detecting and following loud noises may be one of the pieces of data that is used to locate wildlife. A more complex use would be a sound sensor for speech recognition, responding to commands spoken by a user.","title":"Sound"},{"location":"week-2/fl-progrobot-w2-step04/#chemical","text":"Robots can also use specialised sensors to detect certain chemical properties. For example, pH sensors detect the acidity or alkalinity of the environment around a robot. Scientific robots could use this to check the quality of rivers or soil in remote places. Carbon monoxide is poisonous, and robots equipped to sense this gas can be used to monitor potentially dangerous environments where human explorers would be at risk.","title":"Chemical"},{"location":"week-2/fl-progrobot-w2-step04/#object-proximity","text":"Mobile robots have to navigate the world around them, often autonomously, and there are sensors that help them detect the proximity of other objects around them.","title":"Object proximity"},{"location":"week-2/fl-progrobot-w2-step04/#infrared-sensors","text":"Infrared sensors detect changes in the levels of infrared radiation captured by the device. These changes are caused when an object (often a living thing) that is hotter than the background passes through the sensor's field of view.","title":"Infrared sensors"},{"location":"week-2/fl-progrobot-w2-step04/#ultrasonic-distance-sensors","text":"A better sensor for robots that have to navigate around inanimate objects is the ultrasonic distance sensor (UDS). This type of sensor emits high-frequency noises that rebound off objects in the surrounding area and return to the robot. This is how bats sense the world when they are flying at night. You are going to use a UDS in your buggy, and in the next step you will see how they work in greater detail.","title":"Ultrasonic distance sensors"},{"location":"week-2/fl-progrobot-w2-step04/#discussion","text":"Pick one of the types of sensor you have seen in this step. Think of another use of that sensor in robotics, from past experience or from your imagination. Share your ideas in the comments section.","title":"Discussion"},{"location":"week-2/fl-progrobot-w2-step05/","text":"Autonomous robots So far this week you have been exploring how robots sense the world around them. In this step you are going to look at why it benefits robots to sense the world around them, and explore the world of autonomous robots. Autonomy Autonomy is... freedom from external control or influence; independence. Autonomous robots are robots that operate and perform their tasks without intervention from a human controller. These robots use sensors and algorithms to navigate, make decisions, and perform their tasks. Space rovers Robots can venture into environments that are extremely hostile to humans, allowing us to gather information and study important environments we wouldn't otherwise be able to. Extraterrestrial exploration is one area in which robots are making a huge impact. Robotic space rovers are able to collect data and send it back to scientists on Earth for study. Autonomy allows space rovers to make decisions and perform time-sensitive tasks without the time lag that would be involved in sending them signals from Earth. Sensors and tasks The primary directive for space rovers is data collection . They also need the ability to navigate to achieve this mission. Cameras on top of the rover take images and video of the surface of the planet, to study the landscape and terrain. Microscopic cameras take extreme close-ups of soil and rocks, showing minerals and textures on their surfaces. Light spectrometers analyse the properties of soil and air by examining the light they absorb and emit. Air quality, humidity, barometric pressure, and temperature sensors take readings of these environmental properties, to establish weather patterns on a seasonal basis. You can see a full list of instruments on the Curiosity Mars rover here . Driverless cars Autonomous robots can use clever algorithm design to make decisions much more quickly than a human. This can improve safety, and one of the most promising uses is driverless cars . The first driverless car was dreamt up in 1938, over 80 years ago. By 1958, there was a working model: the car could operate without a driver, and was propelled by electromagnetic fields generated by cables embedded in the road. Fast-forward to current technology, and algorithms are running the show. A lot of cars now on the road have semi-autonomous features, such as drive assist and assisted parking and braking. Truly driverless cars are now in development by many different companies. These systems are being tested and tweaked and are expected to be ready for general use as robotaxis in the next decade, although consumers will have to wait a bit longer to drive one themselves. Sensors and tasks Driverless cars combine an array of sensors to collect a remarkable amount of information about their surroundings. Radar sensors around the edge of the car monitor the positions of nearby vehicles. Video cameras monitor less regular stimuli, such as road signs and pedestrians. Light detection and ranging (LIDAR) sensors, which use lasers in the same way as UDS uses ultrasound, are used to check for the edge of the road and road markings, which are typically white and reflect light well. Ultrasonic distance sensors are used near the wheels to detect kerbs and other vehicles while parking. All of the data collected by these sensors is processed by an on-board computer, which will adjust the steering, acceleration, and braking accordingly. Rescue robots Rescue robots can be sent into disaster zones to search for life. These robots are deployed into situations that are extremely dangerous but in which it is essential to save lives, such as house and forest fires, earthquake zones, and tsunami or hurricane landing zones. These robots are designed specifically for a single type of disaster, so this category covers a wide range of robots. Sensors and tasks Due to the wide range of robots in this category, this breakdown will be more general. These robots have a variety of sensors that are used to navigate the terrain, detecting obstacles and dangerous terrain so that they can be avoided. The movement apparatus in these robots is often one of the robot's most complex parts, making them able to roll or swim around many obstacles, or even move them if necessary. Aquatic rescue robots use propulsion systems to move through the water; land rescue robots are often equipped with treads that roll over difficult terrain much more easily than wheels do. Finally, an array of sensors is included to allow the robots to make decisions about where to investigate and how to get there; you will have seen a few of these uses in the earlier step on sensors. Other autonomous robots Another use for autonomous robots is on production lines in factories. What sensors would they use? What tasks do they perform? From your own experience, or by doing some research, answer the question above and post your thoughts in the comments section.","title":"Autonomous robots"},{"location":"week-2/fl-progrobot-w2-step05/#autonomous-robots","text":"So far this week you have been exploring how robots sense the world around them. In this step you are going to look at why it benefits robots to sense the world around them, and explore the world of autonomous robots.","title":"Autonomous robots"},{"location":"week-2/fl-progrobot-w2-step05/#autonomy","text":"Autonomy is... freedom from external control or influence; independence. Autonomous robots are robots that operate and perform their tasks without intervention from a human controller. These robots use sensors and algorithms to navigate, make decisions, and perform their tasks.","title":"Autonomy"},{"location":"week-2/fl-progrobot-w2-step05/#space-rovers","text":"Robots can venture into environments that are extremely hostile to humans, allowing us to gather information and study important environments we wouldn't otherwise be able to. Extraterrestrial exploration is one area in which robots are making a huge impact. Robotic space rovers are able to collect data and send it back to scientists on Earth for study. Autonomy allows space rovers to make decisions and perform time-sensitive tasks without the time lag that would be involved in sending them signals from Earth. Sensors and tasks The primary directive for space rovers is data collection . They also need the ability to navigate to achieve this mission. Cameras on top of the rover take images and video of the surface of the planet, to study the landscape and terrain. Microscopic cameras take extreme close-ups of soil and rocks, showing minerals and textures on their surfaces. Light spectrometers analyse the properties of soil and air by examining the light they absorb and emit. Air quality, humidity, barometric pressure, and temperature sensors take readings of these environmental properties, to establish weather patterns on a seasonal basis. You can see a full list of instruments on the Curiosity Mars rover here .","title":"Space rovers"},{"location":"week-2/fl-progrobot-w2-step05/#driverless-cars","text":"Autonomous robots can use clever algorithm design to make decisions much more quickly than a human. This can improve safety, and one of the most promising uses is driverless cars . The first driverless car was dreamt up in 1938, over 80 years ago. By 1958, there was a working model: the car could operate without a driver, and was propelled by electromagnetic fields generated by cables embedded in the road. Fast-forward to current technology, and algorithms are running the show. A lot of cars now on the road have semi-autonomous features, such as drive assist and assisted parking and braking. Truly driverless cars are now in development by many different companies. These systems are being tested and tweaked and are expected to be ready for general use as robotaxis in the next decade, although consumers will have to wait a bit longer to drive one themselves.","title":"Driverless cars"},{"location":"week-2/fl-progrobot-w2-step05/#sensors-and-tasks","text":"Driverless cars combine an array of sensors to collect a remarkable amount of information about their surroundings. Radar sensors around the edge of the car monitor the positions of nearby vehicles. Video cameras monitor less regular stimuli, such as road signs and pedestrians. Light detection and ranging (LIDAR) sensors, which use lasers in the same way as UDS uses ultrasound, are used to check for the edge of the road and road markings, which are typically white and reflect light well. Ultrasonic distance sensors are used near the wheels to detect kerbs and other vehicles while parking. All of the data collected by these sensors is processed by an on-board computer, which will adjust the steering, acceleration, and braking accordingly.","title":"Sensors and tasks"},{"location":"week-2/fl-progrobot-w2-step05/#rescue-robots","text":"Rescue robots can be sent into disaster zones to search for life. These robots are deployed into situations that are extremely dangerous but in which it is essential to save lives, such as house and forest fires, earthquake zones, and tsunami or hurricane landing zones. These robots are designed specifically for a single type of disaster, so this category covers a wide range of robots.","title":"Rescue robots"},{"location":"week-2/fl-progrobot-w2-step05/#sensors-and-tasks_1","text":"Due to the wide range of robots in this category, this breakdown will be more general. These robots have a variety of sensors that are used to navigate the terrain, detecting obstacles and dangerous terrain so that they can be avoided. The movement apparatus in these robots is often one of the robot's most complex parts, making them able to roll or swim around many obstacles, or even move them if necessary. Aquatic rescue robots use propulsion systems to move through the water; land rescue robots are often equipped with treads that roll over difficult terrain much more easily than wheels do. Finally, an array of sensors is included to allow the robots to make decisions about where to investigate and how to get there; you will have seen a few of these uses in the earlier step on sensors.","title":"Sensors and tasks"},{"location":"week-2/fl-progrobot-w2-step05/#other-autonomous-robots","text":"Another use for autonomous robots is on production lines in factories. What sensors would they use? What tasks do they perform? From your own experience, or by doing some research, answer the question above and post your thoughts in the comments section.","title":"Other autonomous robots"},{"location":"week-2/fl-progrobot-w2-step06/","text":"Ultrasonic distance sensors Your robot buggy will use an ultrasonic distance sensor (UDS) to help it navigate the physical world. In this step, you'll look at how these work. Ultrasound A UDS uses ultrasound to measure distances. Sound travels through the air in a wave pattern ; measurements are made by examining the properties of the pattern over space and time. As the sound travels, the particles in the air oscillate back and forth. This is often represented instead as a wave moving up and down on a graph. A sound's frequency is the number of oscillations per second. Frequency is measured in hertz (Hz); 1Hz corresponds to one oscillation per second. Ultrasound refers to any sound that has a frequency above the range of human hearing. This level varies from person to person, but on average, any sound with a frequency of 20kHz (20,000 oscillations a second) or above is considered ultrasound. The uses of ultrasound are many: doctors use the sound waves to scan inside human bodies, robots can use them to navigate the world, and engineers use them to reinforce metals by compressing the particles. Ultrasound and ultrasonic distance sensors A UDS works by sending out a burst of ultrasound. This sound will travel through air, but reflect back (echo) off surrounding objects. The sensor can detect the echo when it returns. Using a measure of the time between the outgoing burst and the returning echo, and knowing the speed of sound, you can calculate how far away an object is from the sensor. Commonly, a UDS requires two components to do this: an emitter and a receiver. You can see this in the picture above; the two silver cylinders on the front of the sensor are the emitter and receiver. A particular advantage of these sensors over other distance measurers, specifically those that use light, is that a UDS is not affected by the colour of the object that the signal reflects off. However, errors can occur if the object can reflect sound away from the receiver. How to use a UDS Now that you have a better idea of what a UDS is and how it works, you can move on to a more practical examination of how to use one with your buggy. A UDS typically has four pins: VCC needs to be connected to a 5V pin, in order to power the device Trig is the pin that triggers the emission of the ultrasound burst Echo is the pin that provides an output from the device; it outputs at 3.3V or 5V, depending on the UDS model GND is the ground pin, used to complete the circuit If the UDS is 5V-tolerant, this causes some issues because the echo pin will output 5V and the Raspberry Pi can only handle 3.3V. This means you will have to use some resistors to create a voltage divider, also known as a potential divider. Make sure to check the voltage tolerance of your UDS; the HC-SR04 sensor will need a voltage divider. A 3V3-tolerant sensor, such as the HC-SR04P, will work without a voltage divider. Voltage dividers A voltage (or potential) divider can split a voltage into two smaller voltages by using multiple resistors. The diagram below shows a single resistor connected to a 5V pin. The voltage across the resistor is 5V: The diagram below shows how the voltage can be split by using two resistors wired in series. As both resistors are the same, the voltage is split equally between the two: By altering the resistors, you can tailor the voltage across any one of them to be anything you like. Here, you can see that I have split the voltage to give us almost exactly 3.3V across the second resistor: You can use the code below to work out the resistors you need: R1 = 1200 # Your current resistor (alter this) Vout = 3.3 # The voltage you are trying to achieve (always 3.3) across the resistor R2 Vin = 5 # The input voltage (always 5) R2 = (Vout * R1) / (Vin - Vout) print('The resistor you need is approximately', R2) The limitations of a UDS The biggest limitation of this type of sensor comes into play when the object that reflects the ultrasound is very close. In this case, the receiver might not pick up the sound when it is initially reflected off an object, and may instead detect the sound once it has rebounded off another object. This results in an inaccurately high distance reading. Test your voltage divider Using the code and formula above, decide what size resistors you would use to limit the voltage to 1V. Share your thinking and answers in the comments below.","title":"Ultrasonic distance sensors"},{"location":"week-2/fl-progrobot-w2-step06/#ultrasonic-distance-sensors","text":"Your robot buggy will use an ultrasonic distance sensor (UDS) to help it navigate the physical world. In this step, you'll look at how these work.","title":"Ultrasonic distance sensors"},{"location":"week-2/fl-progrobot-w2-step06/#ultrasound","text":"A UDS uses ultrasound to measure distances. Sound travels through the air in a wave pattern ; measurements are made by examining the properties of the pattern over space and time. As the sound travels, the particles in the air oscillate back and forth. This is often represented instead as a wave moving up and down on a graph. A sound's frequency is the number of oscillations per second. Frequency is measured in hertz (Hz); 1Hz corresponds to one oscillation per second. Ultrasound refers to any sound that has a frequency above the range of human hearing. This level varies from person to person, but on average, any sound with a frequency of 20kHz (20,000 oscillations a second) or above is considered ultrasound. The uses of ultrasound are many: doctors use the sound waves to scan inside human bodies, robots can use them to navigate the world, and engineers use them to reinforce metals by compressing the particles.","title":"Ultrasound"},{"location":"week-2/fl-progrobot-w2-step06/#ultrasound-and-ultrasonic-distance-sensors","text":"A UDS works by sending out a burst of ultrasound. This sound will travel through air, but reflect back (echo) off surrounding objects. The sensor can detect the echo when it returns. Using a measure of the time between the outgoing burst and the returning echo, and knowing the speed of sound, you can calculate how far away an object is from the sensor. Commonly, a UDS requires two components to do this: an emitter and a receiver. You can see this in the picture above; the two silver cylinders on the front of the sensor are the emitter and receiver. A particular advantage of these sensors over other distance measurers, specifically those that use light, is that a UDS is not affected by the colour of the object that the signal reflects off. However, errors can occur if the object can reflect sound away from the receiver.","title":"Ultrasound and ultrasonic distance sensors"},{"location":"week-2/fl-progrobot-w2-step06/#how-to-use-a-uds","text":"Now that you have a better idea of what a UDS is and how it works, you can move on to a more practical examination of how to use one with your buggy. A UDS typically has four pins: VCC needs to be connected to a 5V pin, in order to power the device Trig is the pin that triggers the emission of the ultrasound burst Echo is the pin that provides an output from the device; it outputs at 3.3V or 5V, depending on the UDS model GND is the ground pin, used to complete the circuit If the UDS is 5V-tolerant, this causes some issues because the echo pin will output 5V and the Raspberry Pi can only handle 3.3V. This means you will have to use some resistors to create a voltage divider, also known as a potential divider. Make sure to check the voltage tolerance of your UDS; the HC-SR04 sensor will need a voltage divider. A 3V3-tolerant sensor, such as the HC-SR04P, will work without a voltage divider.","title":"How to use a UDS"},{"location":"week-2/fl-progrobot-w2-step06/#voltage-dividers","text":"A voltage (or potential) divider can split a voltage into two smaller voltages by using multiple resistors. The diagram below shows a single resistor connected to a 5V pin. The voltage across the resistor is 5V: The diagram below shows how the voltage can be split by using two resistors wired in series. As both resistors are the same, the voltage is split equally between the two: By altering the resistors, you can tailor the voltage across any one of them to be anything you like. Here, you can see that I have split the voltage to give us almost exactly 3.3V across the second resistor: You can use the code below to work out the resistors you need: R1 = 1200 # Your current resistor (alter this) Vout = 3.3 # The voltage you are trying to achieve (always 3.3) across the resistor R2 Vin = 5 # The input voltage (always 5) R2 = (Vout * R1) / (Vin - Vout) print('The resistor you need is approximately', R2)","title":"Voltage dividers"},{"location":"week-2/fl-progrobot-w2-step06/#the-limitations-of-a-uds","text":"The biggest limitation of this type of sensor comes into play when the object that reflects the ultrasound is very close. In this case, the receiver might not pick up the sound when it is initially reflected off an object, and may instead detect the sound once it has rebounded off another object. This results in an inaccurately high distance reading.","title":"The limitations of a UDS"},{"location":"week-2/fl-progrobot-w2-step06/#test-your-voltage-divider","text":"Using the code and formula above, decide what size resistors you would use to limit the voltage to 1V. Share your thinking and answers in the comments below.","title":"Test your voltage divider"},{"location":"week-2/fl-progrobot-w2-step07/","text":"Resources Video Video subtitles Attaching the UDS to the buggy Now that you have read about how a UDS works, you are going to connect one to your Raspberry Pi. Make sure to check whether you need a voltage divider: check the model number or post a photo in the comments if you are unsure. What you will need For this step, you will need the following items: Ultrasonic distance sensor Four female-to-female jumper leads If your UDS is 5V, you will also need: Two different resistors to split the voltage (e.g. a 330-ohm resistor and a 620-ohm resistor) Two more female-to-female (six in total) Soldering iron and solder Tape Wiring the UDS It is best to set up the UDS with the Raspberry Pi switched off, especially if your UDS is 5V. Otherwise, if you make a mistake with your wiring and the Raspberry Pi is turned on, you might damage it or the UDS. As discussed previously, a typical UDS has four pins: VCC , trig , echo , and GND . All of these pins need to be connected to your Raspberry Pi. The trig and echo pins can be wired to any available GPIO pins on your Pi, though if you choose different pins to the set-up below, the diagrams won't match. You'll also need to remember what pins you used and replace the pin numbers in the code accordingly. Refer to the diagrams in this article or use a reference board that fits over the GPIO pins if you aren't sure which pins on the Raspberry Pi to use. SD Card End 3V3 5V GPIO2 5V GPIO3 GND GPIO4 GPIO14 GND GPIO15 GPIO17 GPIO18 GPIO27 GND GPIO22 GPIO23 3V3 GPIO24 GPIO10 GND GPIO9 GPIO25 GPIO11 GPIO8 GND GPIO7 GPIO0 GPIO1 GPIO5 GND GPIO6 GPIO12 GPIO13 GND GPIO19 GPIO16 GPIO26 GPIO20 GND GPIO21 USB port end Wiring the VCC, trig, and GND pins Start by connecting the VCC pin on your UDS to a 5V pin on your Raspberry Pi, using a female-to-female jumper lead. Connect the trig pin on the UDS to an available GPIO pin on your Raspberry Pi; I've used GPIO 4 . Connect the GND pin from your UDS to a ground pin on your Raspberry Pi. The instructions for wiring the echo pin are different depending on whether the UDS is 3.3V-tolerant or 5V-tolerant . Wiring the echo pin on a 5V UDS If the output of the echo pin is 5V, you need to reduce the output voltage to a maximum of 3.3V . For the purposes of this example, I'm going to use a 330-ohm resistor and a 620-ohm resistor. You can use different resistors to these, but you must ensure that the voltage across the larger resistor has been reduced to 3.3V or just below, using the voltage divider algorithm seen previously. The first thing to do is to solder the pair of resistors together. Then you need to solder a female jumper lead to the other end of each resistor. This part might be easier to do with two people or by using a helping hand . Once the solder has cooled, add tape to secure and insulate all of the joins. Next, attach a third female jumper lead to the join between the two resistors. Add tape to secure this join in place. Now you need to attach the jumper leads to your UDS and the Raspberry Pi. The lead that joins to the smaller of the two resistors needs to go into the echo pin on your UDS The lead that branches out from between the resistors should go into GPIO 17 The lead that comes out of the larger of the two resistors must go into a ground pin on your Raspberry Pi The diagram below shows you the complete set-up for a 5V UDS: Wiring the echo pin on a 3.3V UDS Wiring a 3.3V UDS is fairly simple, as the output voltage of the echo pin does not need to be reduced. The diagram below shows you the complete set-up for a 3.3V UDS, with the echo pin connected to GPIO 17 on the Raspberry Pi: Securing the UDS to the chassis Now that your UDS is connected to your Raspberry Pi, you will need to attach the UDS to the front of the chassis so that your robot can detect objects in front of the buggy. Mark where you want the emitter and receiver (the two silver cylinders from the diagram above) to protrude from the chassis. Cut two holes into the chassis that are just big enough for the emitter and receiver to poke through, then push the cylinders through the holes. You can also add tape to attach the UDS more securely to the chassis. Checking the connections It's easy for the jumper leads to come loose from the Raspberry Pi while you are moving parts of the robot around, so double-check that all your pins are connected properly before turning on your Pi. Discussion Share any issues you had with wiring the UDS or attaching it to the chassis in the comments.","title":"Attaching the UDS to the buggy"},{"location":"week-2/fl-progrobot-w2-step07/#attaching-the-uds-to-the-buggy","text":"Now that you have read about how a UDS works, you are going to connect one to your Raspberry Pi. Make sure to check whether you need a voltage divider: check the model number or post a photo in the comments if you are unsure.","title":"Attaching the UDS to the buggy"},{"location":"week-2/fl-progrobot-w2-step07/#what-you-will-need","text":"For this step, you will need the following items: Ultrasonic distance sensor Four female-to-female jumper leads If your UDS is 5V, you will also need: Two different resistors to split the voltage (e.g. a 330-ohm resistor and a 620-ohm resistor) Two more female-to-female (six in total) Soldering iron and solder Tape","title":"What you will need"},{"location":"week-2/fl-progrobot-w2-step07/#wiring-the-uds","text":"It is best to set up the UDS with the Raspberry Pi switched off, especially if your UDS is 5V. Otherwise, if you make a mistake with your wiring and the Raspberry Pi is turned on, you might damage it or the UDS. As discussed previously, a typical UDS has four pins: VCC , trig , echo , and GND . All of these pins need to be connected to your Raspberry Pi. The trig and echo pins can be wired to any available GPIO pins on your Pi, though if you choose different pins to the set-up below, the diagrams won't match. You'll also need to remember what pins you used and replace the pin numbers in the code accordingly. Refer to the diagrams in this article or use a reference board that fits over the GPIO pins if you aren't sure which pins on the Raspberry Pi to use. SD Card End 3V3 5V GPIO2 5V GPIO3 GND GPIO4 GPIO14 GND GPIO15 GPIO17 GPIO18 GPIO27 GND GPIO22 GPIO23 3V3 GPIO24 GPIO10 GND GPIO9 GPIO25 GPIO11 GPIO8 GND GPIO7 GPIO0 GPIO1 GPIO5 GND GPIO6 GPIO12 GPIO13 GND GPIO19 GPIO16 GPIO26 GPIO20 GND GPIO21 USB port end","title":"Wiring the UDS"},{"location":"week-2/fl-progrobot-w2-step07/#wiring-the-vcc-trig-and-gnd-pins","text":"Start by connecting the VCC pin on your UDS to a 5V pin on your Raspberry Pi, using a female-to-female jumper lead. Connect the trig pin on the UDS to an available GPIO pin on your Raspberry Pi; I've used GPIO 4 . Connect the GND pin from your UDS to a ground pin on your Raspberry Pi. The instructions for wiring the echo pin are different depending on whether the UDS is 3.3V-tolerant or 5V-tolerant .","title":"Wiring the VCC, trig, and GND pins"},{"location":"week-2/fl-progrobot-w2-step07/#wiring-the-echo-pin-on-a-5v-uds","text":"If the output of the echo pin is 5V, you need to reduce the output voltage to a maximum of 3.3V . For the purposes of this example, I'm going to use a 330-ohm resistor and a 620-ohm resistor. You can use different resistors to these, but you must ensure that the voltage across the larger resistor has been reduced to 3.3V or just below, using the voltage divider algorithm seen previously. The first thing to do is to solder the pair of resistors together. Then you need to solder a female jumper lead to the other end of each resistor. This part might be easier to do with two people or by using a helping hand . Once the solder has cooled, add tape to secure and insulate all of the joins. Next, attach a third female jumper lead to the join between the two resistors. Add tape to secure this join in place. Now you need to attach the jumper leads to your UDS and the Raspberry Pi. The lead that joins to the smaller of the two resistors needs to go into the echo pin on your UDS The lead that branches out from between the resistors should go into GPIO 17 The lead that comes out of the larger of the two resistors must go into a ground pin on your Raspberry Pi The diagram below shows you the complete set-up for a 5V UDS:","title":"Wiring the echo pin on a 5V UDS"},{"location":"week-2/fl-progrobot-w2-step07/#wiring-the-echo-pin-on-a-33v-uds","text":"Wiring a 3.3V UDS is fairly simple, as the output voltage of the echo pin does not need to be reduced. The diagram below shows you the complete set-up for a 3.3V UDS, with the echo pin connected to GPIO 17 on the Raspberry Pi:","title":"Wiring the echo pin on a 3.3V UDS"},{"location":"week-2/fl-progrobot-w2-step07/#securing-the-uds-to-the-chassis","text":"Now that your UDS is connected to your Raspberry Pi, you will need to attach the UDS to the front of the chassis so that your robot can detect objects in front of the buggy. Mark where you want the emitter and receiver (the two silver cylinders from the diagram above) to protrude from the chassis. Cut two holes into the chassis that are just big enough for the emitter and receiver to poke through, then push the cylinders through the holes. You can also add tape to attach the UDS more securely to the chassis.","title":"Securing the UDS to the chassis"},{"location":"week-2/fl-progrobot-w2-step07/#checking-the-connections","text":"It's easy for the jumper leads to come loose from the Raspberry Pi while you are moving parts of the robot around, so double-check that all your pins are connected properly before turning on your Pi.","title":"Checking the connections"},{"location":"week-2/fl-progrobot-w2-step07/#discussion","text":"Share any issues you had with wiring the UDS or attaching it to the chassis in the comments.","title":"Discussion"},{"location":"week-2/fl-progrobot-w2-step08/","text":"Resources Video Video subtitles Programming the UDS Now that you've attached the ultrasonic distance sensor (UDS), you need to test that it can detect objects that are directly in front of it at different distances. Testing the UDS First, you need to check that the UDS is working correctly while the robot is stationary. To interact with the UDS, you will be using the GPIO Zero library. Setting up the program 1. In a new Python 3 file, import the libraries required for this program. from gpiozero import InputDevice, OutputDevice from time import sleep, time InputDevice and OutputDevice will be used to communicate with the trig and echo pins. You will also need time and sleep to calculate the time taken for the ultrasound to be emitted and received. 2. Set up the trig and echo pins using the GPIO pins you connected them to on your Raspberry Pi. I used pins 4 and 17 respectively, but you may have used different pins. trig = OutputDevice(4) echo = InputDevice(17) sleep(2) The sleep(2) is there to let the sensor settle when the program starts, so that the readings are accurate. Transmitting and receiving the ultrasound 3. Create a function that will be used to calculate how long it takes for the ultrasound to be transmitted and received i.e. one pulse. Initialise the variables for storing the start and end duration of a pulse. Then set the trig pin to high for 10\u03bcs (microseconds), which prepares the internal clock of the UDS. def get_pulse_time(): pulse_start, pulse_end = 0, 0 trig.on() sleep(0.00001) trig.off() As soon as the trig pin is set to low, a burst of ultrasound is sent from the emitter, and this sound starts to travel through the air. Once the ultrasound has finished being emitted, the UDS sets the echo pin to high. At this point, you need to record the start time. 4. Use a while loop inside the function to record the start time. while echo.is_active == False: pulse_start = time() You can use the is_active command to check if a pin is set to high (which returns True ) or low (which returns False ). The above code works by repeatedly replacing the value of pulse_start with the current time until the echo pin is active. This means that the final value of pulse_start is the time at which the echo pin is set to high. If the ultrasound hits an object, it is reflected back to the sensor. As soon as the receiver picks up the ultrasound, the echo pin is set to low and the program must record the end time. 5. Inside the function, create another while loop that keeps replacing the end time until the echo pin is set to low. while echo.is_active == True: pulse_end = time() 6. Finally, the function should return the amount of time it took for the pulse of ultrasound to be sent and received. return pulse_end - pulse_start All of the code from steps 3 to 6 should be inside the function you created called get_pulse_time() . 7. Test the program by running it and then typing the following into the Python shell (known as the REPL if you are using Mu). print(get_pulse_time()) Try typing the above line of code when your hand is at different distances from the front of the UDS. You should get smaller values as your hand approaches the sensor. Calculating the distance You can use a formula to calculate the distance the sensor is from an object, starting with the speed equation: This can be rearranged to make: but as the sound has to travel to the object and back, you need to divide this distance by 2: The speed of sound in air will vary depending on the conditions, but it tends to hover at around 343 metres per second. Putting the formula into practice 8. Create another function to calculate the distance. def calculate_distance(duration): speed = 343 distance = speed * duration / 2 # calculate distance in metres return distance Using a different function to calculate this distance is good coding practice, as this function can be tested separately, and can easily be reused multiple times within the program. 9. Add an infinite loop to the bottom of the program to test that everything works. while True: duration = get_pulse_time() distance = calculate_distance(duration) sleep(0.06) print(distance) You need the sleep command, as the UDS requires a short wait before it can be used again. The final program Your full code should now look similar to this finished program . 10 . Run your code and you should see a stream of numbers showing you the distance of an object from the sensor in metres. Test this by moving a large, flat object such as a book closer to and further from the distance sensor. Testing the distances What range of values is your program outputting? What happens if you place an object really close to, or far away from, the UDS? Share your answers in the comments below.","title":"Programming the UDS"},{"location":"week-2/fl-progrobot-w2-step08/#programming-the-uds","text":"Now that you've attached the ultrasonic distance sensor (UDS), you need to test that it can detect objects that are directly in front of it at different distances.","title":"Programming the UDS"},{"location":"week-2/fl-progrobot-w2-step08/#testing-the-uds","text":"First, you need to check that the UDS is working correctly while the robot is stationary. To interact with the UDS, you will be using the GPIO Zero library.","title":"Testing the UDS"},{"location":"week-2/fl-progrobot-w2-step08/#setting-up-the-program","text":"1. In a new Python 3 file, import the libraries required for this program. from gpiozero import InputDevice, OutputDevice from time import sleep, time InputDevice and OutputDevice will be used to communicate with the trig and echo pins. You will also need time and sleep to calculate the time taken for the ultrasound to be emitted and received. 2. Set up the trig and echo pins using the GPIO pins you connected them to on your Raspberry Pi. I used pins 4 and 17 respectively, but you may have used different pins. trig = OutputDevice(4) echo = InputDevice(17) sleep(2) The sleep(2) is there to let the sensor settle when the program starts, so that the readings are accurate.","title":"Setting up the program"},{"location":"week-2/fl-progrobot-w2-step08/#transmitting-and-receiving-the-ultrasound","text":"3. Create a function that will be used to calculate how long it takes for the ultrasound to be transmitted and received i.e. one pulse. Initialise the variables for storing the start and end duration of a pulse. Then set the trig pin to high for 10\u03bcs (microseconds), which prepares the internal clock of the UDS. def get_pulse_time(): pulse_start, pulse_end = 0, 0 trig.on() sleep(0.00001) trig.off() As soon as the trig pin is set to low, a burst of ultrasound is sent from the emitter, and this sound starts to travel through the air. Once the ultrasound has finished being emitted, the UDS sets the echo pin to high. At this point, you need to record the start time. 4. Use a while loop inside the function to record the start time. while echo.is_active == False: pulse_start = time() You can use the is_active command to check if a pin is set to high (which returns True ) or low (which returns False ). The above code works by repeatedly replacing the value of pulse_start with the current time until the echo pin is active. This means that the final value of pulse_start is the time at which the echo pin is set to high. If the ultrasound hits an object, it is reflected back to the sensor. As soon as the receiver picks up the ultrasound, the echo pin is set to low and the program must record the end time. 5. Inside the function, create another while loop that keeps replacing the end time until the echo pin is set to low. while echo.is_active == True: pulse_end = time() 6. Finally, the function should return the amount of time it took for the pulse of ultrasound to be sent and received. return pulse_end - pulse_start All of the code from steps 3 to 6 should be inside the function you created called get_pulse_time() . 7. Test the program by running it and then typing the following into the Python shell (known as the REPL if you are using Mu). print(get_pulse_time()) Try typing the above line of code when your hand is at different distances from the front of the UDS. You should get smaller values as your hand approaches the sensor.","title":"Transmitting and receiving the ultrasound"},{"location":"week-2/fl-progrobot-w2-step08/#calculating-the-distance","text":"You can use a formula to calculate the distance the sensor is from an object, starting with the speed equation: This can be rearranged to make: but as the sound has to travel to the object and back, you need to divide this distance by 2: The speed of sound in air will vary depending on the conditions, but it tends to hover at around 343 metres per second.","title":"Calculating the distance"},{"location":"week-2/fl-progrobot-w2-step08/#putting-the-formula-into-practice","text":"8. Create another function to calculate the distance. def calculate_distance(duration): speed = 343 distance = speed * duration / 2 # calculate distance in metres return distance Using a different function to calculate this distance is good coding practice, as this function can be tested separately, and can easily be reused multiple times within the program. 9. Add an infinite loop to the bottom of the program to test that everything works. while True: duration = get_pulse_time() distance = calculate_distance(duration) sleep(0.06) print(distance) You need the sleep command, as the UDS requires a short wait before it can be used again.","title":"Putting the formula into practice"},{"location":"week-2/fl-progrobot-w2-step08/#the-final-program","text":"Your full code should now look similar to this finished program . 10 . Run your code and you should see a stream of numbers showing you the distance of an object from the sensor in metres. Test this by moving a large, flat object such as a book closer to and further from the distance sensor.","title":"The final program"},{"location":"week-2/fl-progrobot-w2-step08/#testing-the-distances","text":"What range of values is your program outputting? What happens if you place an object really close to, or far away from, the UDS? Share your answers in the comments below.","title":"Testing the distances"},{"location":"week-2/fl-progrobot-w2-step09/","text":"Avoiding obstacles autonomously So far, you have created programs for moving the robot buggy and detecting objects at different distances. Now you are going to create a program for detecting and navigating around objects autonomously. Programming the motors and the UDS For this program, you will need to bring together some of the code you have written during the course to solve a new problem. To help you begin this process, consider the different parts of the problem: What components does your program need to interact with? What should the robot do if an object is not too close to it? How should the robot behave when an object is too close? Setting up the program 1. Copy the code from the last step into a new Python file. 2. Change the first line of code so that Robot is also imported from the gpiozero library to control the motors. from gpiozero import Robot, InputDevice, OutputDevice 3. After the trig and echo variables have been initialised, define the Robot using the GPIO pins for your left and right motors. robin = Robot(left=(8,7), right=(9,10)) You can use one of your working programs from week one to check that the GPIO pins of your motors are set correctly, as they may be different to the ones I've used above. Setting up a timer Next, you are going to create a timer so that your robot doesn't run forever, which is especially useful during the testing phases. 4. Add in these three variables just after you have initialised Robot : duration = 10 end_time = time() + duration running = True The value of duration is the number of seconds that the timer will run for. Calculate end_time by adding duration to the current time, which is obtained using the time() function. You will use the running variable later to specify when the program (and the robot) should stop running. Check your program so far against my version of the program after step 4 . The last changes you are going to make are going to all be within the while loop. How should the robot behave? The robot should, by default, move forwards, unless it detects an object that is too close. If an object is detected within a certain distance of the UDS, the robot should turn left or right to avoid the obstacle in front of it. How close is too close? The program currently calculates the distance of an object from the UDS in metres. You need to specify the threshold, in metres, at which an object is too close to the robot. For now, the threshold value I'm going to choose is 20 cm (0.2 metres); you can experiment with this value later. 5. Inside the while loop and before the sleep(0.06) command, use a selection statement to check if an object is less than 0.2 metres away. Instruct the robot to turn left for half a second if the distance is below the threshold value, and to move forwards otherwise. if distance < 0.2: robin.left() sleep(0.5) else: robin.forward() Using a sleep command here inside the if statement means that the robot will continue to turn left for a certain amount of time before checking for more obstructions. This should allow your robot enough time to turn clear of the object that was detected. 6. To stop the program from running forever, add the following code inside the while loop before the sleep(0.06) command. if time() >= end_time: running = False robin.stop() This checks if the current time is more than or equal to the end_time value specified at the start of the program. If so, it will change the value of running to False (which will stop the while loop from repeating) and then stop the motors. 7. Modify the while loop condition so that it stops repeating once running is set to False . Change the condition from: while True: to: while running: Your final code for the while loop should be: while running: duration = get_pulse_time() distance = calculate_distance(duration) if distance < 0.2: robin.left() sleep(0.5) else: robin.forward() if time() >= end_time: running = False robin.stop() sleep(0.06) Testing the program Try running the program, with the robot on a suitable surface. If the buggy is not behaving as expected, check that all the connections to the GPIO pins are correct before trying the code again. It may also be beneficial to run an earlier program that you know was working, to test whether the motors and UDS are still working as expected. Discussion How effective is your robot at avoiding objects? Can you think of any modifications that might help? Share your answers in the comments below, or let us know if you are having any issues.","title":"Avoiding obstacles autonomously"},{"location":"week-2/fl-progrobot-w2-step09/#avoiding-obstacles-autonomously","text":"So far, you have created programs for moving the robot buggy and detecting objects at different distances. Now you are going to create a program for detecting and navigating around objects autonomously.","title":"Avoiding obstacles autonomously"},{"location":"week-2/fl-progrobot-w2-step09/#programming-the-motors-and-the-uds","text":"For this program, you will need to bring together some of the code you have written during the course to solve a new problem. To help you begin this process, consider the different parts of the problem: What components does your program need to interact with? What should the robot do if an object is not too close to it? How should the robot behave when an object is too close?","title":"Programming the motors and the UDS"},{"location":"week-2/fl-progrobot-w2-step09/#setting-up-the-program","text":"1. Copy the code from the last step into a new Python file. 2. Change the first line of code so that Robot is also imported from the gpiozero library to control the motors. from gpiozero import Robot, InputDevice, OutputDevice 3. After the trig and echo variables have been initialised, define the Robot using the GPIO pins for your left and right motors. robin = Robot(left=(8,7), right=(9,10)) You can use one of your working programs from week one to check that the GPIO pins of your motors are set correctly, as they may be different to the ones I've used above.","title":"Setting up the program"},{"location":"week-2/fl-progrobot-w2-step09/#setting-up-a-timer","text":"Next, you are going to create a timer so that your robot doesn't run forever, which is especially useful during the testing phases. 4. Add in these three variables just after you have initialised Robot : duration = 10 end_time = time() + duration running = True The value of duration is the number of seconds that the timer will run for. Calculate end_time by adding duration to the current time, which is obtained using the time() function. You will use the running variable later to specify when the program (and the robot) should stop running. Check your program so far against my version of the program after step 4 . The last changes you are going to make are going to all be within the while loop.","title":"Setting up a timer"},{"location":"week-2/fl-progrobot-w2-step09/#how-should-the-robot-behave","text":"The robot should, by default, move forwards, unless it detects an object that is too close. If an object is detected within a certain distance of the UDS, the robot should turn left or right to avoid the obstacle in front of it. How close is too close? The program currently calculates the distance of an object from the UDS in metres. You need to specify the threshold, in metres, at which an object is too close to the robot. For now, the threshold value I'm going to choose is 20 cm (0.2 metres); you can experiment with this value later. 5. Inside the while loop and before the sleep(0.06) command, use a selection statement to check if an object is less than 0.2 metres away. Instruct the robot to turn left for half a second if the distance is below the threshold value, and to move forwards otherwise. if distance < 0.2: robin.left() sleep(0.5) else: robin.forward() Using a sleep command here inside the if statement means that the robot will continue to turn left for a certain amount of time before checking for more obstructions. This should allow your robot enough time to turn clear of the object that was detected. 6. To stop the program from running forever, add the following code inside the while loop before the sleep(0.06) command. if time() >= end_time: running = False robin.stop() This checks if the current time is more than or equal to the end_time value specified at the start of the program. If so, it will change the value of running to False (which will stop the while loop from repeating) and then stop the motors. 7. Modify the while loop condition so that it stops repeating once running is set to False . Change the condition from: while True: to: while running: Your final code for the while loop should be: while running: duration = get_pulse_time() distance = calculate_distance(duration) if distance < 0.2: robin.left() sleep(0.5) else: robin.forward() if time() >= end_time: running = False robin.stop() sleep(0.06)","title":"How should the robot behave?"},{"location":"week-2/fl-progrobot-w2-step09/#testing-the-program","text":"Try running the program, with the robot on a suitable surface. If the buggy is not behaving as expected, check that all the connections to the GPIO pins are correct before trying the code again. It may also be beneficial to run an earlier program that you know was working, to test whether the motors and UDS are still working as expected.","title":"Testing the program"},{"location":"week-2/fl-progrobot-w2-step09/#discussion","text":"How effective is your robot at avoiding objects? Can you think of any modifications that might help? Share your answers in the comments below, or let us know if you are having any issues.","title":"Discussion"},{"location":"week-2/fl-progrobot-w2-step10/","text":"Challenge: Improving the obstacle-avoidance program There are a number of modifications that will improve your robot's ability to avoid objects autonomously. Most of these require changes to the program from the previous step. First, I suggest making a copy of your program before modifying any of the code, in case something you try doesn't work out. Changing some of the values Begin by experimenting with different distance thresholds and sleep values, to see how that affects the performance of the robot. For example, the distance threshold of 0.2 metres used in the previous program may need to be increased slightly if your robot does not start to turn out of the way of an obstacle in time. You can also change the sleep value of 0.5 seconds, so that the robot continues turning for more or less time once the threshold value has been met. Changing the robot's behaviour Currently, the robot turns left for a set amount of time whenever an object is detected as being too close. This predictable behaviour has the potential to cause issues. One problem is that the robot might get stuck in an obstacle avoidance loop when turning by a fixed amount each time. In this situation, the robot keeps detecting the same obstacles over and over again, seemingly with no way to escape! There are a number of changes you can make to the robot's behaviour. Two steps forward, one step back One modification you can make is to instruct the robot to move backwards for a period of time before turning to avoid an object. This will give your robot a chance to avoid obstacles if it has found itself in a dead end. Another solution is to introduce random aspects into the robot's movements. Randomising the amount of time the robot turns Rather than turning left for a set amount of time, you can instruct the program to generate a random number of seconds within a certain range of values. To add this functionality, you will need to import the random library into your Python program. Use the function random.uniform(a, b) to return a random floating-point number, where a is the lowest value and b is the highest value. Choosing a random direction Another modification to the robot's behaviour is to allow the program to choose a random direction to turn once an obstacle has been detected. Instead of always turning left, the robot could be instructed to turn either left or right. How might you code this? Limitations of the UDS There are some limitations it is important to be aware of when using a UDS. Finding workarounds to these problems will ensure that your program is robust. Objects that are too close You may have noticed that an object that is really close to the UDS returns a much larger distance than expected. This occurs if an object is closer than the minimum distance a UDS can detect accurately; for the HC-SR04 and HC-SR04P models, the detection distance is from about 2 cm to 500 cm. Take a look at the distance values that are output when an object is very close to the UDS and see if you can find a solution within the program to pick up these objects. Objects that are to the side Another issue that your robot may run into is that, depending on the width of your robot, the UDS won't detect objects on either side of it that are going to be in the way. One solution to this would be to add an extra UDS to the front of the robot, so that there is one on each side of the chassis. This modification would also require the program to be adapted so that it is able to work with two UDSs. What improvements will you make? Improve your program using one of the ideas in this step: Change the distance threshold and/or sleep values Once your robot has detected an obstacle: Instruct it to move backwards before turning left Generate a random number of seconds for the robot to turn for Get the program to choose a random direction for the robot to turn in Find a solution for detecting objects that are closer than the minimum detection distance of your UDS Attach another UDS to the chassis and modify your program so it works with two UDSs Discussion Can you think of any other improvements that you could make? In the comments below, share the changes you made and add a link to your new code using Pastebin .","title":"Challenge: Improving the obstacle-avoidance program"},{"location":"week-2/fl-progrobot-w2-step10/#challenge-improving-the-obstacle-avoidance-program","text":"There are a number of modifications that will improve your robot's ability to avoid objects autonomously. Most of these require changes to the program from the previous step. First, I suggest making a copy of your program before modifying any of the code, in case something you try doesn't work out.","title":"Challenge: Improving the obstacle-avoidance program"},{"location":"week-2/fl-progrobot-w2-step10/#changing-some-of-the-values","text":"Begin by experimenting with different distance thresholds and sleep values, to see how that affects the performance of the robot. For example, the distance threshold of 0.2 metres used in the previous program may need to be increased slightly if your robot does not start to turn out of the way of an obstacle in time. You can also change the sleep value of 0.5 seconds, so that the robot continues turning for more or less time once the threshold value has been met.","title":"Changing some of the values"},{"location":"week-2/fl-progrobot-w2-step10/#changing-the-robots-behaviour","text":"Currently, the robot turns left for a set amount of time whenever an object is detected as being too close. This predictable behaviour has the potential to cause issues. One problem is that the robot might get stuck in an obstacle avoidance loop when turning by a fixed amount each time. In this situation, the robot keeps detecting the same obstacles over and over again, seemingly with no way to escape! There are a number of changes you can make to the robot's behaviour.","title":"Changing the robot's behaviour"},{"location":"week-2/fl-progrobot-w2-step10/#two-steps-forward-one-step-back","text":"One modification you can make is to instruct the robot to move backwards for a period of time before turning to avoid an object. This will give your robot a chance to avoid obstacles if it has found itself in a dead end. Another solution is to introduce random aspects into the robot's movements.","title":"Two steps forward, one step back"},{"location":"week-2/fl-progrobot-w2-step10/#randomising-the-amount-of-time-the-robot-turns","text":"Rather than turning left for a set amount of time, you can instruct the program to generate a random number of seconds within a certain range of values. To add this functionality, you will need to import the random library into your Python program. Use the function random.uniform(a, b) to return a random floating-point number, where a is the lowest value and b is the highest value.","title":"Randomising the amount of time the robot turns"},{"location":"week-2/fl-progrobot-w2-step10/#choosing-a-random-direction","text":"Another modification to the robot's behaviour is to allow the program to choose a random direction to turn once an obstacle has been detected. Instead of always turning left, the robot could be instructed to turn either left or right. How might you code this?","title":"Choosing a random direction"},{"location":"week-2/fl-progrobot-w2-step10/#limitations-of-the-uds","text":"There are some limitations it is important to be aware of when using a UDS. Finding workarounds to these problems will ensure that your program is robust.","title":"Limitations of the UDS"},{"location":"week-2/fl-progrobot-w2-step10/#objects-that-are-too-close","text":"You may have noticed that an object that is really close to the UDS returns a much larger distance than expected. This occurs if an object is closer than the minimum distance a UDS can detect accurately; for the HC-SR04 and HC-SR04P models, the detection distance is from about 2 cm to 500 cm. Take a look at the distance values that are output when an object is very close to the UDS and see if you can find a solution within the program to pick up these objects.","title":"Objects that are too close"},{"location":"week-2/fl-progrobot-w2-step10/#objects-that-are-to-the-side","text":"Another issue that your robot may run into is that, depending on the width of your robot, the UDS won't detect objects on either side of it that are going to be in the way. One solution to this would be to add an extra UDS to the front of the robot, so that there is one on each side of the chassis. This modification would also require the program to be adapted so that it is able to work with two UDSs.","title":"Objects that are to the side"},{"location":"week-2/fl-progrobot-w2-step10/#what-improvements-will-you-make","text":"Improve your program using one of the ideas in this step: Change the distance threshold and/or sleep values Once your robot has detected an obstacle: Instruct it to move backwards before turning left Generate a random number of seconds for the robot to turn for Get the program to choose a random direction for the robot to turn in Find a solution for detecting objects that are closer than the minimum detection distance of your UDS Attach another UDS to the chassis and modify your program so it works with two UDSs","title":"What improvements will you make?"},{"location":"week-2/fl-progrobot-w2-step10/#discussion","text":"Can you think of any other improvements that you could make? In the comments below, share the changes you made and add a link to your new code using Pastebin .","title":"Discussion"},{"location":"week-2/fl-progrobot-w2-step11/","text":"Quiz: How do distance sensors work? You have been learning about the functionality of a UDS this week, and have seen some examples of how one can be used for detecting objects. You will be able to test your knowledge of how a UDS functions in this quiz. Question 1 What does a UDS use to measure the time it takes for an object to be detected? Choices Radar No Radar uses radio waves to detect objects but a UDS does not Week 2, step 6 Ultrasound Yes N/A Week 2, step 6 Infrared light No An infrared distance sensor uses infrared light to measure the distance of an object but a UDS does not Week 2, step 6 Ultraviolet light No An UDS doesn't use ultraviolet light to measure the distance of objects Week 2, step 6 Question 2 Which one of these is an advantage of a UDS over other types of distance sensor? Choices It is much more compact than most other distance sensors No Different types of distance sensor can come in a range of sizes, depending on factors such as the range of the sensor Week 2, step 6 It is quicker at calculating the time taken for a signal to be emitted and received No A UDS is not quicker at calculating the time taken for a signal to be emitted and received than some other types of distance sensor that use light Week 2, step 6 It is not affected by sound waves that interfere with the signal No A UDS signal can be disrupted by certain sound waves Week 2, step 6 It is not affected by the colour of the object that the signal reflects off Yes N/A Week 2, step 6 Question 3 What happens if an object is closer than the minimum range of the UDS? Choices A large value is output by the sensor Yes The receiver may not pick up the sound when it is initially reflected off an object, and instead may detect the sound once it has rebounded off another object; this results in an inaccurately high distance reading Week 2, step 6 A very small value is output by the sensor No The receiver may not pick up the signal when it is initially reflected off an object, and instead may detect the signal once it has rebounded off another object Week 2, step 6 The sensor doesn\u2019t output anything No The UDS will always output a duration, even if it does not detect an object Week 2, step 8 An error occurs in the Python program No The GPIO Zero library will output a value each time the UDS is triggered Week 2, step 8 Question 4 What happens if an object is further away than the maximum range of the UDS? Choices A large value is output by the sensor Yes If the receiver doesn\u2019t detect the ultrasound after a set time, the Echo pin returns to low; this duration indicates that no objects were detected within the maximum range of the sensor Week 2, step 8 A very small value is output by the sensor No The receiver may not pick up the signal when it is initially reflected off an object, and may instead detect the signal once it has rebounded off another object Week 2, step 6 The sensor doesn\u2019t output anything No The UDS will always output a duration, even if it does not detect an object Week 2, step 8 An error occurs in the Python program No The GPIO Zero library will output a value each time the UDS is triggered Week 2, step 8","title":"Quiz: How do distance sensors work?"},{"location":"week-2/fl-progrobot-w2-step11/#quiz-how-do-distance-sensors-work","text":"You have been learning about the functionality of a UDS this week, and have seen some examples of how one can be used for detecting objects. You will be able to test your knowledge of how a UDS functions in this quiz.","title":"Quiz: How do distance sensors work?"},{"location":"week-2/fl-progrobot-w2-step11/#question-1","text":"What does a UDS use to measure the time it takes for an object to be detected?","title":"Question 1"},{"location":"week-2/fl-progrobot-w2-step11/#choices","text":"Radar No Radar uses radio waves to detect objects but a UDS does not Week 2, step 6 Ultrasound Yes N/A Week 2, step 6 Infrared light No An infrared distance sensor uses infrared light to measure the distance of an object but a UDS does not Week 2, step 6 Ultraviolet light No An UDS doesn't use ultraviolet light to measure the distance of objects Week 2, step 6","title":"Choices"},{"location":"week-2/fl-progrobot-w2-step11/#question-2","text":"Which one of these is an advantage of a UDS over other types of distance sensor?","title":"Question 2"},{"location":"week-2/fl-progrobot-w2-step11/#choices_1","text":"It is much more compact than most other distance sensors No Different types of distance sensor can come in a range of sizes, depending on factors such as the range of the sensor Week 2, step 6 It is quicker at calculating the time taken for a signal to be emitted and received No A UDS is not quicker at calculating the time taken for a signal to be emitted and received than some other types of distance sensor that use light Week 2, step 6 It is not affected by sound waves that interfere with the signal No A UDS signal can be disrupted by certain sound waves Week 2, step 6 It is not affected by the colour of the object that the signal reflects off Yes N/A Week 2, step 6","title":"Choices"},{"location":"week-2/fl-progrobot-w2-step11/#question-3","text":"What happens if an object is closer than the minimum range of the UDS?","title":"Question 3"},{"location":"week-2/fl-progrobot-w2-step11/#choices_2","text":"A large value is output by the sensor Yes The receiver may not pick up the sound when it is initially reflected off an object, and instead may detect the sound once it has rebounded off another object; this results in an inaccurately high distance reading Week 2, step 6 A very small value is output by the sensor No The receiver may not pick up the signal when it is initially reflected off an object, and instead may detect the signal once it has rebounded off another object Week 2, step 6 The sensor doesn\u2019t output anything No The UDS will always output a duration, even if it does not detect an object Week 2, step 8 An error occurs in the Python program No The GPIO Zero library will output a value each time the UDS is triggered Week 2, step 8","title":"Choices"},{"location":"week-2/fl-progrobot-w2-step11/#question-4","text":"What happens if an object is further away than the maximum range of the UDS?","title":"Question 4"},{"location":"week-2/fl-progrobot-w2-step11/#choices_3","text":"A large value is output by the sensor Yes If the receiver doesn\u2019t detect the ultrasound after a set time, the Echo pin returns to low; this duration indicates that no objects were detected within the maximum range of the sensor Week 2, step 8 A very small value is output by the sensor No The receiver may not pick up the signal when it is initially reflected off an object, and may instead detect the signal once it has rebounded off another object Week 2, step 6 The sensor doesn\u2019t output anything No The UDS will always output a duration, even if it does not detect an object Week 2, step 8 An error occurs in the Python program No The GPIO Zero library will output a value each time the UDS is triggered Week 2, step 8","title":"Choices"},{"location":"week-2/fl-progrobot-w2-step12/","text":"Resources Video Video subtitles The end of week two Well done on reaching the end of week two of the course. This week, you've attached a UDS sensor to your robot and coded the robot to avoid obstacles. You've also thought about how your robot should react to obstacles, and considered its limitations. Next week, you will build on your learning by adding more sensors to your buggy, and write a line-following algorithm. What did you enjoy most this week? Did you find anything particularly tricky? Share your thoughts in the comments section.","title":"The end of week two"},{"location":"week-2/fl-progrobot-w2-step12/#the-end-of-week-two","text":"Well done on reaching the end of week two of the course. This week, you've attached a UDS sensor to your robot and coded the robot to avoid obstacles. You've also thought about how your robot should react to obstacles, and considered its limitations. Next week, you will build on your learning by adding more sensors to your buggy, and write a line-following algorithm. What did you enjoy most this week? Did you find anything particularly tricky? Share your thoughts in the comments section.","title":"The end of week two"},{"location":"week-3/fl-progrobot-w3-activity/","text":"[comment]: # ( Is this step open? Y/N If so, short description of this step: Related links: Related files: ) Week three: Programming robots to follow lines Welcome to week three Welcome to week three of the course! Line-sensing robots Learn about how line sensors work and how they are used in robotics. Adding a line sensor to the buggy Attach two line sensors to your robot buggy and test that they work. Developing line-following algorithms Program your robot to follow a line. The future of robotics How might robots affect different sectors in the future?","title":"Week three: Programming robots to follow lines"},{"location":"week-3/fl-progrobot-w3-activity/#week-three-programming-robots-to-follow-lines","text":"","title":"Week three: Programming robots to follow lines"},{"location":"week-3/fl-progrobot-w3-activity/#welcome-to-week-three","text":"Welcome to week three of the course!","title":"Welcome to week three"},{"location":"week-3/fl-progrobot-w3-activity/#line-sensing-robots","text":"Learn about how line sensors work and how they are used in robotics.","title":"Line-sensing robots"},{"location":"week-3/fl-progrobot-w3-activity/#adding-a-line-sensor-to-the-buggy","text":"Attach two line sensors to your robot buggy and test that they work.","title":"Adding a line sensor to the buggy"},{"location":"week-3/fl-progrobot-w3-activity/#developing-line-following-algorithms","text":"Program your robot to follow a line.","title":"Developing line-following algorithms"},{"location":"week-3/fl-progrobot-w3-activity/#the-future-of-robotics","text":"How might robots affect different sectors in the future?","title":"The future of robotics"},{"location":"week-3/fl-progrobot-w3-step01/","text":"Resources Video Video subtitles Welcome to week three Welcome to week three of Robotics With Raspberry Pi: Build and Program Your First Robot Buggy . Last week you added a UDS to your robot, and programmed it to avoid obstacles. This week you will: Look at how line-sensing robots are used Connect some line sensors to your robot and check that they sense correctly the change between white paper and a dark line Program your robot to follow a line Think about how to improve the performance of your line-following robot I hope you enjoy the week!","title":"Welcome to week three"},{"location":"week-3/fl-progrobot-w3-step01/#welcome-to-week-three","text":"Welcome to week three of Robotics With Raspberry Pi: Build and Program Your First Robot Buggy . Last week you added a UDS to your robot, and programmed it to avoid obstacles. This week you will: Look at how line-sensing robots are used Connect some line sensors to your robot and check that they sense correctly the change between white paper and a dark line Program your robot to follow a line Think about how to improve the performance of your line-following robot I hope you enjoy the week!","title":"Welcome to week three"},{"location":"week-3/fl-progrobot-w3-step03/","text":"Line-sensing robots This week you will be attaching a line sensor to your buggy and turning it into a line-following robot. This type of robot is very popular with beginner roboticists, as it lets you experience both the software and hardware aspects of robotics. However, line-following robots are much more than a learning tool, and have a rich history going all the way back to the 1960s. What is line sensing and why are robots doing it? Line-sensing robots (sometimes called line-following robots) move autonomously by following a line, typically one drawn on the ground underneath the robot. In early robotics, line following was a way of allowing robots to move autonomously. Processors at the time were struggling to handle the amount of data required from cameras or proximity sensors for full autonomous movement. Line sensing was pursued as an achievable alternative to true autonomous movement. Examples of line-sensing robots As you have heard already, robots are often used to explore harsh environments that would be difficult for human explorers. In the 1960s, one of the biggest exploration projects of all time was in full swing: the space race. Most robots that were built for Moon landings were remote-controlled. The massive distance between the Earth and the Moon meant that these early Moon buggies had to deal with huge delays between instruction and action. To try to tackle this challenge, a team of university roboticists at Stanford created a cart. The Stanford Cart The Stanford Cart started life as a remote-controlled mobile robot. A four-wheeled cart, its chassis consisted of a rectangular box fitted with cameras and an on-board TV system. Researchers at the university worked on the cart from 1960 to 1980; for a period in 1970 they outfitted the cart with line sensors to test autonomous navigation algorithms. embed Here is another video of the cart in action ; the out-takes from the original video start from six seconds in. The robot used a camera pointing towards the ground, which tracked a white line drawn by the researchers. The robot would adjust its direction to keep the line in the middle of the picture captured by the camera. It moved at a walking pace and was reasonably successful at this task. Later, the cart would be turned into a fully autonomous vehicle; for a time, it was at the cutting edge of vision-controlled robots. The team would famously let the robot roam the campus unaccompanied, and created a sign that read \"CAUTION ROBOT VEHICLE\" to hang on it when it was out and about. This sign caused the lead researcher a lot of headaches, as he kept having to get it remade after it was repeatedly stolen. Modern uses for line-following robots Line-following robots excel in situations in which the tasks they need to complete do not involve complex movement or much decision-making. Warehouse robots A good example is robots working in a warehouse; the movements they need to make require them to follow preset paths to collect pallets. Warehouses, particularly those of large internet shopping companies (think Amazon or Alibaba), need a lot of stock to be moved around the massive buildings. The stock robots move around the warehouses to pick up cages containing items that have either just arrived or are being prepared for dispatch. Lines on the floor allow the robots to navigate the busy warehouse space without wasting too much computational power on navigation. Competitions As mentioned earlier, line-sensing robots have a secure place in the robotics world, as they make a great challenge for beginner roboticists. This has led to the creation of competitions pitting robots against one another, challenging them to follow a line track as quickly as possible. Judges watch the robots and penalise them for straying from the line, either by giving time penalties or in some cases by disqualifying them. The size and complexity of the track depends on the competitors and their expected experience levels. Some competitions are aimed at children, and so the courses are simple, small ovals. Some more complex competitions involve line mazes for robots to map and navigate. Have a look online; you might be able to find a competition running near you. You could even enter your buggy! Discussion Earlier, I discussed warehouse robots, which are one modern use of line following. What other types of work could a line-following robot do? Are there other types of work that require only simple navigation? Leave your thoughts in the comments below.","title":"Line-sensing robots"},{"location":"week-3/fl-progrobot-w3-step03/#line-sensing-robots","text":"This week you will be attaching a line sensor to your buggy and turning it into a line-following robot. This type of robot is very popular with beginner roboticists, as it lets you experience both the software and hardware aspects of robotics. However, line-following robots are much more than a learning tool, and have a rich history going all the way back to the 1960s.","title":"Line-sensing robots"},{"location":"week-3/fl-progrobot-w3-step03/#what-is-line-sensing-and-why-are-robots-doing-it","text":"Line-sensing robots (sometimes called line-following robots) move autonomously by following a line, typically one drawn on the ground underneath the robot. In early robotics, line following was a way of allowing robots to move autonomously. Processors at the time were struggling to handle the amount of data required from cameras or proximity sensors for full autonomous movement. Line sensing was pursued as an achievable alternative to true autonomous movement.","title":"What is line sensing and why are robots doing it?"},{"location":"week-3/fl-progrobot-w3-step03/#examples-of-line-sensing-robots","text":"As you have heard already, robots are often used to explore harsh environments that would be difficult for human explorers. In the 1960s, one of the biggest exploration projects of all time was in full swing: the space race. Most robots that were built for Moon landings were remote-controlled. The massive distance between the Earth and the Moon meant that these early Moon buggies had to deal with huge delays between instruction and action. To try to tackle this challenge, a team of university roboticists at Stanford created a cart.","title":"Examples of line-sensing robots"},{"location":"week-3/fl-progrobot-w3-step03/#the-stanford-cart","text":"The Stanford Cart started life as a remote-controlled mobile robot. A four-wheeled cart, its chassis consisted of a rectangular box fitted with cameras and an on-board TV system. Researchers at the university worked on the cart from 1960 to 1980; for a period in 1970 they outfitted the cart with line sensors to test autonomous navigation algorithms. embed Here is another video of the cart in action ; the out-takes from the original video start from six seconds in. The robot used a camera pointing towards the ground, which tracked a white line drawn by the researchers. The robot would adjust its direction to keep the line in the middle of the picture captured by the camera. It moved at a walking pace and was reasonably successful at this task. Later, the cart would be turned into a fully autonomous vehicle; for a time, it was at the cutting edge of vision-controlled robots. The team would famously let the robot roam the campus unaccompanied, and created a sign that read \"CAUTION ROBOT VEHICLE\" to hang on it when it was out and about. This sign caused the lead researcher a lot of headaches, as he kept having to get it remade after it was repeatedly stolen.","title":"The Stanford Cart"},{"location":"week-3/fl-progrobot-w3-step03/#modern-uses-for-line-following-robots","text":"Line-following robots excel in situations in which the tasks they need to complete do not involve complex movement or much decision-making.","title":"Modern uses for line-following robots"},{"location":"week-3/fl-progrobot-w3-step03/#warehouse-robots","text":"A good example is robots working in a warehouse; the movements they need to make require them to follow preset paths to collect pallets. Warehouses, particularly those of large internet shopping companies (think Amazon or Alibaba), need a lot of stock to be moved around the massive buildings. The stock robots move around the warehouses to pick up cages containing items that have either just arrived or are being prepared for dispatch. Lines on the floor allow the robots to navigate the busy warehouse space without wasting too much computational power on navigation.","title":"Warehouse robots"},{"location":"week-3/fl-progrobot-w3-step03/#competitions","text":"As mentioned earlier, line-sensing robots have a secure place in the robotics world, as they make a great challenge for beginner roboticists. This has led to the creation of competitions pitting robots against one another, challenging them to follow a line track as quickly as possible. Judges watch the robots and penalise them for straying from the line, either by giving time penalties or in some cases by disqualifying them. The size and complexity of the track depends on the competitors and their expected experience levels. Some competitions are aimed at children, and so the courses are simple, small ovals. Some more complex competitions involve line mazes for robots to map and navigate. Have a look online; you might be able to find a competition running near you. You could even enter your buggy!","title":"Competitions"},{"location":"week-3/fl-progrobot-w3-step03/#discussion","text":"Earlier, I discussed warehouse robots, which are one modern use of line following. What other types of work could a line-following robot do? Are there other types of work that require only simple navigation? Leave your thoughts in the comments below.","title":"Discussion"},{"location":"week-3/fl-progrobot-w3-step04/","text":"Line sensors and how to use them In this step you will investigate how a line sensor operates and how it detects a line. I will be using the TCRT5000 IR sensor as my example, but the learning can apply to other line sensors as well. This knowledge will help you design and program a line-following algorithm later in the week. Infrared (IR) detection Line sensors detect the presence of a black line by emitting infrared (IR) light and detecting the light levels that return to the sensor. They do this using two components: an emitter and a light sensor (receiver). You can see an example TCRT5000 line sensor below. Your components may be laid out differently (all on one side, for example), but the components I will discuss will be present on most line sensors. On the top right-hand side of the image you can see two circular components that look a bit like LEDs. The blue one is the IR emitter and the black one is the receiver. These devices also have a component called a potentiometer, which adjusts the device's threshold. This is done by using a screwdriver to turn the white dial that looks like a cross on the left-hand side of the image. The device will emit IR light, and the sensor will capture the light level that is reflected from the surface underneath it. Some line sensors have two types of output: analogue and digital. The analogue output is not always present, but will return a constant reading of the light levels the sensor is detecting. Analogue signals need to be converted to digital before a Raspberry Pi can use them. The digital output results from a comparison of the light levels against a threshold level that is adjusted by turning the potentiometer. If the sensor does not receive enough light to surpass the threshold value, the digital output will be high (1). If enough light is received and the threshold value is surpassed, the pin will be set to low (0). The set-up of these devices may seem a bit topsy-turvy at first, but it makes more sense when you consider that the sensor is designed to detect black lines. A black line will not reflect as much light, so the output will be set to high (1) when a black surface is underneath. How to use a line sensor Now that you know a bit more how a line sensor works, you should learn how to use one. The line sensor also has an array of pins, some of which you will have to connect to the Raspberry Pi you are using: VCC needs to be connected to a voltage in between 3.3 and 5V, to power the device GND is the ground pin that is required to complete the circuit AO is the analogue output (this will not work with the Raspberry Pi) DO is the digital output pin (this will work with the Raspberry Pi) The VCC pin here can take a range of voltages, so potential dividers are not necessary. It is also worth noting that the AO pin does not feature on all line sensors. Two sensors are better than one You can create a line-following robot with only one sensor, as this is enough to detect a line underneath the robot. If the robot strays from the line, though, it is very difficult to work out which way it needs to turn to find the line again. To solve this problem, you can use more than one sensor. If you add a second sensor, and spread the sensors out evenly on either side of the caster wheel, the information gathered from the sensors will allow your robot to find the line again. If the line is in the centre of the robot, both sensors will return a 0 from their digital pins, as they are both over the white background. However, if the robot moves to the right, the left sensor will eventually cross onto the line, changing its output to a 1. When this happens, the robot should correct its course and turn left. Once the sensor returns to a 0 value, we know that the line is back in the middle of the robot. The same applies when the robot turns too far left; the right sensor will move over the line and change its reading. The robot should then turn right to the right to correct itself. Discussion You can use even more than two sensors if you want; some designs use three or four. How would a third sensor in the centre of the robot impact the way it moves? What difference do the extra sensors make? Share your thoughts in the comments section.","title":"Line sensors and how to use them"},{"location":"week-3/fl-progrobot-w3-step04/#line-sensors-and-how-to-use-them","text":"In this step you will investigate how a line sensor operates and how it detects a line. I will be using the TCRT5000 IR sensor as my example, but the learning can apply to other line sensors as well. This knowledge will help you design and program a line-following algorithm later in the week.","title":"Line sensors and how to use them"},{"location":"week-3/fl-progrobot-w3-step04/#infrared-ir-detection","text":"Line sensors detect the presence of a black line by emitting infrared (IR) light and detecting the light levels that return to the sensor. They do this using two components: an emitter and a light sensor (receiver). You can see an example TCRT5000 line sensor below. Your components may be laid out differently (all on one side, for example), but the components I will discuss will be present on most line sensors. On the top right-hand side of the image you can see two circular components that look a bit like LEDs. The blue one is the IR emitter and the black one is the receiver. These devices also have a component called a potentiometer, which adjusts the device's threshold. This is done by using a screwdriver to turn the white dial that looks like a cross on the left-hand side of the image. The device will emit IR light, and the sensor will capture the light level that is reflected from the surface underneath it. Some line sensors have two types of output: analogue and digital. The analogue output is not always present, but will return a constant reading of the light levels the sensor is detecting. Analogue signals need to be converted to digital before a Raspberry Pi can use them. The digital output results from a comparison of the light levels against a threshold level that is adjusted by turning the potentiometer. If the sensor does not receive enough light to surpass the threshold value, the digital output will be high (1). If enough light is received and the threshold value is surpassed, the pin will be set to low (0). The set-up of these devices may seem a bit topsy-turvy at first, but it makes more sense when you consider that the sensor is designed to detect black lines. A black line will not reflect as much light, so the output will be set to high (1) when a black surface is underneath.","title":"Infrared (IR) detection"},{"location":"week-3/fl-progrobot-w3-step04/#how-to-use-a-line-sensor","text":"Now that you know a bit more how a line sensor works, you should learn how to use one. The line sensor also has an array of pins, some of which you will have to connect to the Raspberry Pi you are using: VCC needs to be connected to a voltage in between 3.3 and 5V, to power the device GND is the ground pin that is required to complete the circuit AO is the analogue output (this will not work with the Raspberry Pi) DO is the digital output pin (this will work with the Raspberry Pi) The VCC pin here can take a range of voltages, so potential dividers are not necessary. It is also worth noting that the AO pin does not feature on all line sensors.","title":"How to use a line sensor"},{"location":"week-3/fl-progrobot-w3-step04/#two-sensors-are-better-than-one","text":"You can create a line-following robot with only one sensor, as this is enough to detect a line underneath the robot. If the robot strays from the line, though, it is very difficult to work out which way it needs to turn to find the line again. To solve this problem, you can use more than one sensor. If you add a second sensor, and spread the sensors out evenly on either side of the caster wheel, the information gathered from the sensors will allow your robot to find the line again. If the line is in the centre of the robot, both sensors will return a 0 from their digital pins, as they are both over the white background. However, if the robot moves to the right, the left sensor will eventually cross onto the line, changing its output to a 1. When this happens, the robot should correct its course and turn left. Once the sensor returns to a 0 value, we know that the line is back in the middle of the robot. The same applies when the robot turns too far left; the right sensor will move over the line and change its reading. The robot should then turn right to the right to correct itself.","title":"Two sensors are better than one"},{"location":"week-3/fl-progrobot-w3-step04/#discussion","text":"You can use even more than two sensors if you want; some designs use three or four. How would a third sensor in the centre of the robot impact the way it moves? What difference do the extra sensors make? Share your thoughts in the comments section.","title":"Discussion"},{"location":"week-3/fl-progrobot-w3-step05/","text":"Resources Video Video subtitles Connecting the line sensors The rest of this week will be spent turning your robot buggy into a line-following robot. I will be demonstrating how to connect two TCRT5000 line sensors to a Raspberry Pi. If you are not using the same line sensors, the instructions may be different, so check the specifications of your sensors. What you will need You will need the following items for this step: A robot buggy Six female-to-female jumper leads Two line-following sensors Making sense of your sensors For this build, I will be using two TCRT5000 line sensors, which have a working voltage of 3.3V to 5V. This means that each line sensor can be powered from either the 5V or 3V3 pins on a Raspberry Pi. The power pins that you have free will depend on the set-up of your robot. If you don't have enough power pins available, you can remove the power pin to the ultrasonic distance sensor (UDS) for now. The line sensor I am using has three pins: VCC for power, GND for ground, and OUT or DO for digital out (as described in the previous step). These are the only pins you will need to use for the buggy, though your line sensor may also have an extra pin for analogue out. One of the sensors will be used to detect a line on the left-hand side of the robot, and the other to detect a line on the right-hand side. Choose which sensor you want to be on the left and which on the right, before connecting them to the Raspberry Pi. Ideally, you don't want too many jumper leads crossing each other, or it can become a bit of a tangle! Connect the sensors to the Raspberry Pi Take one of the line sensors and three female-to-female jumper leads. Connect a jumper lead to each of the VCC , GND , and OUT (or DO ) pins. Connect the jumper lead from the VCC pin on the line sensor to either a 3V3 or 5V pin on the Raspberry Pi. Connect the GND pin on the sensor to a GND pin on the Raspberry Pi. The OUT pin can be connected to any numbered GPIO pin. In this example, I've used GPIO 19 for the left sensor and GPIO 26 for the right sensor. Repeat this process for the second line sensor, so that both sensors are connected to the Raspberry Pi. Discussion If you had any issues, leave a comment below and one of the facilitators will be able to help you.","title":"Connecting the line sensors"},{"location":"week-3/fl-progrobot-w3-step05/#connecting-the-line-sensors","text":"The rest of this week will be spent turning your robot buggy into a line-following robot. I will be demonstrating how to connect two TCRT5000 line sensors to a Raspberry Pi. If you are not using the same line sensors, the instructions may be different, so check the specifications of your sensors.","title":"Connecting the line sensors"},{"location":"week-3/fl-progrobot-w3-step05/#what-you-will-need","text":"You will need the following items for this step: A robot buggy Six female-to-female jumper leads Two line-following sensors","title":"What you will need"},{"location":"week-3/fl-progrobot-w3-step05/#making-sense-of-your-sensors","text":"For this build, I will be using two TCRT5000 line sensors, which have a working voltage of 3.3V to 5V. This means that each line sensor can be powered from either the 5V or 3V3 pins on a Raspberry Pi. The power pins that you have free will depend on the set-up of your robot. If you don't have enough power pins available, you can remove the power pin to the ultrasonic distance sensor (UDS) for now. The line sensor I am using has three pins: VCC for power, GND for ground, and OUT or DO for digital out (as described in the previous step). These are the only pins you will need to use for the buggy, though your line sensor may also have an extra pin for analogue out. One of the sensors will be used to detect a line on the left-hand side of the robot, and the other to detect a line on the right-hand side. Choose which sensor you want to be on the left and which on the right, before connecting them to the Raspberry Pi. Ideally, you don't want too many jumper leads crossing each other, or it can become a bit of a tangle!","title":"Making sense of your sensors"},{"location":"week-3/fl-progrobot-w3-step05/#connect-the-sensors-to-the-raspberry-pi","text":"Take one of the line sensors and three female-to-female jumper leads. Connect a jumper lead to each of the VCC , GND , and OUT (or DO ) pins. Connect the jumper lead from the VCC pin on the line sensor to either a 3V3 or 5V pin on the Raspberry Pi. Connect the GND pin on the sensor to a GND pin on the Raspberry Pi. The OUT pin can be connected to any numbered GPIO pin. In this example, I've used GPIO 19 for the left sensor and GPIO 26 for the right sensor. Repeat this process for the second line sensor, so that both sensors are connected to the Raspberry Pi.","title":"Connect the sensors to the Raspberry Pi"},{"location":"week-3/fl-progrobot-w3-step05/#discussion","text":"If you had any issues, leave a comment below and one of the facilitators will be able to help you.","title":"Discussion"},{"location":"week-3/fl-progrobot-w3-step06/","text":"Testing the line sensors You are now going to attach your line-following sensors to the chassis and test whether they are picking up the difference between light and dark surfaces. What you will need White paper or card (at least three sheets of A4) Black tape (a black marker pen would also work) You may also need: A screwdriver Preparing your track To test your robot, you'll need to prepare a track with a line for it to follow. I made a simple track out of three pieces of A4 paper placed in a slightly curved row, with a single strip of black tape making a line through the middle of the paper, as pictured below. This provides a clear contrast in light levels between the white paper and the black tape, so your line sensors should be able to detect accurately when the line is beneath them. Attaching the sensors to the chassis Before you modify the chassis, I recommend taking a few photos of your robot and the connections between the pins on the Raspberry Pi and the components. It is quite likely that a few of the jumper leads will come loose while you are attaching the line sensors to the chassis. You can use the photo of the robot, and/or the steps covered in the previous two weeks of this course, to help you check the leads and reconnect them correctly if necessary. Positioning the line sensors When using two line sensors, you want them to be positioned near the front of the chassis, and evenly spaced on either side of the caster wheel. This is so that each sensor can detect when it is over the line with minimal delay, so that the robot can be programmed to change course before it has drifted too far to either side of the line. The smaller the gap is between the sensors, the less the robot will need to wiggle from side to side before it is positioned directly over the line again. The optimal distance between the surface and the sensor is from 1 cm to 3 cm, which should be fine for most chassis. If not, you may need to tune the sensors later, using the instructions below. Align your robot so that the centre of the robot is directly over the black line on your track. On the chassis, mark where you want to position the line sensors so that the sensors will be on either side of the line. Securing the sensors to the chassis Cut two small holes in the bottom of your chassis so that the infrared (IR) emitter and receiver (the blue and black components that look like LEDs) can fit through. If the potentiometer and/or the tiny LED (which indicates when a line has been detected) are on the same side as the IR emitter and receiver, you will also need to include some space for these to fit through. Ideally, the holes will be big enough so that these parts can fit through them without the entire sensor dropping through the hole! You can then secure the sensor in place using tape; make sure the tape doesn't cover the IR emitter or receiver. Tuning the line sensors You need to check that the line sensors can detect the difference between a white surface and a black line reliably, and tune them up using the potentiometer. With the line sensors attached, boot up your Raspberry Pi. Move the robot slowly from side to side so that each of the line sensors passes over the black line. When a sensor is over a light surface, the LED on the sensor board should be on . Conversely, when a sensor passes over a dark line, the LED on the sensor should be off . Ideally, the LED of each sensor should be off as soon as the black line is directly underneath it, with as little delay as possible. If either of the sensors is not picking up the changes in light between the white paper and the black line accurately, you will need to adjust the threshold value by adjusting the potentiometer using a screwdriver. Be careful when turning the potentiometer, as it is quite a delicate component. Discussion How did you get on with testing the line sensors? Did you have any issues? Share your thoughts in the comments. In the next step you will have an opportunity to reflect on how you have got on in the course so far.","title":"Testing the line sensors"},{"location":"week-3/fl-progrobot-w3-step06/#testing-the-line-sensors","text":"You are now going to attach your line-following sensors to the chassis and test whether they are picking up the difference between light and dark surfaces.","title":"Testing the line sensors"},{"location":"week-3/fl-progrobot-w3-step06/#what-you-will-need","text":"White paper or card (at least three sheets of A4) Black tape (a black marker pen would also work) You may also need: A screwdriver","title":"What you will need"},{"location":"week-3/fl-progrobot-w3-step06/#preparing-your-track","text":"To test your robot, you'll need to prepare a track with a line for it to follow. I made a simple track out of three pieces of A4 paper placed in a slightly curved row, with a single strip of black tape making a line through the middle of the paper, as pictured below. This provides a clear contrast in light levels between the white paper and the black tape, so your line sensors should be able to detect accurately when the line is beneath them.","title":"Preparing your track"},{"location":"week-3/fl-progrobot-w3-step06/#attaching-the-sensors-to-the-chassis","text":"Before you modify the chassis, I recommend taking a few photos of your robot and the connections between the pins on the Raspberry Pi and the components. It is quite likely that a few of the jumper leads will come loose while you are attaching the line sensors to the chassis. You can use the photo of the robot, and/or the steps covered in the previous two weeks of this course, to help you check the leads and reconnect them correctly if necessary.","title":"Attaching the sensors to the chassis"},{"location":"week-3/fl-progrobot-w3-step06/#positioning-the-line-sensors","text":"When using two line sensors, you want them to be positioned near the front of the chassis, and evenly spaced on either side of the caster wheel. This is so that each sensor can detect when it is over the line with minimal delay, so that the robot can be programmed to change course before it has drifted too far to either side of the line. The smaller the gap is between the sensors, the less the robot will need to wiggle from side to side before it is positioned directly over the line again. The optimal distance between the surface and the sensor is from 1 cm to 3 cm, which should be fine for most chassis. If not, you may need to tune the sensors later, using the instructions below. Align your robot so that the centre of the robot is directly over the black line on your track. On the chassis, mark where you want to position the line sensors so that the sensors will be on either side of the line.","title":"Positioning the line sensors"},{"location":"week-3/fl-progrobot-w3-step06/#securing-the-sensors-to-the-chassis","text":"Cut two small holes in the bottom of your chassis so that the infrared (IR) emitter and receiver (the blue and black components that look like LEDs) can fit through. If the potentiometer and/or the tiny LED (which indicates when a line has been detected) are on the same side as the IR emitter and receiver, you will also need to include some space for these to fit through. Ideally, the holes will be big enough so that these parts can fit through them without the entire sensor dropping through the hole! You can then secure the sensor in place using tape; make sure the tape doesn't cover the IR emitter or receiver.","title":"Securing the sensors to the chassis"},{"location":"week-3/fl-progrobot-w3-step06/#tuning-the-line-sensors","text":"You need to check that the line sensors can detect the difference between a white surface and a black line reliably, and tune them up using the potentiometer. With the line sensors attached, boot up your Raspberry Pi. Move the robot slowly from side to side so that each of the line sensors passes over the black line. When a sensor is over a light surface, the LED on the sensor board should be on . Conversely, when a sensor passes over a dark line, the LED on the sensor should be off . Ideally, the LED of each sensor should be off as soon as the black line is directly underneath it, with as little delay as possible. If either of the sensors is not picking up the changes in light between the white paper and the black line accurately, you will need to adjust the threshold value by adjusting the potentiometer using a screwdriver. Be careful when turning the potentiometer, as it is quite a delicate component.","title":"Tuning the line sensors"},{"location":"week-3/fl-progrobot-w3-step06/#discussion","text":"How did you get on with testing the line sensors? Did you have any issues? Share your thoughts in the comments. In the next step you will have an opportunity to reflect on how you have got on in the course so far.","title":"Discussion"},{"location":"week-3/fl-progrobot-w3-step07/","text":"Sharing your progress You have made incredible progress with your robot buggy, turning it from an inanimate object into a robot that is able to sense the world around it and act upon this information. Well done. Take a minute to congratulate yourself on the hard work and persistence you have shown throughout this course. This is also a perfect time to share the progress you have made and any pictures or videos that you have of your robot in action. Describe your progress, and share a link to any image or videos you've taken of your robot, in the comments section below. You may need to use an image-hosting platform such as Imgur or a video-hosting platform such as YouTube . Are you stuck with anything? If you have any questions or are struggling with anything related to your robot buggy, leave a comment below and one of the course facilitators will provide help and support. Next steps In the next step you are going to write an algorithm for a basic line-following robot. You already know that the line sensors can detect the difference between light and dark surfaces, and that this can be translated into a digital output of 0 (for a white surface) or 1 (for a black surface). Think about the line-following algorithm and consider these questions: What do you think the line-following algorithm might look like? How should your robot react when the left sensor detects the line on your track? How should your robot react when the right sensor detects the line? Answer these questions in the comments section, either by writing the different stages of the algorithm as a list of instructions, or by creating a flow chart and posting a link to it.","title":"Sharing your progress"},{"location":"week-3/fl-progrobot-w3-step07/#sharing-your-progress","text":"You have made incredible progress with your robot buggy, turning it from an inanimate object into a robot that is able to sense the world around it and act upon this information. Well done. Take a minute to congratulate yourself on the hard work and persistence you have shown throughout this course. This is also a perfect time to share the progress you have made and any pictures or videos that you have of your robot in action. Describe your progress, and share a link to any image or videos you've taken of your robot, in the comments section below. You may need to use an image-hosting platform such as Imgur or a video-hosting platform such as YouTube .","title":"Sharing your progress"},{"location":"week-3/fl-progrobot-w3-step07/#are-you-stuck-with-anything","text":"If you have any questions or are struggling with anything related to your robot buggy, leave a comment below and one of the course facilitators will provide help and support.","title":"Are you stuck with anything?"},{"location":"week-3/fl-progrobot-w3-step07/#next-steps","text":"In the next step you are going to write an algorithm for a basic line-following robot. You already know that the line sensors can detect the difference between light and dark surfaces, and that this can be translated into a digital output of 0 (for a white surface) or 1 (for a black surface). Think about the line-following algorithm and consider these questions: What do you think the line-following algorithm might look like? How should your robot react when the left sensor detects the line on your track? How should your robot react when the right sensor detects the line? Answer these questions in the comments section, either by writing the different stages of the algorithm as a list of instructions, or by creating a flow chart and posting a link to it.","title":"Next steps"},{"location":"week-3/fl-progrobot-w3-step08/","text":"Resources Video Video subtitles Program a line-following algorithm Now that you have attached the line sensors, you are going to create a basic line-following algorithm using the readings from those sensors. Setting up the motors and line sensors First, you need to set up your program with the components you'll be interacting with. 1. Create a new Python 3 file. 2. Set up the program using the code below. You should recognise the elements from your previous programs. from gpiozero import Robot, LineSensor from time import sleep, time robin = Robot(left=(8, 7), right=(9, 10)) left_sensor = LineSensor(19) right_sensor= LineSensor(26) robin.forward() Don\u2019t forget to adjust the pin numbers if you\u2019ve used different GPIO pins for the motors or line sensors. The robin.forward() command is used to get your robot started. Describing the algorithm The line sensors have two states: the line is detected, or the line is not detected. The current state of each sensor will help to define the rules of your algorithm. To start with, consider what the robot should do when neither of the sensors detects the line. If the line is in the centre of the robot, both line sensors will return a 0, as they are over the white background. In this scenario, the robot should move forwards. Think about the rest of the line-following algorithm: What is the initial position of the robot in relation to the line? How should the robot react when the left sensor detects the line? How should the robot react when the right sensor detects the line? The rules of the algorithm The actions that the robot needs to take, depending on the readings it gets from the line sensors, are as follows: If there\u2019s a line under the left sensor, turn left If there\u2019s a line under the right sensor, turn right If there\u2019s no line under either the left sensor or the right sensor, drive forwards Using events To detect the state of each sensor, you are going to use two events from LineSensor , which is part of the GPIO Zero library. So far you have been writing procedural programs, which generally run instructions from top to bottom, calling functions as they run. Event-driven programs operate somewhat differently. The main difference is that in an event-driven program, the flow of the program and the order in which instructions are run are determined by events, such as a button being pressed. In your program, each of the line sensors will handle two events: when_line and when_no_line . The when_line event is triggered whenever the sensor changes state from 0 (white background) to 1 (black line), while when_no_line is triggered when the sensor changes state from 1 to 0. Programming the algorithm 3. Within the Python file you set up, instruct your robot to move in a certain direction based on the rules of the algorithm. left_sensor.when_line = robin.left right_sensor.when_line = robin.right left_sensor.when_no_line = robin.forward right_sensor.when_no_line = robin.forward Note: Unlike calling these methods during a program, when using events, you should make sure not to put brackets after the method name. You are providing a reference to the method, not calling it. The event only needs you to provide the method name; when the event happens it will find the method and call it. If you include brackets with the method, it will be called immediately. Ensuring the program doesn't run forever Currently, the motors will continue to run even after you close the program. If you ran the program at the moment, you would probably need to turn off the Raspberry Pi to stop your robot from moving. 4. To make sure that the robot doesn\u2019t keep running forever, and to close all the components' connections cleanly, add the following to the end of your program: sleep(10) robin.stop() robin.close() left_sensor.close() right_sensor.close() After ten seconds, the stop() command will stop both motors. Then the close() command will ensure that the motors and line sensors are shut down completely. You can change the number of seconds to a different value if you want to test the robot for a different period of time. Testing the algorithm 5. Try running the program with your robot on your track. Here is an example of a robot running on a basic track with this algorithm: Don\u2019t worry if your robot moves off the line a bit; just observe whether it follows the line. If it doesn't, check that the algorithm and the GPIO pin numbers you have specified in the program are correct. You may also need to check that the line sensors are accurately detecting the difference between the white surface and black line, using the instructions for testing the line sensors. Discussion How well does your robot follow the line? Why do you think the command robin.forward() is necessary before the events are defined? Share your thoughts in the comments section.","title":"Program a line-following algorithm"},{"location":"week-3/fl-progrobot-w3-step08/#program-a-line-following-algorithm","text":"Now that you have attached the line sensors, you are going to create a basic line-following algorithm using the readings from those sensors.","title":"Program a line-following algorithm"},{"location":"week-3/fl-progrobot-w3-step08/#setting-up-the-motors-and-line-sensors","text":"First, you need to set up your program with the components you'll be interacting with. 1. Create a new Python 3 file. 2. Set up the program using the code below. You should recognise the elements from your previous programs. from gpiozero import Robot, LineSensor from time import sleep, time robin = Robot(left=(8, 7), right=(9, 10)) left_sensor = LineSensor(19) right_sensor= LineSensor(26) robin.forward() Don\u2019t forget to adjust the pin numbers if you\u2019ve used different GPIO pins for the motors or line sensors. The robin.forward() command is used to get your robot started.","title":"Setting up the motors and line sensors"},{"location":"week-3/fl-progrobot-w3-step08/#describing-the-algorithm","text":"The line sensors have two states: the line is detected, or the line is not detected. The current state of each sensor will help to define the rules of your algorithm. To start with, consider what the robot should do when neither of the sensors detects the line. If the line is in the centre of the robot, both line sensors will return a 0, as they are over the white background. In this scenario, the robot should move forwards. Think about the rest of the line-following algorithm: What is the initial position of the robot in relation to the line? How should the robot react when the left sensor detects the line? How should the robot react when the right sensor detects the line?","title":"Describing the algorithm"},{"location":"week-3/fl-progrobot-w3-step08/#the-rules-of-the-algorithm","text":"The actions that the robot needs to take, depending on the readings it gets from the line sensors, are as follows: If there\u2019s a line under the left sensor, turn left If there\u2019s a line under the right sensor, turn right If there\u2019s no line under either the left sensor or the right sensor, drive forwards","title":"The rules of the algorithm"},{"location":"week-3/fl-progrobot-w3-step08/#using-events","text":"To detect the state of each sensor, you are going to use two events from LineSensor , which is part of the GPIO Zero library. So far you have been writing procedural programs, which generally run instructions from top to bottom, calling functions as they run. Event-driven programs operate somewhat differently. The main difference is that in an event-driven program, the flow of the program and the order in which instructions are run are determined by events, such as a button being pressed. In your program, each of the line sensors will handle two events: when_line and when_no_line . The when_line event is triggered whenever the sensor changes state from 0 (white background) to 1 (black line), while when_no_line is triggered when the sensor changes state from 1 to 0.","title":"Using events"},{"location":"week-3/fl-progrobot-w3-step08/#programming-the-algorithm","text":"3. Within the Python file you set up, instruct your robot to move in a certain direction based on the rules of the algorithm. left_sensor.when_line = robin.left right_sensor.when_line = robin.right left_sensor.when_no_line = robin.forward right_sensor.when_no_line = robin.forward Note: Unlike calling these methods during a program, when using events, you should make sure not to put brackets after the method name. You are providing a reference to the method, not calling it. The event only needs you to provide the method name; when the event happens it will find the method and call it. If you include brackets with the method, it will be called immediately.","title":"Programming the algorithm"},{"location":"week-3/fl-progrobot-w3-step08/#ensuring-the-program-doesnt-run-forever","text":"Currently, the motors will continue to run even after you close the program. If you ran the program at the moment, you would probably need to turn off the Raspberry Pi to stop your robot from moving. 4. To make sure that the robot doesn\u2019t keep running forever, and to close all the components' connections cleanly, add the following to the end of your program: sleep(10) robin.stop() robin.close() left_sensor.close() right_sensor.close() After ten seconds, the stop() command will stop both motors. Then the close() command will ensure that the motors and line sensors are shut down completely. You can change the number of seconds to a different value if you want to test the robot for a different period of time.","title":"Ensuring the program doesn't run forever"},{"location":"week-3/fl-progrobot-w3-step08/#testing-the-algorithm","text":"5. Try running the program with your robot on your track. Here is an example of a robot running on a basic track with this algorithm: Don\u2019t worry if your robot moves off the line a bit; just observe whether it follows the line. If it doesn't, check that the algorithm and the GPIO pin numbers you have specified in the program are correct. You may also need to check that the line sensors are accurately detecting the difference between the white surface and black line, using the instructions for testing the line sensors.","title":"Testing the algorithm"},{"location":"week-3/fl-progrobot-w3-step08/#discussion","text":"How well does your robot follow the line? Why do you think the command robin.forward() is necessary before the events are defined? Share your thoughts in the comments section.","title":"Discussion"},{"location":"week-3/fl-progrobot-w3-step09/","text":"Improving the line following The previous line-following program is OK, but the robot can move from side to side quite a lot as it follows the line. To make the movement more elegant, you can slow down the speed of the robot, making the turns smaller and more gradual. However, the when_line and when_no_line events don't allow you to modify the robot's default speed. To have more control over the robot, you can adapt your program so that it considers the states of the line sensors and uses these to choose the actions that are required of the motors. Setting up the program 1. Copy the code from the last step into a new Python file. 2. Remove all of the code after you have initialised the variables left_sensor and right_sensor . 3. After those variables have been defined, initialise the variables for controlling the speed of the motors and the timer: speed = 0.75 duration = 10 end_time = time() + duration running = True The value for each motor will be modified by the speed multiplier to slow down the robot a little. The value for speed usually needs to be at least 0.6, otherwise the motors do not have enough momentum to turn on a solid surface; the maximum value is 1. The other variables are used to create a timer so that the robot doesn't run forever, as with the UDS program last week. Remember that duration is the number of seconds your program will run for, and you can modify this yourself. Planning a better program To have more control over the robot's movement and speed, your program needs to choose how to instruct the motors based on the values received from the line sensors. Remember that when a line sensor is above a line, it outputs a 1 . When it\u2019s off a line, it outputs a 0 . You can\u2019t simply pass these values straight to the motors, because the motors accept a range of values from -1 to 1 ; positive values tell the motor to run forwards and negative values tell it to run in reverse. Taking this behaviour into account, I am going to define three rules to determine what outputs are sent to the motors. Three rules to rule them all Rule 1 If both line sensors output 0 , both motors should receive a positive value to drive forwards. Rule 2 If the left sensor outputs 1 , the robot has drifted to the right and needs to turn left. In this case, the left motor should run backwards (a negative signal is needed), while the right motor should run forwards. Rule 3 If the right sensor outputs 1 , the robot has drifted to the left and needs to turn right. Therefore, the right motor should run backwards (a negative signal is needed), while the left motor should run forwards. Why do you think there is not a rule for both the sensors outputting a 1 simultaneously? Programming the rules To start applying these rules, the code needs to read the outputs of the line sensors repeatedly, in a loop. 4. Add a while loop to the program, after where you initialised the speed and timer variables. while running: left_detect = left_sensor.value right_detect = right_sensor.value print (left_detect, right_detect) 5. If you run the program now, you should see the binary output from the sensors change when you move the sensors over and off the line, in accordance with the rules stated above. 6. Inside the while loop, use conditional statements to specify the direction of each motor, depending on the line sensor readings: while running: left_detect = left_sensor.value right_detect = right_sensor.value # Rule 1 if left_detect == 0 and right_detect == 0: left_mot = 1 right_mot = 1 # Rule 2 elif left_detect == 1: left_mot = -1 right_mot = 1 # Rule 3 elif right_detect == 1: left_mot = 1 right_mot = -1 print (left_mot, right_mot) 7. Run your code and test that the program outputs the correct motor values when you move the robot over and off the line. 8. Inside the loop, remove the print statement and replace it with: robin.left_motor.value = left_mot * speed robin.right_motor.value = right_mot * speed The value for each motor will be modified by the speed multiplier, to slow the robot down a little. Make sure you remove any print statements within the loop, otherwise these will affect the response time of the program and the robot may overshoot the line. 9. To stop the while loop from running forever, and to close all the component's connections cleanly, add this code inside the loop, at the end: if time() >= end_time: running = False robin.stop() robin.close() left_sensor.close() right_sensor.close() Test your program Now run your code and test your robot over a track. Try different values for speed (between 0 and 1) and check how your robot runs. How does this affect your robot's ability to follow the line? Share your findings in the comments section.","title":"Improving the line following"},{"location":"week-3/fl-progrobot-w3-step09/#improving-the-line-following","text":"The previous line-following program is OK, but the robot can move from side to side quite a lot as it follows the line. To make the movement more elegant, you can slow down the speed of the robot, making the turns smaller and more gradual. However, the when_line and when_no_line events don't allow you to modify the robot's default speed. To have more control over the robot, you can adapt your program so that it considers the states of the line sensors and uses these to choose the actions that are required of the motors.","title":"Improving the line following"},{"location":"week-3/fl-progrobot-w3-step09/#setting-up-the-program","text":"1. Copy the code from the last step into a new Python file. 2. Remove all of the code after you have initialised the variables left_sensor and right_sensor . 3. After those variables have been defined, initialise the variables for controlling the speed of the motors and the timer: speed = 0.75 duration = 10 end_time = time() + duration running = True The value for each motor will be modified by the speed multiplier to slow down the robot a little. The value for speed usually needs to be at least 0.6, otherwise the motors do not have enough momentum to turn on a solid surface; the maximum value is 1. The other variables are used to create a timer so that the robot doesn't run forever, as with the UDS program last week. Remember that duration is the number of seconds your program will run for, and you can modify this yourself.","title":"Setting up the program"},{"location":"week-3/fl-progrobot-w3-step09/#planning-a-better-program","text":"To have more control over the robot's movement and speed, your program needs to choose how to instruct the motors based on the values received from the line sensors. Remember that when a line sensor is above a line, it outputs a 1 . When it\u2019s off a line, it outputs a 0 . You can\u2019t simply pass these values straight to the motors, because the motors accept a range of values from -1 to 1 ; positive values tell the motor to run forwards and negative values tell it to run in reverse. Taking this behaviour into account, I am going to define three rules to determine what outputs are sent to the motors.","title":"Planning a better program"},{"location":"week-3/fl-progrobot-w3-step09/#three-rules-to-rule-them-all","text":"Rule 1 If both line sensors output 0 , both motors should receive a positive value to drive forwards. Rule 2 If the left sensor outputs 1 , the robot has drifted to the right and needs to turn left. In this case, the left motor should run backwards (a negative signal is needed), while the right motor should run forwards. Rule 3 If the right sensor outputs 1 , the robot has drifted to the left and needs to turn right. Therefore, the right motor should run backwards (a negative signal is needed), while the left motor should run forwards. Why do you think there is not a rule for both the sensors outputting a 1 simultaneously?","title":"Three rules to rule them all"},{"location":"week-3/fl-progrobot-w3-step09/#programming-the-rules","text":"To start applying these rules, the code needs to read the outputs of the line sensors repeatedly, in a loop. 4. Add a while loop to the program, after where you initialised the speed and timer variables. while running: left_detect = left_sensor.value right_detect = right_sensor.value print (left_detect, right_detect) 5. If you run the program now, you should see the binary output from the sensors change when you move the sensors over and off the line, in accordance with the rules stated above. 6. Inside the while loop, use conditional statements to specify the direction of each motor, depending on the line sensor readings: while running: left_detect = left_sensor.value right_detect = right_sensor.value # Rule 1 if left_detect == 0 and right_detect == 0: left_mot = 1 right_mot = 1 # Rule 2 elif left_detect == 1: left_mot = -1 right_mot = 1 # Rule 3 elif right_detect == 1: left_mot = 1 right_mot = -1 print (left_mot, right_mot) 7. Run your code and test that the program outputs the correct motor values when you move the robot over and off the line. 8. Inside the loop, remove the print statement and replace it with: robin.left_motor.value = left_mot * speed robin.right_motor.value = right_mot * speed The value for each motor will be modified by the speed multiplier, to slow the robot down a little. Make sure you remove any print statements within the loop, otherwise these will affect the response time of the program and the robot may overshoot the line. 9. To stop the while loop from running forever, and to close all the component's connections cleanly, add this code inside the loop, at the end: if time() >= end_time: running = False robin.stop() robin.close() left_sensor.close() right_sensor.close()","title":"Programming the rules"},{"location":"week-3/fl-progrobot-w3-step09/#test-your-program","text":"Now run your code and test your robot over a track. Try different values for speed (between 0 and 1) and check how your robot runs. How does this affect your robot's ability to follow the line? Share your findings in the comments section.","title":"Test your program"},{"location":"week-3/fl-progrobot-w3-step10/","text":"Robotics is changing our lives A few years ago, much of the content you have covered in this course would have been discussed exclusively in research laboratories, but robots have now shifted firmly from science fiction to science fact. This shift requires us to change the way we discuss the impact of robotics, moving the discussion from the theoretical to the concrete. Automation Modern factories have been transformed by robots, and our society has been transformed by the resulting improvements in efficiency and production rates. The lifestyle you lead now has been shaped by robotics, from the food you buy in supermarkets to the car you drive and even the books you read. AI and machine learning are huge industries, and these technologies are constantly improving. The jobs of our muscles are already at risk, and protected for now only by the cost of robotics. What happens when robots come for the jobs of our minds as well? More complex tasks, particularly creative ones, are next in line for a robotic revolution. How will we handle robots that have the ability to learn, lead whole companies, and even design new robots? For more discussion on the impact of technology, including automation and robotics, you can join our other course, Impact of Technology: How to Lead Classroom Discussions . The impact of robotics Industry The production industry is not the only sector to take advantage of robots. Earlier, you heard about warehouse robots that help with packing and shipping orders for large retailers. You also learnt about robots being used to navigate dangerous environments; some industrial environments definitely fit this bill. Mining is a good example of this, and not just mining for coal or oil, but also for the precious metals and materials used in the components inside our mobile phones and computers. Robots drastically improve efficiency in industry, and this can lead to large increases in production. The resources used are not bottomless, however, and neither is the energy required; without regulation we are at risk of overconsumption. Medicine Surgical robots are being used, to the benefit of both patients and staff. These machines are tools that a surgeon controls to perform surgeries through tiny incisions in a patient's body. The robots are very small and extremely accurate, so they cause far less trauma than traditional surgery, meaning quicker recovery times and fewer complications after the operation. Looking to the future, you can see a world where AI and medical robots merge. Intelligent surgical robots could perform surgeries independently, leading to a boost in the availability of high-quality medical care. The main downside of surgical robotics is the cost. Surgical robots are currently far too pricey for every hospital to be able to afford one. This restricts the care to wealthier areas; a drop in cost may eventually help to increase access to this resource. Lastly, there is a very important side of medicine that robots cannot currently replace: patient bedside care. The care nurses, doctors, and hospital staff provide comfort to patients, and for now this remains a task that only a human can accomplish. Education Robotics provides enormous benefits to computing education. Robots are cool, and they remain one of the biggest attractions to computing education, bringing fledgling roboticists to courses such as this one. In order to be a successful roboticist, you need the knowledge and skills provided by computer science. Some learners enjoy getting involved in robot competitions, and these offer a mixture of competitiveness and fun to engage learners, with learning as a side effect of participation. There is still work to be done to make the subject more inclusive. Robotics is still a selective subject, with relatively high entry requirements, both financially and cognitively. A lot of work has been done to improve this, and robotics is more accessible now than ever before. As I am sure you have noticed, the subject is still quite challenging for beginners, and a lot of resilience is necessary. There is an argument that this is not a bad thing, and that robotics also has a place in education as an extension activity to push more confident learners. Robotics in your life You have heard about a few ways in which robots have impacted our society and will continue to do so in the future. How have robots impacted your life, or the society you live in? This could be on one of the areas I spoke about above, or another experience you have had. Share your answers in the comments.","title":"Robotics is changing our lives"},{"location":"week-3/fl-progrobot-w3-step10/#robotics-is-changing-our-lives","text":"A few years ago, much of the content you have covered in this course would have been discussed exclusively in research laboratories, but robots have now shifted firmly from science fiction to science fact. This shift requires us to change the way we discuss the impact of robotics, moving the discussion from the theoretical to the concrete.","title":"Robotics is changing our lives"},{"location":"week-3/fl-progrobot-w3-step10/#automation","text":"Modern factories have been transformed by robots, and our society has been transformed by the resulting improvements in efficiency and production rates. The lifestyle you lead now has been shaped by robotics, from the food you buy in supermarkets to the car you drive and even the books you read. AI and machine learning are huge industries, and these technologies are constantly improving. The jobs of our muscles are already at risk, and protected for now only by the cost of robotics. What happens when robots come for the jobs of our minds as well? More complex tasks, particularly creative ones, are next in line for a robotic revolution. How will we handle robots that have the ability to learn, lead whole companies, and even design new robots? For more discussion on the impact of technology, including automation and robotics, you can join our other course, Impact of Technology: How to Lead Classroom Discussions .","title":"Automation"},{"location":"week-3/fl-progrobot-w3-step10/#the-impact-of-robotics","text":"","title":"The impact of robotics"},{"location":"week-3/fl-progrobot-w3-step10/#industry","text":"The production industry is not the only sector to take advantage of robots. Earlier, you heard about warehouse robots that help with packing and shipping orders for large retailers. You also learnt about robots being used to navigate dangerous environments; some industrial environments definitely fit this bill. Mining is a good example of this, and not just mining for coal or oil, but also for the precious metals and materials used in the components inside our mobile phones and computers. Robots drastically improve efficiency in industry, and this can lead to large increases in production. The resources used are not bottomless, however, and neither is the energy required; without regulation we are at risk of overconsumption.","title":"Industry"},{"location":"week-3/fl-progrobot-w3-step10/#medicine","text":"Surgical robots are being used, to the benefit of both patients and staff. These machines are tools that a surgeon controls to perform surgeries through tiny incisions in a patient's body. The robots are very small and extremely accurate, so they cause far less trauma than traditional surgery, meaning quicker recovery times and fewer complications after the operation. Looking to the future, you can see a world where AI and medical robots merge. Intelligent surgical robots could perform surgeries independently, leading to a boost in the availability of high-quality medical care. The main downside of surgical robotics is the cost. Surgical robots are currently far too pricey for every hospital to be able to afford one. This restricts the care to wealthier areas; a drop in cost may eventually help to increase access to this resource. Lastly, there is a very important side of medicine that robots cannot currently replace: patient bedside care. The care nurses, doctors, and hospital staff provide comfort to patients, and for now this remains a task that only a human can accomplish.","title":"Medicine"},{"location":"week-3/fl-progrobot-w3-step10/#education","text":"Robotics provides enormous benefits to computing education. Robots are cool, and they remain one of the biggest attractions to computing education, bringing fledgling roboticists to courses such as this one. In order to be a successful roboticist, you need the knowledge and skills provided by computer science. Some learners enjoy getting involved in robot competitions, and these offer a mixture of competitiveness and fun to engage learners, with learning as a side effect of participation. There is still work to be done to make the subject more inclusive. Robotics is still a selective subject, with relatively high entry requirements, both financially and cognitively. A lot of work has been done to improve this, and robotics is more accessible now than ever before. As I am sure you have noticed, the subject is still quite challenging for beginners, and a lot of resilience is necessary. There is an argument that this is not a bad thing, and that robotics also has a place in education as an extension activity to push more confident learners.","title":"Education"},{"location":"week-3/fl-progrobot-w3-step10/#robotics-in-your-life","text":"You have heard about a few ways in which robots have impacted our society and will continue to do so in the future. How have robots impacted your life, or the society you live in? This could be on one of the areas I spoke about above, or another experience you have had. Share your answers in the comments.","title":"Robotics in your life"},{"location":"week-3/fl-progrobot-w3-step11/","text":"Peer-assessment: Create a new function for your robot buggy This course has been all about building and programming a robot buggy using a Raspberry Pi. Over the three weeks of the course you have been following my instructions, attaching components to your chassis, and writing code to communicate with these components. Now it's time for you to create a new piece of functionality for your robot on your own. You'll then share what you've done with a fellow learner, so that they can give you feedback on it. Some examples of modifications you could make to your robot are: Allowing the buggy to be controlled remotely Adding a second UDS to the front of your chassis to improve object detection Attaching LEDs to your robot and decorating the chassis Replacing the ball caster with two more wheels Using a PID controller to gain more precise control over your robot's movement For this assignment you should upload images of your upgraded robot to an image-hosting platform such as Imgur or a video-hosting platform such as YouTube and include the link in your assignment. Alongside this, write a short summary of your new function, including: The original idea and why you chose it The components you used and any modifications you had to make to your robot A copy of your code and a description of how you designed and tested your program The challenges you had while adding the new functionality, as well as the successes you are proud of This assignment is peer assessed: once you have submitted your assignment, it will be reviewed by another learner on the course. In turn, you will be asked to assess another learner\u2019s work. There is a free-form text box for you to use below, but please feel free to include links to any online content you produce. You could use any cloud-based storage or office solution, such as: Dropbox Google Drive Remember that you also need to include links to the photos or videos of your robot that I've asked you to include. Warning: Once you submit your assignment, you cannot edit it again. It will be sent to another learner for feedback. Please be sure to read over your submission carefully before you send it off. Assignment guidelines You must give three assignment guidelines in the form of questions for the peer reviewer to answer, for example: What new piece of functionality has the author added? How well have they documented the components used and the code developed? How thoroughly has the author tested their robot?","title":"Peer-assessment: Create a new function for your robot buggy"},{"location":"week-3/fl-progrobot-w3-step11/#peer-assessment-create-a-new-function-for-your-robot-buggy","text":"This course has been all about building and programming a robot buggy using a Raspberry Pi. Over the three weeks of the course you have been following my instructions, attaching components to your chassis, and writing code to communicate with these components. Now it's time for you to create a new piece of functionality for your robot on your own. You'll then share what you've done with a fellow learner, so that they can give you feedback on it. Some examples of modifications you could make to your robot are: Allowing the buggy to be controlled remotely Adding a second UDS to the front of your chassis to improve object detection Attaching LEDs to your robot and decorating the chassis Replacing the ball caster with two more wheels Using a PID controller to gain more precise control over your robot's movement For this assignment you should upload images of your upgraded robot to an image-hosting platform such as Imgur or a video-hosting platform such as YouTube and include the link in your assignment. Alongside this, write a short summary of your new function, including: The original idea and why you chose it The components you used and any modifications you had to make to your robot A copy of your code and a description of how you designed and tested your program The challenges you had while adding the new functionality, as well as the successes you are proud of This assignment is peer assessed: once you have submitted your assignment, it will be reviewed by another learner on the course. In turn, you will be asked to assess another learner\u2019s work. There is a free-form text box for you to use below, but please feel free to include links to any online content you produce. You could use any cloud-based storage or office solution, such as: Dropbox Google Drive Remember that you also need to include links to the photos or videos of your robot that I've asked you to include. Warning: Once you submit your assignment, you cannot edit it again. It will be sent to another learner for feedback. Please be sure to read over your submission carefully before you send it off.","title":"Peer-assessment: Create a new function for your robot buggy"},{"location":"week-3/fl-progrobot-w3-step11/#assignment-guidelines","text":"You must give three assignment guidelines in the form of questions for the peer reviewer to answer, for example: What new piece of functionality has the author added? How well have they documented the components used and the code developed? How thoroughly has the author tested their robot?","title":"Assignment guidelines"},{"location":"week-3/fl-progrobot-w3-step12/","text":"Reviewing your peer's work Now that you've completed your assessment, it's time to review the work of one of your peers. You should read through their assessment, making sure to check that they've described the new functionality that they added to their buggy and the code and components that they needed to make it work. You should also look for some evidence of how they tested their robot. When leaving your review, provide three specific pieces of positive feedback, each mentioning one thing that you liked about their work and why you liked it. Also provide a single piece of constructive feedback about their new piece of functionality.","title":"Reviewing your peer's work"},{"location":"week-3/fl-progrobot-w3-step12/#reviewing-your-peers-work","text":"Now that you've completed your assessment, it's time to review the work of one of your peers. You should read through their assessment, making sure to check that they've described the new functionality that they added to their buggy and the code and components that they needed to make it work. You should also look for some evidence of how they tested their robot. When leaving your review, provide three specific pieces of positive feedback, each mentioning one thing that you liked about their work and why you liked it. Also provide a single piece of constructive feedback about their new piece of functionality.","title":"Reviewing your peer's work"},{"location":"week-3/fl-progrobot-w3-step14/","text":"Resources Video Video subtitles The end of the course Congratulations on reaching the end of the course! Over the three weeks of the course, you've built a robot based on a Raspberry Pi, and developed it so that it could move, avoid obstacles, and follow lines. You've also completed an assignment to increase the functionality of your robot. You've learnt about the GPIO Zero library and used it to control your robot. You've also had to think about how to construct your robot, attaching new elements to the chassis in suitable positions. It's also likely that you've had to fix some problems, either with how you built your robot, or with your programming. Throughout the course you've been developing these skills, which will be applicable to a whole range of products, not just robots. Good luck with all your future projects! Course feedback Share your thoughts on the course in the comments section. We'd love to hear your feedback. We'd particularly like to hear which parts of the course you enjoyed, something new that you learnt, or where you struggled. Continue learning The Raspberry Pi Foundation offers a range of other courses, and if you are a teacher in England, you can get free upgraded access to them through teachcomputing.org , the official website of the National Centre for Computing Education. This means you'll have free, unlimited access to the course, even after the run finishes, and you'll receive a Certificate of Achievement from FutureLearn when you complete the course. You'll also be able to use the courses as evidence for National Centre for Computing Education certification. If you are not a teacher in England, you can join the other courses from the Raspberry Pi Foundation for free on FutureLearn . In particular, the following courses may help to develop your background knowledge and inspire further discussion: Design and Prototype Embedded Systems : Improve your project design skills and learn about the embedded systems that are used in the world around you If you are a teacher in England, sign up for Design and Prototype Embedded Computer Systems through teachcomputing.org to access your free upgrade If you are not a teacher in England, sign up for Design and Prototype Embedded Computer Systems on FutureLearn Object-Oriented Programming in Python: Create Your Own Adventure Game : Learn more about the idea of 'classes', such as the Robot class that you used in this course. If you are a teacher in England, sign up for Object-Oriented Programming in Python through teachcomputing.org to access your free upgrade If you are not a teacher in England, sign up for Object-Oriented Programming in Python on FutureLearn Understanding Computer Systems : This course provides some background about the history of computation If you are a teacher in England, sign up for Understanding Computer Systems through teachcomputing.org to access your free upgrade If you are not a teacher in England, sign up for Understanding Computer Systems on FutureLearn","title":"The end of the course"},{"location":"week-3/fl-progrobot-w3-step14/#the-end-of-the-course","text":"Congratulations on reaching the end of the course! Over the three weeks of the course, you've built a robot based on a Raspberry Pi, and developed it so that it could move, avoid obstacles, and follow lines. You've also completed an assignment to increase the functionality of your robot. You've learnt about the GPIO Zero library and used it to control your robot. You've also had to think about how to construct your robot, attaching new elements to the chassis in suitable positions. It's also likely that you've had to fix some problems, either with how you built your robot, or with your programming. Throughout the course you've been developing these skills, which will be applicable to a whole range of products, not just robots. Good luck with all your future projects!","title":"The end of the course"},{"location":"week-3/fl-progrobot-w3-step14/#course-feedback","text":"Share your thoughts on the course in the comments section. We'd love to hear your feedback. We'd particularly like to hear which parts of the course you enjoyed, something new that you learnt, or where you struggled.","title":"Course feedback"},{"location":"week-3/fl-progrobot-w3-step14/#continue-learning","text":"The Raspberry Pi Foundation offers a range of other courses, and if you are a teacher in England, you can get free upgraded access to them through teachcomputing.org , the official website of the National Centre for Computing Education. This means you'll have free, unlimited access to the course, even after the run finishes, and you'll receive a Certificate of Achievement from FutureLearn when you complete the course. You'll also be able to use the courses as evidence for National Centre for Computing Education certification. If you are not a teacher in England, you can join the other courses from the Raspberry Pi Foundation for free on FutureLearn . In particular, the following courses may help to develop your background knowledge and inspire further discussion: Design and Prototype Embedded Systems : Improve your project design skills and learn about the embedded systems that are used in the world around you If you are a teacher in England, sign up for Design and Prototype Embedded Computer Systems through teachcomputing.org to access your free upgrade If you are not a teacher in England, sign up for Design and Prototype Embedded Computer Systems on FutureLearn Object-Oriented Programming in Python: Create Your Own Adventure Game : Learn more about the idea of 'classes', such as the Robot class that you used in this course. If you are a teacher in England, sign up for Object-Oriented Programming in Python through teachcomputing.org to access your free upgrade If you are not a teacher in England, sign up for Object-Oriented Programming in Python on FutureLearn Understanding Computer Systems : This course provides some background about the history of computation If you are a teacher in England, sign up for Understanding Computer Systems through teachcomputing.org to access your free upgrade If you are not a teacher in England, sign up for Understanding Computer Systems on FutureLearn","title":"Continue learning"}]}