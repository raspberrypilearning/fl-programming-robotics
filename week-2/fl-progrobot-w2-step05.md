[comment]: # (
Is this step open? Y/N
If so, short description of this step:
Related links:
Related files:
)

## Autonomous robots

So far this week you have been exploring *how* robots sense the world around them. In this step you are going to look at *why* it benefits robots to sense the world around them, and explore the world of autonomous robots.

### Autonomy

Autonomy is...

*freedom from external control or influence; independence.*

Autonomous robots are robots that operate and perform their tasks without intervention from a human controller. These robots use sensors and algorithms to navigate, make decisions and perform their tasks.

### Space Rovers

Robots can venture into environments that are extremely hostile to humans, allowing us to gather info and study important environments we wouldn't otherwise be able to.

![A rover on the surface of a Mars like planet (red and dusty) - it is collecting data on a clipboard. There are various sensors and modules on the robots body (satellite dishes, maybe a scanning light and a weather vein](images/2_5-Exploring_Rover)

Extra-terrestrial exploration is one area where robots are making a huge impact. Robotic space rovers are able to collect data and send it back to scientists on earth for study. Autonomy allows space rovers to make decisions and perform time sensitive tasks without the time lag for sending them signals from Earth.

**Sensors & Tasks**

The primary directive for space rovers is **data collection**. They also need the ability to navigate to achieve this mission. **Cameras** on top of the rover take images and video of the surface of the planet, to study the landscape and terrain. **Microscopic cameras** take extreme close ups of soil and rocks, showing minerals and textures on their surfaces. [**Light spectrometers**](https://sciencing.com/spectrometer-5372347.html) analyse the properties of soil and air by examining the light they absorb and emit. **Air quality, humidity, barometric pressure and temperature sensors** take readings of the environmental properties, to establish weather patterns on a seasonal basis.  

[If you are interested, you can see a full list of instruments on the Curiosity Mars rover here](https://mars.nasa.gov/msl/spacecraft/instruments/summary/)

### Driverless cars

Autonomous robots can use clever algorithm design to make decisions  much quicker than a human can. This can improve safety, and one of the most promising uses for this is *driverless cars*.

![A car, driving down a road with passengers inside. There are 4 passengers and they are all facing each other - clearly no one is driving. ](images/2_5-Driverless_Car)

The first driverless car was dreamt up in 1938, over 80 years ago. By 1958, there was a working model: the car could operate without a driver but was propelled by electro magnetic fields generated by cables embedded in the road.

Fast forward to current technology, and algorithms are running the show. A lot of cars now on the road have 'semi-autonomous' features like drive assist, assisted parking and braking. Truly driverless cars are in development by many different companies. [These systems are being tested and tweaked and are expected to be ready for general use as robotaxis in the next decade, although consumers will have to wait a bit longer to get their hands on one.](https://www.wired.com/story/future-of-transportation-self-driving-cars-reality-check/)

**Sensors & Tasks**

Driverless cars combine a array of sensors to collect a remarkable amount of information about their surroundings.

**Radar sensors** around the edge of the car monitor the positions of nearby vehicles. **Video cameras** monitor less regular stimuli, like road signs and pedestrians. **Light detection and ranging (LIDAR)** sensors, which use lasers in the same way UDS uses ultrasound, are used to check for the edge of the road and road markings, which are typically white and reflect light well. **Ultrasonic sensors** are used near the wheels to detect kerbs and other vehicles while parking. All of the data collected by these sensors is processed by an onboard computer, which will adjust the steering, acceleration and braking.

### Rescue Robots

Rescue robots can be sent into disaster zones to search for life. These robots are deployed into situations that are extremely dangerous but essential to save lives: house and forest fires, earthquake zones and tsunami/hurricane landing zones amongst many others. These robots are designed specifically for a single type of disaster, so this category covers a wide range of robots.

![A robot navigating through rubble - could be styled with an emergency responder high vis style paint. This robot should have tracks rather than wheels.](images/2_5-Rescue_Robot)

**Sensors & Tasks**

Due to the wide range of robots in this category, this break down will be a bit more general. These robots have a variety of sensors that are used to navigate through the terrain, detecting obstacles and dangerous terrain so they can be avoided. The movement apparatus in these robots are often the most complex parts of the robots, able to roll or swim around many obstacles or even move them if necessary. Aquatic rescue robots use propulsion systems to move through the water, land rescue robots are often equipped with treads which roll over difficult terrain much easier than wheels. Finally, an array of sensors are included to allow the robots to make decisions about where to investigate and how to get there; you will have seen a few of these uses in the earlier step on sensors.

### Other autonomous robots.

Another use for autonomous robots is in production lines and factories.

**What sensors would they use? Which tasks do they perform?**

From your own experience or by doing some research answer the question above and post your thoughts in the comments section.
