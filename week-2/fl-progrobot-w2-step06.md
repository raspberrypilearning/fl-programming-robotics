[comment]: # (
Is this step open? Y/N
If so, short description of this step:
Related links:
Related files:
)

## Autonomous robots

So far this week you have been exploring *how* robots sense the world around them. You looked at various sensors and their applications in robotics, and took a deeper look at the UDS and how it works. In this step you are going to look at the *why* it benefits robots to sense the world around them and explore the world of autonomous robots.

### Autonomy

Autonomy is...

*freedom from external control or influence; independence.*

Autonomous robots, are robots that operate and perform their tasks without intervention from a human controller. These robots use algorithms alone to navigate, make decisions and perform their tasks. 

### Driverless cars

Autonomous robots can use clever algorithm design to make decisions incredibly quickly, much quicker than a human can. One of the best uses for autonomous robots is for safety, and one of the most prevalent uses for this is *driverless cars*.

The first driverless car, was dreamt up in 1938... yeah you read that correctly - 1938, 80 years ago. By 1958, there was a working model, the car could operate without a driver but was propelled by electro magnetic fields generated by cables embedded in the road. No algorithms were involved in the making of that car. 

Fast forward to current technology, and algorithms are running the show. A lot of cars now on the road have 'semi-autonomous' features like drive assist, assisted parking and braking. Truly driverless cars have been developed by companies like; Tesla, Google, BMW and Mercedes Benz amongst others. These systems are being tested and tweaked for general use and are expected to be commonplace as early as 2025.

**How do they work?**

Driverless cars combine a huge array of sensors to monitor the road, surroundings, obstacles and other vehicles. The combination of these different systems give driverless cars a remarkable amount of information about their surroundings. 

*Radar sensors* around the edge of the car monitor the positions of nearby vehicles. *Video cameras* monitor less regular stimuli, like road signs and pedestrians. *Light detection and ranging (LIDAR)* sensors use lasers in the same way UDS uses ultrasound - to detect ranges. These sensors check for the edge of the road and road markings, which are typically white and reflect light well. Ultrasonic sensors are used near the wheels to detect kerbs and other vehicles while parking. All of this data is processed by an onboard computer, which will adjust the steering, acceleration and braking. 

### Space Rovers

Many of the important; scientific, exploratory and rescue operations humanity is undertaking involve venturing into environments that are extremely hostile to us. Using robots to do this allows us to gather info and study important environments we wouldn't otherwise be able to. 

Extraterrestrial exploration is one area where robots are making a huge impact - depending on the gravity. Robotic space rovers are able to navigate and collect data and send it back to scientists on earth for study. 

**How do they work?** 

The primary directive for space rovers is *data collection*, and the ability to navigate - which is essential to achieve the first mission. *Cameras* on top of the rover take images and video of the surface of the planet, so scientists can study the landscape and other properties of the terrain. *Microscopic cameras* are used to take extreme close ups of soil and rocks, showing minerals and textures on their surfaces. [*Spectrometers*](https://sciencing.com/spectrometer-5372347.html) analyse the properties of soil and air by examining their light spectrum properties, these instruments can detect radiation and other forms of light. *Environmental and atmospheric sensors* take readings of the weather and environmental properties of a planet, this data is used to establish weather patterns on a seasonal basis.  

[If you are interested, you can see a full list of instruments on the Curiosity Mars rover here](https://mars.nasa.gov/msl/spacecraft/instruments/summary/)

### Rescue Robots

Another great use of robotics in hostile environments, is rescue robots sent into disaster zones to search for life. These robots are deployed into situations that are extremely dangerous but essential to save lives. House and Forest fires, earthquake zones and tsunami/hurricane landing zones - amongst many others. These robots are designed specifically for a single type of disaster, so this category covers a wide range of robots. 

**How do they work?** 

Due to the wide range of robots in this category, this break down will be a bit more general. These robots have a variety of sensors that are used to navigate through the terrain, detecting obstacles and dangerous terrain so they can be avoided. The movement apparatus in these robots are often the most complex parts of the robots, able to roll or swim around many obstacles or even move them if necessary. Aquatic rescue robots use propulsion systems to move through the water, land rescue robots are often equipped with treads which roll over difficult terrain much easier. Finally, an array of sensors are included to allow the robots to make decisions about where to investigate and how to get there, you will have seen a few of these uses in the earlier step on sensors.

### Other autonomous robots. 

Another use for autonomous robots is in production lines and factory's. 

**How do they work?** 

From your own experience or by doing some research answer the question above and post your thoughts in the comments section.